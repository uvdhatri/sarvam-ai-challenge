{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uvdhatri/sarvam-ai-challenge/blob/main/sarvam_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rntJPk4H2OoF"
      },
      "source": [
        "# Download YouTube Video's Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCDAbzvU1DqZ"
      },
      "outputs": [],
      "source": [
        "! pip install pytube -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRT0zkiT1Q1L"
      },
      "outputs": [],
      "source": [
        "from pytube import YouTube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8F333t01vOK"
      },
      "outputs": [],
      "source": [
        "#VIDEO_URL = \"https://youtu.be/Sby1uJ_NFIY?si=M6iyHaF6V1kRuT-e\" #sarvam ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4s2ZtSmHj3-"
      },
      "outputs": [],
      "source": [
        "VIDEO_URL = 'https://youtu.be/Sby1uJ_NFIY?si=M6iyHaF6V1kRuT-e' #sarvam ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9XZvTcI3mhz"
      },
      "outputs": [],
      "source": [
        "#VIDEO_URL = 'https://youtu.be/Sby1uJ_NFIY?si=M6iyHaF6V1kRuT-e'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhBsFZ4V1wZG"
      },
      "outputs": [],
      "source": [
        "yt = YouTube(VIDEO_URL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zk1w07V21XDZ",
        "outputId": "fa580c5b-b42b-4b21-ebb2-8c1a2e2f7bae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ytaudio.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "yt.streams \\\n",
        ".filter(only_audio=True, file_extension='mp4') \\\n",
        "    .first() \\\n",
        "    .download(filename='ytaudio.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUfk3DWo12yb",
        "outputId": "dd5503a1-31cb-4dfe-8542-a2a0c3be0920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'ytaudio.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : dash\n",
            "    minor_version   : 0\n",
            "    compatible_brands: iso6mp41\n",
            "    creation_time   : 2023-12-16T09:34:29.000000Z\n",
            "  Duration: 00:26:15.15, start: 0.000000, bitrate: 48 kb/s\n",
            "  Stream #0:0(eng): Audio: aac (HE-AAC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 0 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2023-12-16T09:34:29.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to 'ytaudio.wav':\n",
            "  Metadata:\n",
            "    major_brand     : dash\n",
            "    minor_version   : 0\n",
            "    compatible_brands: iso6mp41\n",
            "    ISFT            : Lavf58.76.100\n",
            "  Stream #0:0(eng): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, stereo, s16, 512 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2023-12-16T09:34:29.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc58.134.100 pcm_s16le\n",
            "size=   98447kB time=00:26:15.14 bitrate= 512.0kbits/s speed= 180x    \n",
            "video:0kB audio:98447kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000077%\n"
          ]
        }
      ],
      "source": [
        "! ffmpeg -i ytaudio.mp4 -acodec pcm_s16le -ar 16000 ytaudio.wav"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CqgQmI62RcX"
      },
      "source": [
        "# English ASR with HuggingSound"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkfBQrUN2Vjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7505c1fc-7752-4eb3-c493-26c428de36a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m506.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install huggingsound -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkUnx8ZU2WlJ"
      },
      "outputs": [],
      "source": [
        "from huggingsound import SpeechRecognitionModel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jj7WcGRx5NvJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cZYiuhenEtzD",
        "outputId": "cbbcee4b-4b1a-4368-9e49-a2ca3ecef8f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336,
          "referenced_widgets": [
            "f6399a0aaaba4199bd17bdb3f4c4c105",
            "c021321ad1c34121a56e45062db03b12",
            "61cbc9241a0d402ca06cc3f920712fd3",
            "7fac24baddcd4b3590a94530559777cc",
            "c9e909b01cca482981a3397e39e9a4b7",
            "660301ea651442adadce24d8da27a2fa",
            "1c875bc1839f4ce198c2aaa92d506b6b",
            "ee4424304f5540978216f4c79d74479a",
            "0d5863c887474be3919bd72b3e9fbd87",
            "89101a79247542dd9a8095bef7afcee6",
            "53e8ccab8da346b89e1532cff5eefb81",
            "bba9fdaa4f334a1b9b3eb244f7749042",
            "b7d781a9752b4673b9a0319239e33ffb",
            "61ad0b88193d4777b73916c6ecfaf829",
            "c6f3ea1e36ec4d47964e36c21e3108f7",
            "df56bc77113e4b46b551eab776838043",
            "cc3e10bcf5bc4ea49c21fd4702cca395",
            "38e616f59e284052882473201e53bf41",
            "c87d95c93b3049a58547b56fc859f233",
            "0317b9fcee974d4190d680cf4a82637e",
            "17918264bc964a6a90ae95107075dfb1",
            "42ea468df5834d01b130b89e6a9f34bf",
            "d79e7c909fda4fbf972494a16b7e6d8f",
            "2e8bb7a508084c438fa7eb57715c6287",
            "33e15d315d834330bb79c47718c3b2a1",
            "990552a19b6040598369af0c2976ffd3",
            "5abf10858c8d4a65856d5ca262f92d95",
            "6ecb54fce93e436399c2ebd965c18cb7",
            "76e8e8d229534300ae371a04d5f4fe3d",
            "50025e04e630441bb85207c42d4e2b4a",
            "8d698c9d3b4c442d860a597672f240b2",
            "cf80d4fde51b4342b66b174272b1bdb7",
            "330d7c50653c4069a100d51b96619779",
            "e42bf5d388064b19b2f1b0ebfbeae4c3",
            "80c495c9092a48869cab7ba7df20c381",
            "ca8e8fabc7494f0faf28090572977347",
            "032c8e094eec40c98ac0d9e284d9dd56",
            "63abb5c8ed86426fa0f672f9f734ac04",
            "712b181a9138445893edf51b9e32d003",
            "bcca7a7c463942ec811358413ff1ec77",
            "0d37948d4ad942069064476a99076707",
            "b513e0a403b74191b4bac698ecdb9c25",
            "56caba84a5fb46fcb210dda0bb474577",
            "8e7cf019480747768090c838781d1712",
            "15dcb7b3a28345b49c2f5dc638196cce",
            "a93d84b0d4ff4aa8a9f9fb50edbce2c2",
            "ba541533e6d64ac4b97689f14d9682fc",
            "f2a7303730f1499583e84a0aad789114",
            "28e126392b5a4a0fad4bdbc13f30883c",
            "63a1d5ae21cd4be4b5a34177916992bb",
            "42e699c717ce4e0bbce5e8a298552faf",
            "112afb0733a7441ca6dd4850e81566b1",
            "1a12cd402e654b4a842736e830f9b553",
            "be995b49d1d04fd8b1b5cb7f2135f3bf",
            "bb418f25644847579af5634cdc1dee6c"
          ]
        },
        "id": "2EisvBe52ZHO",
        "outputId": "c231f8e9-4d0a-4241-91cb-15debb571741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:huggingsound.speech_recognition.model:Loading model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6399a0aaaba4199bd17bdb3f4c4c105"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bba9fdaa4f334a1b9b3eb244f7749042"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-english were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-english and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/262 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d79e7c909fda4fbf972494a16b7e6d8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/300 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e42bf5d388064b19b2f1b0ebfbeae4c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15dcb7b3a28345b49c2f5dc638196cce"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = SpeechRecognitionModel(\"jonatasgrosman/wav2vec2-large-xlsr-53-english\", device = device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX4o4edBE_7g"
      },
      "source": [
        "OUT OF MEMORY (OOM) error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqmMi7VMq3kq"
      },
      "source": [
        "# Audio Chunking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47leIDcR1LsQ"
      },
      "outputs": [],
      "source": [
        "import librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lm67x4AX3L57"
      },
      "outputs": [],
      "source": [
        "input_file = '/content/ytaudio.wav'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NGzeYGr3IZA",
        "outputId": "fe53dab3-de73-4d7b-adef-4a3d10a784e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16000\n"
          ]
        }
      ],
      "source": [
        "print(librosa.get_samplerate(input_file))\n",
        "\n",
        "# Stream over 15 seconds chunks rather than load the full file\n",
        "stream = librosa.stream(\n",
        "    input_file,\n",
        "    block_length=15,\n",
        "    frame_length=16000,\n",
        "    hop_length=16000\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmlYH6ag32bj"
      },
      "outputs": [],
      "source": [
        "import soundfile as sf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yj1wf18l3QJJ"
      },
      "outputs": [],
      "source": [
        "for i,speech in enumerate(stream):\n",
        "  sf.write(f'{i}.wav', speech, 16000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTMcAuRgH3DI",
        "outputId": "0fef9802-731b-4800-d1bb-ab8fae1effc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "105"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5H4Uyoy9jF9"
      },
      "source": [
        "# Audio Transcription / ASR / Speech to Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8a8Mr4R6ndX"
      },
      "outputs": [],
      "source": [
        "audio_path =[]\n",
        "for a in range(i+1):\n",
        "  audio_path.append(f'/content/{a}.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spXDc1r88RPn",
        "outputId": "0403b913-1892-4aaa-e052-35d3ce46a3e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/0.wav',\n",
              " '/content/1.wav',\n",
              " '/content/2.wav',\n",
              " '/content/3.wav',\n",
              " '/content/4.wav',\n",
              " '/content/5.wav',\n",
              " '/content/6.wav',\n",
              " '/content/7.wav',\n",
              " '/content/8.wav',\n",
              " '/content/9.wav',\n",
              " '/content/10.wav',\n",
              " '/content/11.wav',\n",
              " '/content/12.wav',\n",
              " '/content/13.wav',\n",
              " '/content/14.wav',\n",
              " '/content/15.wav',\n",
              " '/content/16.wav',\n",
              " '/content/17.wav',\n",
              " '/content/18.wav',\n",
              " '/content/19.wav',\n",
              " '/content/20.wav',\n",
              " '/content/21.wav',\n",
              " '/content/22.wav',\n",
              " '/content/23.wav',\n",
              " '/content/24.wav',\n",
              " '/content/25.wav',\n",
              " '/content/26.wav',\n",
              " '/content/27.wav',\n",
              " '/content/28.wav',\n",
              " '/content/29.wav',\n",
              " '/content/30.wav',\n",
              " '/content/31.wav',\n",
              " '/content/32.wav',\n",
              " '/content/33.wav',\n",
              " '/content/34.wav',\n",
              " '/content/35.wav',\n",
              " '/content/36.wav',\n",
              " '/content/37.wav',\n",
              " '/content/38.wav',\n",
              " '/content/39.wav',\n",
              " '/content/40.wav',\n",
              " '/content/41.wav',\n",
              " '/content/42.wav',\n",
              " '/content/43.wav',\n",
              " '/content/44.wav',\n",
              " '/content/45.wav',\n",
              " '/content/46.wav',\n",
              " '/content/47.wav',\n",
              " '/content/48.wav',\n",
              " '/content/49.wav',\n",
              " '/content/50.wav',\n",
              " '/content/51.wav',\n",
              " '/content/52.wav',\n",
              " '/content/53.wav',\n",
              " '/content/54.wav',\n",
              " '/content/55.wav',\n",
              " '/content/56.wav',\n",
              " '/content/57.wav',\n",
              " '/content/58.wav',\n",
              " '/content/59.wav',\n",
              " '/content/60.wav',\n",
              " '/content/61.wav',\n",
              " '/content/62.wav',\n",
              " '/content/63.wav',\n",
              " '/content/64.wav',\n",
              " '/content/65.wav',\n",
              " '/content/66.wav',\n",
              " '/content/67.wav',\n",
              " '/content/68.wav',\n",
              " '/content/69.wav',\n",
              " '/content/70.wav',\n",
              " '/content/71.wav',\n",
              " '/content/72.wav',\n",
              " '/content/73.wav',\n",
              " '/content/74.wav',\n",
              " '/content/75.wav',\n",
              " '/content/76.wav',\n",
              " '/content/77.wav',\n",
              " '/content/78.wav',\n",
              " '/content/79.wav',\n",
              " '/content/80.wav',\n",
              " '/content/81.wav',\n",
              " '/content/82.wav',\n",
              " '/content/83.wav',\n",
              " '/content/84.wav',\n",
              " '/content/85.wav',\n",
              " '/content/86.wav',\n",
              " '/content/87.wav',\n",
              " '/content/88.wav',\n",
              " '/content/89.wav',\n",
              " '/content/90.wav',\n",
              " '/content/91.wav',\n",
              " '/content/92.wav',\n",
              " '/content/93.wav',\n",
              " '/content/94.wav',\n",
              " '/content/95.wav',\n",
              " '/content/96.wav',\n",
              " '/content/97.wav',\n",
              " '/content/98.wav',\n",
              " '/content/99.wav',\n",
              " '/content/100.wav',\n",
              " '/content/101.wav',\n",
              " '/content/102.wav',\n",
              " '/content/103.wav',\n",
              " '/content/104.wav',\n",
              " '/content/105.wav']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "audio_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYLKuZ1g2kmL",
        "outputId": "1b823f26-6ccf-4412-96fe-318c911a30ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 106/106 [23:23<00:00, 13.24s/it]\n"
          ]
        }
      ],
      "source": [
        "transcriptions = model.transcribe(audio_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbzcKziD9aYx"
      },
      "outputs": [],
      "source": [
        "full_transcript = ' '"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2Vi7kXw2xGo"
      },
      "outputs": [],
      "source": [
        "for item in transcriptions:\n",
        "  full_transcript += ''.join(item['transcription'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LKBXZrk5ima",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e501fb7-a127-4e8c-83dd-eb205b549212"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20516"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "len(full_transcript)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = full_transcript"
      ],
      "metadata": {
        "id": "JxORQJxmVmWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwjCzvW1YcNX",
        "outputId": "0242b7b5-1ff1-4094-88eb-5d8b0d6fff15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " congratulations to you mr ragowin for that thank you so much for joining us overteahe everybody how are youam not hearing this at all it is like a postlancha energy downear or somethinglet's hear it arygays a wakeall right you bet ter be because we have a superstar guest her you heard the forty-one million dollars i didn'tontanyi she said after tatoasks for about forty million dollars from by the end of this conversationbut let' get started i want introduced evek anpratyush's co-founder was not herewe wanted to start with playing a video or of what open hearthe does encourage all of you to go to the website surround and check it outbtemest by introducing ak's deal friendhe is vey very modest one of the most modest guys that i know but his personal journey k youv been phd from cannigmilin you souded and sold the company to magma and andi moved back to india from bot invallesame day actually in yuben in india for the last sixteen years and hamost people don't knows urjonia adhar he spent thirteen years selflessly at adar nobodywoud have heard of himbuhe was a pioneering technology visionary behind  which we all take for granted today please give it honestly when i think of selfless service truself-ervice always ting oand since then he also was an ifo bahret which wegonto touch on where he met prateosh's other co-founder praducephl from itachtzuric he was iibmresearch was at microsoft research playing a key role  faculty tymaras and aphabatothat's a little brief introduction about them these guys are modest modest engineers so they don't toot their own  ifor toting in this case  jump righton about the moneyfunding forty onmillion buxmen that's a lot of money every entreprener hear saying whathelguys these guys do what did they investircy to write such a big checkthink its ithink it's a triend of new triend of what's going on in india i think that for the very first timei think the investors have looked at youno let's try and build somingpack out of the country and let's try to figure out how to build something as a foundational technology the country and that's really wats wats really exciting yoithink that about  balabosmentioning for but fifteen years i've been kind of working in kind of both digital public infrastructure and kind of non-profit kind of things tis whole thing of generateway came aboutok how can i actually make a difference in  space and i said maybe thisis the opportunity to actually come out any build somethe only way that we realis that you can do it is actuallytheprivate sectorithink t when wewent out there and said we want to build something which is a continurghtfundamentally hequestion isthe reason whatwe want to do aserver mayiis we want to basically make generaavailable and accessible to  people in the country and that's that's the intntand when we said that we want to do this there was a resodance in the investment community and i think its ich a responsibility to rarely to showsometing like this can be built out of india so we see that as  confidence and a responsibility and ialso hope it's a trend you know that there are many more people like like us who are backed because if you're locte maybe it'sarge number in indian contexts but in te global context i think there just thereshould be many may more entrpreners who are back to do things in indiai want to come back to mnymore entrpreners obviously oo s abouts kutrim we come back to that question but again forty-one million dollars all of what you said two million dollarthat's a good namont of money for  starkup which inall which has not yet built anythingwhat are yugondo with all this moneyi can sell her problemi an  perfect solution for the power think in he last week i've got lots of cors ofloods of peopletell me how ii know your firsti'm on the front of achonestly i think the key thing in this is is to putting together an amazing team and we actually have an amazing team but we believe that it is talent that will drive this kind fthing oit i to get get key talent and of course the other thing is compute this is extremely expensive compute wie to actually do these kinds of things and i think that those are the two primary things that that reuce thscomputing in my own head as an entprener talent ok you've lik twenty-fifteen people how much aryou paying disguise tls wot watuguase actually builtwtis open-heartwould yo explain openheartly to many people here who might not have nown know about itso i think openhearty s fetival right we come from personally come from topen source ecosystm fropi ecosystso webelieve that for this work we need the ecosystem to be successful and as a result of that one of the first things we did was e there are these open-source large-language models that exist right everybody knows about the lamaamily fometa are others like mbunch of open source ino large language modelsand then we said is there any way that take an existing opensource model and teach itanguae ilsis really unowhat we ie whatwsycan wedo so like thatand i relative flugal way of of actually making models euroa work in ndiverse languages because the truth is still today the amount of dati knowledge it i still english dominates these things i think that how do you actually take and make it understand any languagenderstandin indian context and all of those thins actually a in an efficient way therefore this was an attempt tothatand aits openartis s currently based on lama seven million model but willbe releasingmore models in different languages different sizes things like that as part of this as part of t series of course you know we will be building further models on those doing other things tactually and weill also have any points that people can uif it i definitely tat people can can cn uehis thats that's the essence of of whoenhappyisso what does it mean to people in audience here either doing their own starteps or business orodevelopers how should they look at open i ithink the way you located is that wbone of important things that we're doing is not justilding models weare o going building platform a platform for developers where you can actually use accombination of various different kinds of models  which are from ase some which are open source som which may not be open source nctly to at pulled together and figure out how to deploy generative air applications at scale and understand and evaluate their performance in an efficient manner and a something that we're planning o withyxcoblemonths will becoming out there it will be available to developers but of course those who want to start with the open source aquetat of course please go ahead and do that as wellthat's phenomenalmbut how does it compare to open-air itself or googlesee at least the thinks that weare doing now right one ohthings that when we thought about abuilding servam we said we want to build a full ssk generatcompyfferent pele understanding of ulse tackes bat we needoknow how to train models from scratchwe need o know how to kind of figure out how to deploy models to solve real world use casesand we nedplay in the ecosystem to make sure that we can actually deploy populscale applications right-so wewer thinking about all of these things but still the models we were talking about are unofairly small models tare fairysmall model rigte sevento may be up to seventyind of range pretocupar while these models-like openai and gugla are alreay much bigger modelanwe wantunderstand the techniques and be able to build thatmuscle todo all of these things mak omake it available to people houh those models are think tthere is space for all of those things and i think i'n srter was talking about earlyear in theday we believe that these smaller models can do kind of domain specific tas extremely well probably better nthe larger models and that is rearely one of the key areasnhe value of these kinds of things rightweare not aiming in these moseto models to build any agi toes not goalgare are goalists to make things that work extremely well for domain specific usecases orinceaccessibility through language rovc all ofuique to india but what is unique about indiaanyting especially in our ecosystem that makes small model focused with indian languagess better for more suitad for our problemsso i think tatthere are quite a few things that are unique about india the first thing is i think that we are voice first nations therefore i think voce has to be thefor do thingsthe r  of course india is extremely zacost-conscious nfrom a class perspective nt i would say that there are lots of interesting usecases where you can usen incostructure works depending on your application but when you want to scale things to a massive level and make it worth then then you have to figure out hmall models work soe that is also specific to indiaird hing which is specificis reallthe success that india has had in building all this digital public infrastructure when you add the aii layer on top of it then you can actually et dramatic dramaic mulmeditorial effects based ontoitiks that's a phenomenal point s like dpto the power of air almost in some ways and as part of other building other no better person than you so in sommary what i'm hearing is small modelsspecialized trained-with indic-specific language data suited for indian problems at compelling caus point will be suited for wnot solving some world auautonomous vehicles or some complex problem weresolving some basic problemscifically focused with onvoice with multiple languages tis what oucea as the future praphacing this crectyi think that certainly voice and indian languages important part of our strategy but we will be building tommodels to solve various other kinds of problems as well that 's not just limited to think indifferent domains working efenedomains making building things based on unique data thatenterprises have hs like ein that will also loocatefairoffso coming back to elephant in the room funintended with open hathi what about barby shakerwal and cruthrimwhat is your take on thet i think it's great i think it's 's wonderful right abad the fact thatthe technology  is so important that we need multiple people working on it te fact that there are other people thinking is actually validates that this is an important problem to be solvedthink we needeverybody come together and do that so i really welcome that i think it's it's great and i think that ther'll be different people will have different takes as to how to solve this kind of problem and an hopefully as a result of that the entirecosystembenefitonmore question a then i wantto talk about some of the predictions that you've boldly made so wke iusually ask people about audio think the future will beverybody usually hedges i ask  what youthink is gonto happen by december twenty-twenty-fourat doyou sittin in this room one year later we can expect and he made three bold predictions oi wanto talk about that before theone last questionwhat are the top three applications utyou think are relevant for indiayou'ld see kot medicalquick summary what is ist ollytingtetop tree apps are for india for so i think that set things like education and medicular clearly areas where where i think things can can be labolatthe whole idea of all th kind of rdipi aspect of it is another major application where things can happen and here i'm bi country specific workand i think the whole idea which rather also talked about was to be a concept of softwareithink that c we have a very large software industry and and how to reimagine those things in this context is also something that's kirlygas ready for bkragwan's bold predictionsno i'm not hearing any thit's like a big deal he's like on of the smartest guys that i know he wants to make three predictions you'd want to hear itsoi askd him what o you think year laer what you tink we can expecthe came up with threegs ausually people give very bly answers when you ask questions like this because they don't want to be caught wrongnoks boldso he basically said three things list out three things andis ask him about itso oonhe saysi would prefer to talk to an automated customer service than a real personbecause they'll geve me a better answersth ralwen's prediction onenumber two is that when everybody is talking about a jpyu shortagethe wague predicted theil ba pu glutin india keeping ther btoo much on a hmedia k tis a good time anumber three which was extremely unexpected he said some companies will suddenly diethee are not what i expectedquickly taught about each of them wi ise just oopertis and then will throw the first open audience questions soi don't think i quite said it e etrn interesting but i think the first thing that we said is i think that and i don't think ithink there will come a time when you knowinin areas of customer service ecetra when you want to do someing very specific today you now when yoll when you call some kind of a bot you actually endup you mostly try to disconnect the call are extremely ubsetito abotbut i think there will come a time i'mpredicting issooner than later that you will actually get better responses from bot than wat he human representative at least be average human representative that you could talk tocood giv and i think ththat's jt just said thtthere willcome at time where you know it's not a human tear talking to but it's probably more likely to solve your intent human fsttithink t could happendefinitely controversial wllwhat about pw glutont ik sothink the fact that there is a tremendous shortage right nowi think that shortage will east because how the cycles of things go right whenwhe the fact that there wes such a severe shortage last year unobally caused a number of different players to to ramp up invarious kinds of forms ithink t'll always go in a cycle but find out that there are many many more interesting problems that people will be able to solvestill remywe were at ageneevent in inbangalor and wewere talking to people and we said you now how many people have access to you no a four-ay hundred this was the question that i asked and nobody in the rom an these are all extremely enthusiastic genealnobody had access a i think that thing is going to change you will be able to get these kinds of things and people who want to hacg and do things will have access to these higs atwithout write major hccheckbek is also a semi-conductor guy before he went into az iwould tk predictionvery seriously i owwantto sell myai would not do that butthat's not what i saidblame you forthe third one is pretty strange in our companies albourne companies die but you say some companies will suddenly diewhat does that meanink the interesting thing is and ithink icomes backto the fundamental nature ofea is a tool right and you have to use that and you have to use that within your business processrighthow a is being used  what's gon happen is this iswit wtside uintoms of yupeople they said that the people who laverage ai will e more effective than those who don't laverage aaiand that will sto for organizations also organizations that aveage ai fundamentally in their core business processes will be more effective than those who don'ttithink that's the you won't know the difference until one day it becomes too obvious and it would belate and i think that's the reason why everybody needs to think about what it means for your business because youl everything will be fine everything will be find han one day somebody in yor either either's either or competiteyour space or somebody brand yu coming into your space will b re-imagining your business process completely and at that stage you'll find that ts t's a ver ig very tall younmountain to climb and that's why i think it'simportant for both people and entities to think about how theyll upgrade themselves or they ill modify their s proat's a y nonsanserveerybody  asania businessshould reallybout it because life will be the same en cudtenly curteinly ba step change few more questions but i'm sure the audience as a lot of questions for you so howgow we doing on timesomokquestion o love to is that a mite that began passalathank you my nemiskartic i work for iservice industryso you are saying that youare working on s fine dun  on top of lamamy basic question fundamental question is we don't have a foundational model for india oste models are basically using english ar those kinds of things for el andrew was talking about the tocanizers and things like that so are you working on anythig like that or youoyou want touse mostlythe existing models and run ontop of itorgoquest on youae cherry question for imno i ink the interesting thing is that if you look at we have actually a blog on this on our website i think one of he things that wactuallybuilt customized ocanizer which actually fundamentally changes the cost of some of these generations in indian languages andi think that werwe're not testfine toni we're actually weare leveraging the existing taininwer doing what's known as continual free-training whch actuallybut having said tyou now i think when we have to figure out where is the data to train an extremely large motol from scratch and some of those things are gs which will happenover timebut think hat think yes i think that wewill doing various kinds of things but the interesting thing is that if i want to change the accessibility proglem with an existing open source mottel how do ido that and te problem that weave that we think we absolved and sequentby the heart of this open arty cit is excetedly well explained in the blog even i could understand itam presured i worked for a fintec companyquestiounlike chinaw never had a consumerfacing application coming out from india and in beban web to creptuenal why do you think it willod different this time ilike eicauswilld dipa and other things will serve the same purpose but the great fireworl did in china or rooting like inbecause aai is a strategic sector no outside countyork in nasa projects mayall n contact will go to thembut exectly s the mothair for an indian companyso k quis i dont know the answer to these questions ithink it's difficult to predict but i do believe repeating that te combinatorial effect of being using genea at a large scalein additionalong with tdpai work at pupdan in india will have people i think thaints intent is that people need to be able to use it and they will vote by things that are useful for themifdoesntyou'r writhink tat we have to figure out what is the mechanism of delivery of slight in boha where do indians consume so sorry but were out of tewllbouiesohe would be able to answer the question out ime oon lacan icjust takeon thank you thank you im anihothurry i'm from isbir business school good that i got a chance to ask you this question during lunchtime they were a few ofor educationists whom wewere talking about one from school and we are from tmbia institutions wthinking of these present-generations how do we get them into what you are doingthere is one thing tahave been regularlyconcentrations that they're working on but artificial intelligence and getting inosgetting them into their academics and making them a part of it is very important including trainers who train themmaking them future ready into what youare doing is amazingspeedithwhich itis growing it is calling for a lot of training that needs to be donecan you from your angle throw some light on how we could make them future ready how these people wrwhoare management graduates and from schools who are comegohow do we get into this part of he technology that you spoke aboutthis really a challenge because i think everyone will need to understand at some level what this technology does and i think that we have to redink how we get everyone into hthis kind of education hasto be at many different levels right there are from a core set of having people who are extremely good at there yu don't need as manybut then there are basically vast numbers of people who can actually leverage biestols by the way the most important thing about an rivirates part of what makes an alalem interesting is that how you use it yourrmilege various yunderstand how to actually lavage this in an interesting way someing thatwidely teach many many people because asking thigs i the rightway right kindof applications will make ausereference to how people can eversea st thank you very much very good luck to sarmom and good luck to india think its goingno be alarde rine on the shoulder thank thanks ballerthankyou mr ragovenn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(OR)"
      ],
      "metadata": {
        "id": "7vi4J0X0Zdjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing libraries**"
      ],
      "metadata": {
        "id": "yonYwIHNYof0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLkjS8CIYt_J",
        "outputId": "9b76d422-b7d8-4dfa-8a4e-f7ee8182354f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytube\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgr8Lzt6X_5z",
        "outputId": "adf1ef07-ebfd-4235-edbd-b5b772e04fb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m724.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytube\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "from IPython.display import Audio, display\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "n7R3evldYwdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Downloading the youtube video and Converting into audio**"
      ],
      "metadata": {
        "id": "h88iXBGDXj9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to download video and extract audio\n",
        "def download_and_extract_audio(youtube_link, output_path):\n",
        "    #Downloading the Youtube Video\n",
        "    yt = pytube.YouTube(youtube_link)\n",
        "\n",
        "    # Filter the available streams to include only audio streams, and select the first one\n",
        "    video = yt.streams.filter(only_audio=True).first()\n",
        "\n",
        "    # Download the selected audio stream and save it to the specified output directory with the filename 'audio'\n",
        "    video.download(output_path=output_path, filename='audio')\n",
        "\n",
        "    return output_path + '/audio.mp4'"
      ],
      "metadata": {
        "id": "-7Tjrh31Xox-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Specifying the youtube Link and directory to store the extracted audio**"
      ],
      "metadata": {
        "id": "rsDvpsP9XQIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "youtube_link = \"https://www.youtube.com/watch?v=Sby1uJ_NFIY\"\n",
        "output_path = \"./\"\n",
        "audio_file_path = download_and_extract_audio(youtube_link, output_path)\n",
        "print(\"Audio extracted successfully:\", audio_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p88GZiZHXQ3j",
        "outputId": "06c37233-5207-4326-9a1c-4e34d8ebf119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio extracted successfully: .//audio.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**pipeline for automatic speech recognition (ASR) using Hugging Face's Transformers library**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rWaQr7FqW_fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the pipeline\n",
        "whisper = pipeline('automatic-speech-recognition', model='openai/whisper-medium')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Irh25MxNXGiK",
        "outputId": "0b5ece3c-a305-4268-afd0-7c7ca5f9e513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Translate speech to text**"
      ],
      "metadata": {
        "id": "oWF54YS3kQJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transcript = whisper('audio')"
      ],
      "metadata": {
        "id": "_HIU2uWkiS1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56aIcsV9bIhp",
        "outputId": "e4398472-46b6-4b5e-9c5a-a77fc618b608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': \" Congratulations to you Mr. Raghavan for that. Thank you so much for joining us. Over to you. Hi everybody. How are you? Okay, I am not hearing this at all. This is like a post-lunch energy downer or something. Let's hear it. Are you guys awake? Yes. Alright. You better be because we have a superstar guest here. You heard the 41 million dollars and I didn't hear honestly anything she said after that. So we're going to ask for about 40 million dollars from him by the end of this conversation, okay? But let's get started. I want to introduce Vivek and Pratyush, his co-founder who's not here. We wanted to start with playing a video of what OpenHati does. I encourage all of you to go to the website, savrom.ai, and check it out. But let me start by introducing Vivek. Vivek is a dear friend, and he's very, very modest. One of the most modest guys that I know. But his personal journey, Vivek, you've got a PhD from Carnegie Mellon. You started and sold the company to Magma. And Vivek and I moved back to India. We were both in the valley on the same day, actually. And you've been in India for the last 16 years. And what most people don't know is your journey at Aadhaar. He spent 13 years selflessly at Aadhaar. Nobody would have heard of him, but he was a pioneering technology visionary behind Aadhaar, which we all take for granted today. So please give it up. Honestly, when I think of selfless service, truly selfless service, I always think of Vivek. And since then, he also was at AI for Bharat, which we're going to touch on, where he met Pratyush's co-founder. Pratyush had a PhD from ETH at Zurich. He was at IBM research. He was at Microsoft research playing a key role and a faculty at IIT Madras and at AI for Bharat. So that's a little brief introduction about them. These guys are modest, modest engineers. So they don't toot their own horn. So forgive me for tooting their horn in this case. But But let's jump right in about the money, funding. 41 million bucks man, that's a lot of money, right? Every entrepreneur here is saying, what the hell did these guys do? What did the investors see to write such a big check? No, I think it's a trend, a new trend of what's going on in India. I think that for the very first time, I think the investors have looked at, you know, let's try and build something deep tech out of the country and let's try to figure out how to build something as a foundational technology out of the country and that's really what's what's really exciting you know and I think that about you know as as as well I was mentioning for the past 15 years I've been kind of working in kind of you know both digital public infrastructure and and and kind of a nonprofit kind of things and but when this whole thing of generative AI came came about, we said, okay, how can I actually make a difference in this space? And I said, maybe this is the opportunity to actually come out and really build something and the only way that we realize that you can do it is actually in the private sector and I think that's the end. Then we went out there and we said we want to build something which is a continuation, right? I mean, fundamentally the question is the reason of what we want to do at from AI is we want to basically make generative AI available and accessible to the people in the country. And that's the intent. And when we said that we want to do this, there was a resonance in the investment community. And I think it's a responsibility to really to show that something like this can be built out of India. So we see that as confidence and a responsibility. And I also hope it's a trend that there are many more people like us who are backed because if you look at it maybe it's a large number in the Indian context but in the global context I think there should be many, many more entrepreneurs who are back to do things in India. I'm going to come back to the many more entrepreneurs. I'm obviously going to ask you about Bhavesh's Kruthram. So we're going to come back to the question but again $41 million, all of what you said, you know, $2 million, you know, that's a good amount of money for a startup which, you know, which has not yet built anything. What are you going to do with all this money? I can solve the problem. I can have a perfect solution for the problem. I think in the last week I've got lots of calls from lots of people telling me how I can do it. No, but... I know you first, okay? I'll be landed in the country the same day. I'm in front of the queue. No, but but but honestly I think the key thing in this is is to putting together an amazing team And we actually have an amazing team But we believe that it is talent that will drive this kind of thing and so it is it is to get Get key talent and of course the other thing is compute. This is extremely Expensive compute wise to actually do these kinds of things and I think that those are the two primary things that that you know We'd use this for okay I'm computing in my own head as an entrepreneur, talent, okay, you have like 20-15 people, how much are you paying these guys? But okay, we won't touch on that. But let's talk about what you guys actually built. What is Open Hathi? How would you explain Open Hathi to many people here who might not have known about it? So I think Open Hathi is, so first of all, right, we come from, I personally come from the open source ecosystem and also from the DPI ecosystem. So we believe that for this to work, we need the ecosystem to be successful. And as a result of that, one of the first things we did was, hey, there are these open source large language models that exist, right? I mean, everybody knows about the llama family from Meta. They also, there are others like Mistral. There are a bunch of open source, you know, large language models. And then we said, is there any way that they can existing open source model and teach it language skills, right? I mean, and that is really the, you know, what we decide, what we said that can we do something like that? And is this a, you know, relatively frugal way of actually, you know, making models, you know, work in diverse languages? Because the truth is still today, I mean, if you look at the amount of data and knowledge, it is still English dominates these things. And I think that how do you actually take and make it understand Indian language, understand Indian context and all of those things in actually a in an efficient way. And therefore this was an attempt to do that. And it's a open hearty is you know is currently based on the llama seven billion model but we'll be releasing many more models in different languages, different sizes and things like that as part of this as part of this series. And of course you know we will be building further models on those and doing other things to actually and we'll also have endpoints that people can use so that it's not, it's definitely something that people can use to things and that's the essence of what this OpenHarp is. So what does it mean to people in the audience here who are either doing their own startups or a business or developers, how should they look at OpenAI? Sorry, Sarvam, not OpenAI. No, no, I think the way you look at it is that one of the important things that we are doing is we're not just building models. We are also going to be building a platform, a platform for developers where you can actually use a combination of various different kinds of models, some which are from us, some which are open source, some which may not be open source, and actually to actually pull together and figure out how to deploy generative AI applications scale and understand and evaluate their performance in an efficient manner and that's something that we are planning to do at this and this platform is you know in the next couple of months will be coming out there it will be available to developers but of course those who want to start with the open source things and hack for that of course please go ahead and do that as well. That's phenomenal but how does it compare to OpenAI itself or Google? See at least the things that we are doing now. One of the things that when we thought about building Sarvam, we said we want to build a full stack generative AI company and different people have an understanding of full stack is that we need to know how to train models from scratch. We need to know how to kind of figure out how to deploy models to solve real world use cases. And we need to play in the ecosystem to make sure that we can actually deploy population scale applications So we were thinking about all of these things. But still the models we were talking about are fairly small models. They are fairly small models, right, in the seven to maybe up to 70 billion kind of range we're talking about. While these models like OpenAI and Google are obviously much bigger models, right? But we want to understand the techniques and be able to build that muscle to do all of these things, to make it available to people. Now those models are, I mean, as I said, I think that there is space for all of those things and I think as even Sridhar was talking about earlier in the day, we believe that these smaller models can do very, I mean, many, many kind of domain specific tasks extremely well, probably even better than the larger models and that is really one of the key areas. And so therefore the value of these kinds of things, right, we are not aiming in these set of models to build any AGI. That's not our goal here. Our goal is to make things that work extremely well for domain specific use cases or increase accessibility through language and all of those kinds of things. And obviously all of this unique to India. But what is unique about India? Is there anything special in our ecosystem that makes small models focused with Indian languages better for, more suited for our problems? So I think that, I mean, there are quite a few things that are unique about India, right? The first thing is I think that we are a voice first nation, so therefore I think voice has to be the core to doing things. The other thing, of course, India is extremely, it's a cost conscious country from a cost perspective. Now, I would say that there are lots of interesting use cases where you can use OpenAI and the cost structure works depending on your application. But when you want to scale things to a massive level and make it work, then you have to figure out how small models work. So that's something that is also specific to India. The third thing which is specific to India is really the success that India has had in building all this digital public infrastructure. When you add the AI layer on top of it, then you can actually get dramatic, you know, dramatic, I think, multiplicative combinatorial effects based on doing things like that. That's a phenomenal point. Like, you know, it's like DPI to the power of AI almost in some ways. And as a part of building Aadhaar, no better person than you. So in summary, what I'm hearing is small models specialized with, trained with Indic-specific language data suited for Indian problems at a compelling cost point will be suited for us. autonomous vehicles or some complex problem, we're solving some basic problems specifically focused on voice with multiple languages. That is what you see as the future. Am I paraphrasing this correctly? No, yeah. So I think that certainly, I mean, voice and Indian languages are an important part of our strategy, but we will be building custom models to solve various other kinds of problems as well. That's not just limited to, I think, in different domains, working different domains, making building things based on unique data that enterprises have and things like that. So that's something that we'll also look at. Fair enough. So coming back to the elephant in the room, no fun intended with open Hathi, what about Babesh Akarwal and Kruthrim? What is your take on that? I think it's great. I think it's wonderful, right? I mean, the fact that the technology AI is so important that we need multiple people working on it. The fact that there are other people thinking is actually validates that this is an important problem to be solved. And I think that we need everybody to come together and do that. So I really welcome that. I think it's great. And I think that there will be different people will have different takes as to how to solve this kind of problem. And hopefully as a result of that, the entire ecosystem benefits. One more question and then I want to talk about some of the predictions that you've boldly made. So Vivek, I usually ask people about what do you think the future will be and everybody usually hedges. I asked Vivek, what do you think is going to happen by December 2024? What do you think sitting in this room one year later we can expect? And he made three bold predictions. So I want to talk about that. Before that, I have one last question. What are the top three applications that you think are relevant for India? You heard Sridhar talk about medical. What, you know, any quick summary, what is, what do you, what do you think your the top three apps are for India for AI? So I mean I think that as you said things like education and medical are clearly areas where I think that things can can be leveraged. The whole idea of all these kind of the DPI aspect of it is another major application where things can happen in and here I'm talking about country specific work and I think the whole idea which Sridhar also talked about was the the concept of software right and I think that and clearly we have a very large software industry and how to reimagine those things in this context is also something that's going to be big. Fair enough. Are you guys ready for Vivek Raghavan's bold predictions? Yes? No? I'm not hearing any yes sir. This is like a big deal. He's like one of the smartest guys that I know. He wants to make three predictions. You don't want to hear it? All right. So I asked him, what do you think, you know, a year later, what do you think we can expect? And he came up with three things and usually people give very blah answers when you ask question like this because they don't want to be caught wrong. Not Vivek. Vivek is bold. So he basically said three things and I'm going to list out the three things and then he's asking about it. So number one, he says, I would prefer to talk to an automated customer service than a real person because they'll give me a better answer. So that is Vivek Ragwan's prediction number one. So number two is that when everybody is talking about a GPU shortage, Vivek predicts that there will be a GPU glut in India. He thinks there will be too much GPU. So if you want a short NVIDIA talk, this is a good time. And number three, which was extremely unexpected, he said some companies will suddenly die. So Vivek, these are not what I expected. So do you want to quickly talk about each of them, why you just came up with these and then we'll throw the open for audience questions. So I don't think I quite said it the way that Pallav is kind of making, but it's interesting. But I think the first thing that we said is I think that and I don't think that this is I think there will come a time when in areas of customer service, et cetera, when you want to do something very specific. Today, you know, when you call some kind of a bot, you actually end up, you mostly try to disconnect the call or, you know, you're extremely upset that you're talking to a bot. But I think that there will come a time, and I'm predicting it is sooner than later, that you will actually get better responses from the bot than what the human representative, at least the average human representative that you could talk to could give. And I think that that's just a, I just said that there will come a time where you know it's not a human you're talking to, but it's probably more likely to solve your intent than the human person. That's just something that I think that could happen. Okay, definitely controversial, but we'll let it go. What about the GPU glut? No, no, yeah. So I don't think that, so I think that the fact that there is a tremendous shortage right now, I think that shortage will ease because that is how the cycles of things go, right? When, you know, I think the fact that there was such a severe shortage last year, you know, basically caused a number of different players to ramp up in various kinds of forms and I think that that will always go in a cycle. But you may find out that there are many, many more interesting problems that people will be able to solve. I still remember you know, we were at a Gen.AI event in Bangalore and we were talking to people and we said, you know, how many people have access to, you know, four A-hundreds? This was the question that I'd asked and nobody in the room and these are all extremely enthusiastic Gen.AI people and nobody had access and I think that thing is going to change. You will be able to get these kinds of things and people who want to hack and do things will have access to these things without having to write a check. Vivek is also a semiconductor guy before he went into Aadhaar. So I would take his predictions very seriously. So I don't know what I will do. I'm going to sell my NMEDIA stock. I would not do that. But that's not what I said. I want to blame you for this if it goes up. But the third one is pretty strange. Companies are born, companies die. But you said some companies will suddenly die. What does that mean? No, I think, see, I think the interesting thing is, and I think that it comes back to the fundamental nature of AI. AI is a tool, right? And you have to use that. And you have to use that within your business process, right? And how AI is being used. And so what's going to happen is that, I mean, I think this is true with, you know, when someone said in terms of people, they said that the people who leverage AI will be more effective than those who don't leverage AI. And that will stoop for organizations also. Organizations that leverage AI fundamentally in their core business processes will be more effective than those who don't. And I think that's the thing. And you won't know the difference until one day it becomes too obvious, and it will be too late. And I think that's the reason why everybody needs to think about what it means for your business. Because everything will be fine. Everything will be fine. And one day, somebody in your, either your competitor in your space or somebody brand new coming into your space will be reimagining your business process completely. And at that stage, you will find that it's a very big, very tall mountain to climb. And that's why I think it's important for both people and entities to think about how they will, you know, they will upgrade themselves or they will modify their business processes to, you know, to work out this. That's a very nuanced answer and everybody here who's running a business should really think about it because life will be the same and then suddenly, suddenly something will, you know, then it will be a step change. Vivek, I have a few more questions but I'm sure the audience has a lot of questions for you. So, how are we doing on time? Okay. So, does, okay. does, okay, a lot of questions, so love to, is there a mic that we can pass around? Thank you. My name is Karthik. I work for IT service industry. So you're saying that you're working on LLM, sorry, it's fine-tuned LLM on top of Lama. My basic question, fundamental question is we don't have a fund them foundational model for India most of the models are basically using English or those kind of things for example even Andrew was talking about the tokenizers and things like that so are you working on anything like that or you do you want to use mostly the existing models and run on top of it are you going to ask a good question you have the cherry question for him so no I think the interesting thing is that if you look at and then we have actually a blog on this on our website. I think one of the things that we've built is we actually built a customized tokenizer which actually fundamentally changes the cost of some of these generations in Indian languages and I think that we are not just fine-tuning. We are actually, we are leveraging the existing pre-training but we are doing what's known as continual free training which actually, but having said that you know I think I think that we have to figure out where is the data to train an extremely large model from scratch. And some of those things are things which will happen over time. But I think that, yes, I think that we will be doing various kinds of things. But the interesting thing is that if I want to change the accessibility problem with an existing open source model, how do I do that? And that's the problem that we think we have solved and is going to be the heart of this open-heart series. It's extremely well explained in the blog, even I could understand it. Hi, I'm Prashant. I work for a fintech company. My question is, unlike China, we never had a consumer-facing application coming out from India, and in web one, web two, crypto and all. Why do you think it will be different this time in AI? Because will the BPAI and other things will serve the same purpose what the great fire world did in China? Or do you think, like in NASA, because AI is a strategic sector, no outside country can work in NASA projects. Maybe all government contracts will go to them. What exactly is the moat here for an Indian company? So I think the question is, I don't know the answer to these questions, right? I mean, I think that it's difficult to predict but I do believe and as I'm repeating that the combinatorial effect of being using GenAI at a large scale in addition along with the DPI work that we've done in India will have people and I I think that in the end, the intent is that people need to be able to use it and they will vote by things that are useful for them. And if that doesn't happen, you're right. I think that we have to figure out what is the mechanism of delivery of apps. Where do Indians consume content? That's the question. I'm so sorry, but we are out of time. Vivek will be outside, so he would be able to answer the question. Do we have time for one last question? Can I just take one last? Yeah. Thank you. Thank you. I'm Manish Kothari. I'm from ISBR Business School. Good that I got a chance to ask you this question. During lunchtime, there were a few of our educationists whom we were talking about and we were there was one from school and we are from the MBA institutions. We were thinking of these present generations. How do we get them into what you are doing? There is one thing that they have been regularly that the concentrations that they are working on but artificial intelligence and getting into this getting them into their academics and making them a part of it is very important including the trainers who train them making them future ready into what you are doing is amazing and the speed that with which is growing it is calling for a lot of training that needs to be done. Can you from your angle throw some light on how we could make them future ready how these people who are who are management graduates and from schools who are coming out how do we get into this part of technology that you spoke about? No, so this is really a challenge because I think everyone will need to understand at some level what this technology does and I think that we have to rethink how we get everyone into this and that this kind of education has to be at many different levels, right? There are from a core set of having people who are extremely good at some and there you don't need as many, but then there are basically vast numbers of people who can actually leverage these tools. By the way, the most important thing about, I mean, maybe that's part of what makes an LLM interesting, is that how you use it, your mileage varies by that. And to understand how to actually leverage this in an interesting way is something that we have to widely teach many, many people. And because asking the, you know, things in the right way and having the right kind of applications will make a huge difference to how people can use these tools. Awesome. Thank you. Thank you very much Vivek. Very good luck to Sarvam and good luck to India. I think it's going to be a lot right on your shoulders. Thanks Bala. Thank you Mr. Raghavan.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#taking the value inside the 'text' key to perform semantic chunking\n",
        "transcript=transcript['text']\n",
        "print(transcript)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIkmE9TqxMK3",
        "outputId": "7dd92d82-e42c-49bc-f145-c7c03d201c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Congratulations to you Mr. Raghavan for that. Thank you so much for joining us. Over to you. Hi everybody. How are you? Okay, I am not hearing this at all. This is like a post-lunch energy downer or something. Let's hear it. Are you guys awake? Yes. Alright. You better be because we have a superstar guest here. You heard the 41 million dollars and I didn't hear honestly anything she said after that. So we're going to ask for about 40 million dollars from him by the end of this conversation, okay? But let's get started. I want to introduce Vivek and Pratyush, his co-founder who's not here. We wanted to start with playing a video of what OpenHati does. I encourage all of you to go to the website, savrom.ai, and check it out. But let me start by introducing Vivek. Vivek is a dear friend, and he's very, very modest. One of the most modest guys that I know. But his personal journey, Vivek, you've got a PhD from Carnegie Mellon. You started and sold the company to Magma. And Vivek and I moved back to India. We were both in the valley on the same day, actually. And you've been in India for the last 16 years. And what most people don't know is your journey at Aadhaar. He spent 13 years selflessly at Aadhaar. Nobody would have heard of him, but he was a pioneering technology visionary behind Aadhaar, which we all take for granted today. So please give it up. Honestly, when I think of selfless service, truly selfless service, I always think of Vivek. And since then, he also was at AI for Bharat, which we're going to touch on, where he met Pratyush's co-founder. Pratyush had a PhD from ETH at Zurich. He was at IBM research. He was at Microsoft research playing a key role and a faculty at IIT Madras and at AI for Bharat. So that's a little brief introduction about them. These guys are modest, modest engineers. So they don't toot their own horn. So forgive me for tooting their horn in this case. But But let's jump right in about the money, funding. 41 million bucks man, that's a lot of money, right? Every entrepreneur here is saying, what the hell did these guys do? What did the investors see to write such a big check? No, I think it's a trend, a new trend of what's going on in India. I think that for the very first time, I think the investors have looked at, you know, let's try and build something deep tech out of the country and let's try to figure out how to build something as a foundational technology out of the country and that's really what's what's really exciting you know and I think that about you know as as as well I was mentioning for the past 15 years I've been kind of working in kind of you know both digital public infrastructure and and and kind of a nonprofit kind of things and but when this whole thing of generative AI came came about, we said, okay, how can I actually make a difference in this space? And I said, maybe this is the opportunity to actually come out and really build something and the only way that we realize that you can do it is actually in the private sector and I think that's the end. Then we went out there and we said we want to build something which is a continuation, right? I mean, fundamentally the question is the reason of what we want to do at from AI is we want to basically make generative AI available and accessible to the people in the country. And that's the intent. And when we said that we want to do this, there was a resonance in the investment community. And I think it's a responsibility to really to show that something like this can be built out of India. So we see that as confidence and a responsibility. And I also hope it's a trend that there are many more people like us who are backed because if you look at it maybe it's a large number in the Indian context but in the global context I think there should be many, many more entrepreneurs who are back to do things in India. I'm going to come back to the many more entrepreneurs. I'm obviously going to ask you about Bhavesh's Kruthram. So we're going to come back to the question but again $41 million, all of what you said, you know, $2 million, you know, that's a good amount of money for a startup which, you know, which has not yet built anything. What are you going to do with all this money? I can solve the problem. I can have a perfect solution for the problem. I think in the last week I've got lots of calls from lots of people telling me how I can do it. No, but... I know you first, okay? I'll be landed in the country the same day. I'm in front of the queue. No, but but but honestly I think the key thing in this is is to putting together an amazing team And we actually have an amazing team But we believe that it is talent that will drive this kind of thing and so it is it is to get Get key talent and of course the other thing is compute. This is extremely Expensive compute wise to actually do these kinds of things and I think that those are the two primary things that that you know We'd use this for okay I'm computing in my own head as an entrepreneur, talent, okay, you have like 20-15 people, how much are you paying these guys? But okay, we won't touch on that. But let's talk about what you guys actually built. What is Open Hathi? How would you explain Open Hathi to many people here who might not have known about it? So I think Open Hathi is, so first of all, right, we come from, I personally come from the open source ecosystem and also from the DPI ecosystem. So we believe that for this to work, we need the ecosystem to be successful. And as a result of that, one of the first things we did was, hey, there are these open source large language models that exist, right? I mean, everybody knows about the llama family from Meta. They also, there are others like Mistral. There are a bunch of open source, you know, large language models. And then we said, is there any way that they can existing open source model and teach it language skills, right? I mean, and that is really the, you know, what we decide, what we said that can we do something like that? And is this a, you know, relatively frugal way of actually, you know, making models, you know, work in diverse languages? Because the truth is still today, I mean, if you look at the amount of data and knowledge, it is still English dominates these things. And I think that how do you actually take and make it understand Indian language, understand Indian context and all of those things in actually a in an efficient way. And therefore this was an attempt to do that. And it's a open hearty is you know is currently based on the llama seven billion model but we'll be releasing many more models in different languages, different sizes and things like that as part of this as part of this series. And of course you know we will be building further models on those and doing other things to actually and we'll also have endpoints that people can use so that it's not, it's definitely something that people can use to things and that's the essence of what this OpenHarp is. So what does it mean to people in the audience here who are either doing their own startups or a business or developers, how should they look at OpenAI? Sorry, Sarvam, not OpenAI. No, no, I think the way you look at it is that one of the important things that we are doing is we're not just building models. We are also going to be building a platform, a platform for developers where you can actually use a combination of various different kinds of models, some which are from us, some which are open source, some which may not be open source, and actually to actually pull together and figure out how to deploy generative AI applications scale and understand and evaluate their performance in an efficient manner and that's something that we are planning to do at this and this platform is you know in the next couple of months will be coming out there it will be available to developers but of course those who want to start with the open source things and hack for that of course please go ahead and do that as well. That's phenomenal but how does it compare to OpenAI itself or Google? See at least the things that we are doing now. One of the things that when we thought about building Sarvam, we said we want to build a full stack generative AI company and different people have an understanding of full stack is that we need to know how to train models from scratch. We need to know how to kind of figure out how to deploy models to solve real world use cases. And we need to play in the ecosystem to make sure that we can actually deploy population scale applications So we were thinking about all of these things. But still the models we were talking about are fairly small models. They are fairly small models, right, in the seven to maybe up to 70 billion kind of range we're talking about. While these models like OpenAI and Google are obviously much bigger models, right? But we want to understand the techniques and be able to build that muscle to do all of these things, to make it available to people. Now those models are, I mean, as I said, I think that there is space for all of those things and I think as even Sridhar was talking about earlier in the day, we believe that these smaller models can do very, I mean, many, many kind of domain specific tasks extremely well, probably even better than the larger models and that is really one of the key areas. And so therefore the value of these kinds of things, right, we are not aiming in these set of models to build any AGI. That's not our goal here. Our goal is to make things that work extremely well for domain specific use cases or increase accessibility through language and all of those kinds of things. And obviously all of this unique to India. But what is unique about India? Is there anything special in our ecosystem that makes small models focused with Indian languages better for, more suited for our problems? So I think that, I mean, there are quite a few things that are unique about India, right? The first thing is I think that we are a voice first nation, so therefore I think voice has to be the core to doing things. The other thing, of course, India is extremely, it's a cost conscious country from a cost perspective. Now, I would say that there are lots of interesting use cases where you can use OpenAI and the cost structure works depending on your application. But when you want to scale things to a massive level and make it work, then you have to figure out how small models work. So that's something that is also specific to India. The third thing which is specific to India is really the success that India has had in building all this digital public infrastructure. When you add the AI layer on top of it, then you can actually get dramatic, you know, dramatic, I think, multiplicative combinatorial effects based on doing things like that. That's a phenomenal point. Like, you know, it's like DPI to the power of AI almost in some ways. And as a part of building Aadhaar, no better person than you. So in summary, what I'm hearing is small models specialized with, trained with Indic-specific language data suited for Indian problems at a compelling cost point will be suited for us. autonomous vehicles or some complex problem, we're solving some basic problems specifically focused on voice with multiple languages. That is what you see as the future. Am I paraphrasing this correctly? No, yeah. So I think that certainly, I mean, voice and Indian languages are an important part of our strategy, but we will be building custom models to solve various other kinds of problems as well. That's not just limited to, I think, in different domains, working different domains, making building things based on unique data that enterprises have and things like that. So that's something that we'll also look at. Fair enough. So coming back to the elephant in the room, no fun intended with open Hathi, what about Babesh Akarwal and Kruthrim? What is your take on that? I think it's great. I think it's wonderful, right? I mean, the fact that the technology AI is so important that we need multiple people working on it. The fact that there are other people thinking is actually validates that this is an important problem to be solved. And I think that we need everybody to come together and do that. So I really welcome that. I think it's great. And I think that there will be different people will have different takes as to how to solve this kind of problem. And hopefully as a result of that, the entire ecosystem benefits. One more question and then I want to talk about some of the predictions that you've boldly made. So Vivek, I usually ask people about what do you think the future will be and everybody usually hedges. I asked Vivek, what do you think is going to happen by December 2024? What do you think sitting in this room one year later we can expect? And he made three bold predictions. So I want to talk about that. Before that, I have one last question. What are the top three applications that you think are relevant for India? You heard Sridhar talk about medical. What, you know, any quick summary, what is, what do you, what do you think your the top three apps are for India for AI? So I mean I think that as you said things like education and medical are clearly areas where I think that things can can be leveraged. The whole idea of all these kind of the DPI aspect of it is another major application where things can happen in and here I'm talking about country specific work and I think the whole idea which Sridhar also talked about was the the concept of software right and I think that and clearly we have a very large software industry and how to reimagine those things in this context is also something that's going to be big. Fair enough. Are you guys ready for Vivek Raghavan's bold predictions? Yes? No? I'm not hearing any yes sir. This is like a big deal. He's like one of the smartest guys that I know. He wants to make three predictions. You don't want to hear it? All right. So I asked him, what do you think, you know, a year later, what do you think we can expect? And he came up with three things and usually people give very blah answers when you ask question like this because they don't want to be caught wrong. Not Vivek. Vivek is bold. So he basically said three things and I'm going to list out the three things and then he's asking about it. So number one, he says, I would prefer to talk to an automated customer service than a real person because they'll give me a better answer. So that is Vivek Ragwan's prediction number one. So number two is that when everybody is talking about a GPU shortage, Vivek predicts that there will be a GPU glut in India. He thinks there will be too much GPU. So if you want a short NVIDIA talk, this is a good time. And number three, which was extremely unexpected, he said some companies will suddenly die. So Vivek, these are not what I expected. So do you want to quickly talk about each of them, why you just came up with these and then we'll throw the open for audience questions. So I don't think I quite said it the way that Pallav is kind of making, but it's interesting. But I think the first thing that we said is I think that and I don't think that this is I think there will come a time when in areas of customer service, et cetera, when you want to do something very specific. Today, you know, when you call some kind of a bot, you actually end up, you mostly try to disconnect the call or, you know, you're extremely upset that you're talking to a bot. But I think that there will come a time, and I'm predicting it is sooner than later, that you will actually get better responses from the bot than what the human representative, at least the average human representative that you could talk to could give. And I think that that's just a, I just said that there will come a time where you know it's not a human you're talking to, but it's probably more likely to solve your intent than the human person. That's just something that I think that could happen. Okay, definitely controversial, but we'll let it go. What about the GPU glut? No, no, yeah. So I don't think that, so I think that the fact that there is a tremendous shortage right now, I think that shortage will ease because that is how the cycles of things go, right? When, you know, I think the fact that there was such a severe shortage last year, you know, basically caused a number of different players to ramp up in various kinds of forms and I think that that will always go in a cycle. But you may find out that there are many, many more interesting problems that people will be able to solve. I still remember you know, we were at a Gen.AI event in Bangalore and we were talking to people and we said, you know, how many people have access to, you know, four A-hundreds? This was the question that I'd asked and nobody in the room and these are all extremely enthusiastic Gen.AI people and nobody had access and I think that thing is going to change. You will be able to get these kinds of things and people who want to hack and do things will have access to these things without having to write a check. Vivek is also a semiconductor guy before he went into Aadhaar. So I would take his predictions very seriously. So I don't know what I will do. I'm going to sell my NMEDIA stock. I would not do that. But that's not what I said. I want to blame you for this if it goes up. But the third one is pretty strange. Companies are born, companies die. But you said some companies will suddenly die. What does that mean? No, I think, see, I think the interesting thing is, and I think that it comes back to the fundamental nature of AI. AI is a tool, right? And you have to use that. And you have to use that within your business process, right? And how AI is being used. And so what's going to happen is that, I mean, I think this is true with, you know, when someone said in terms of people, they said that the people who leverage AI will be more effective than those who don't leverage AI. And that will stoop for organizations also. Organizations that leverage AI fundamentally in their core business processes will be more effective than those who don't. And I think that's the thing. And you won't know the difference until one day it becomes too obvious, and it will be too late. And I think that's the reason why everybody needs to think about what it means for your business. Because everything will be fine. Everything will be fine. And one day, somebody in your, either your competitor in your space or somebody brand new coming into your space will be reimagining your business process completely. And at that stage, you will find that it's a very big, very tall mountain to climb. And that's why I think it's important for both people and entities to think about how they will, you know, they will upgrade themselves or they will modify their business processes to, you know, to work out this. That's a very nuanced answer and everybody here who's running a business should really think about it because life will be the same and then suddenly, suddenly something will, you know, then it will be a step change. Vivek, I have a few more questions but I'm sure the audience has a lot of questions for you. So, how are we doing on time? Okay. So, does, okay. does, okay, a lot of questions, so love to, is there a mic that we can pass around? Thank you. My name is Karthik. I work for IT service industry. So you're saying that you're working on LLM, sorry, it's fine-tuned LLM on top of Lama. My basic question, fundamental question is we don't have a fund them foundational model for India most of the models are basically using English or those kind of things for example even Andrew was talking about the tokenizers and things like that so are you working on anything like that or you do you want to use mostly the existing models and run on top of it are you going to ask a good question you have the cherry question for him so no I think the interesting thing is that if you look at and then we have actually a blog on this on our website. I think one of the things that we've built is we actually built a customized tokenizer which actually fundamentally changes the cost of some of these generations in Indian languages and I think that we are not just fine-tuning. We are actually, we are leveraging the existing pre-training but we are doing what's known as continual free training which actually, but having said that you know I think I think that we have to figure out where is the data to train an extremely large model from scratch. And some of those things are things which will happen over time. But I think that, yes, I think that we will be doing various kinds of things. But the interesting thing is that if I want to change the accessibility problem with an existing open source model, how do I do that? And that's the problem that we think we have solved and is going to be the heart of this open-heart series. It's extremely well explained in the blog, even I could understand it. Hi, I'm Prashant. I work for a fintech company. My question is, unlike China, we never had a consumer-facing application coming out from India, and in web one, web two, crypto and all. Why do you think it will be different this time in AI? Because will the BPAI and other things will serve the same purpose what the great fire world did in China? Or do you think, like in NASA, because AI is a strategic sector, no outside country can work in NASA projects. Maybe all government contracts will go to them. What exactly is the moat here for an Indian company? So I think the question is, I don't know the answer to these questions, right? I mean, I think that it's difficult to predict but I do believe and as I'm repeating that the combinatorial effect of being using GenAI at a large scale in addition along with the DPI work that we've done in India will have people and I I think that in the end, the intent is that people need to be able to use it and they will vote by things that are useful for them. And if that doesn't happen, you're right. I think that we have to figure out what is the mechanism of delivery of apps. Where do Indians consume content? That's the question. I'm so sorry, but we are out of time. Vivek will be outside, so he would be able to answer the question. Do we have time for one last question? Can I just take one last? Yeah. Thank you. Thank you. I'm Manish Kothari. I'm from ISBR Business School. Good that I got a chance to ask you this question. During lunchtime, there were a few of our educationists whom we were talking about and we were there was one from school and we are from the MBA institutions. We were thinking of these present generations. How do we get them into what you are doing? There is one thing that they have been regularly that the concentrations that they are working on but artificial intelligence and getting into this getting them into their academics and making them a part of it is very important including the trainers who train them making them future ready into what you are doing is amazing and the speed that with which is growing it is calling for a lot of training that needs to be done. Can you from your angle throw some light on how we could make them future ready how these people who are who are management graduates and from schools who are coming out how do we get into this part of technology that you spoke about? No, so this is really a challenge because I think everyone will need to understand at some level what this technology does and I think that we have to rethink how we get everyone into this and that this kind of education has to be at many different levels, right? There are from a core set of having people who are extremely good at some and there you don't need as many, but then there are basically vast numbers of people who can actually leverage these tools. By the way, the most important thing about, I mean, maybe that's part of what makes an LLM interesting, is that how you use it, your mileage varies by that. And to understand how to actually leverage this in an interesting way is something that we have to widely teach many, many people. And because asking the, you know, things in the right way and having the right kind of applications will make a huge difference to how people can use these tools. Awesome. Thank you. Thank you very much Vivek. Very good luck to Sarvam and good luck to India. I think it's going to be a lot right on your shoulders. Thanks Bala. Thank you Mr. Raghavan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORLaRL7qbLzE"
      },
      "source": [
        "**semantic chunking**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQQoFYEyBoQW"
      },
      "outputs": [],
      "source": [
        "audio_path = \"/content/audio\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDsc0OwMBpk8"
      },
      "outputs": [],
      "source": [
        "# Function to get the duration of the audio file in seconds\n",
        "def get_audio_duration(audio_path):\n",
        "    audio = AudioSegment.from_file(audio_path)\n",
        "    return len(audio) / 1000.0  # Duration in seconds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDl1y6s3BuMu"
      },
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "# Function to perform semantic chunking\n",
        "def semantic_chunking(transcript, total_duration, max_chunk_duration=15):\n",
        "    \"\"\"\n",
        "    Chunks the transcript into pieces where each piece has a duration of less than 15 seconds.\n",
        "\n",
        "    Parameters:\n",
        "    transcript (str): The complete transcript of the audio.\n",
        "    total_duration (float): The total duration of the audio in seconds.\n",
        "    max_chunk_duration (int): The maximum allowed duration for each chunk.\n",
        "\n",
        "    Returns:\n",
        "    List[str]: List of transcript chunks.\n",
        "    \"\"\"\n",
        "    # Splits the transcript string into a list of words\n",
        "    words = transcript.split()\n",
        "\n",
        "    # Calculate average duration per word\n",
        "    word_duration = total_duration / len(words)\n",
        "\n",
        "    # Calculate number of words per chunk to ensure chunks are less than 15 seconds\n",
        "    chunk_size = int(max_chunk_duration / word_duration)\n",
        "\n",
        "    chunks = []\n",
        "    start_idx = 0\n",
        "\n",
        "    while start_idx < len(words):\n",
        "        end_idx = min(start_idx + chunk_size, len(words))\n",
        "\n",
        "        # Find the nearest sentence end to the chunk size limit\n",
        "        if end_idx < len(words):\n",
        "            while end_idx > start_idx :\n",
        "                end_idx -= 1\n",
        "            if end_idx == start_idx:  # No sentence end found within limit, use chunk size\n",
        "                end_idx = start_idx + chunk_size\n",
        "\n",
        "        chunk_text = ' '.join(words[start_idx:end_idx])\n",
        "        chunks.append(chunk_text)\n",
        "        start_idx = end_idx\n",
        "\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the total duration of the audio\n",
        "total_duration = get_audio_duration(audio_path)\n",
        "\n",
        "# Perform semantic chunking\n",
        "chunks = semantic_chunking(transcript, total_duration)\n",
        "for i, chunk in enumerate(chunks):\n",
        "    print(f\"Chunk {i+1}: {chunk}\")"
      ],
      "metadata": {
        "id": "eHyrxjwiLAMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd881f41-c2a4-4e5a-99c7-ee7d93083e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1: Congratulations to you Mr. Raghavan for that. Thank you so much for joining us. Over to you. Hi everybody. How are you? Okay, I am not hearing this at all. This is like a post-lunch energy downer or something. Let's hear it. Are\n",
            "Chunk 2: you guys awake? Yes. Alright. You better be because we have a superstar guest here. You heard the 41 million dollars and I didn't hear honestly anything she said after that. So we're going to ask for about 40 million dollars from him\n",
            "Chunk 3: by the end of this conversation, okay? But let's get started. I want to introduce Vivek and Pratyush, his co-founder who's not here. We wanted to start with playing a video of what OpenHati does. I encourage all of you to go to\n",
            "Chunk 4: the website, savrom.ai, and check it out. But let me start by introducing Vivek. Vivek is a dear friend, and he's very, very modest. One of the most modest guys that I know. But his personal journey, Vivek, you've got a PhD from\n",
            "Chunk 5: Carnegie Mellon. You started and sold the company to Magma. And Vivek and I moved back to India. We were both in the valley on the same day, actually. And you've been in India for the last 16 years. And what most people\n",
            "Chunk 6: don't know is your journey at Aadhaar. He spent 13 years selflessly at Aadhaar. Nobody would have heard of him, but he was a pioneering technology visionary behind Aadhaar, which we all take for granted today. So please give it up. Honestly, when\n",
            "Chunk 7: I think of selfless service, truly selfless service, I always think of Vivek. And since then, he also was at AI for Bharat, which we're going to touch on, where he met Pratyush's co-founder. Pratyush had a PhD from ETH at Zurich. He\n",
            "Chunk 8: was at IBM research. He was at Microsoft research playing a key role and a faculty at IIT Madras and at AI for Bharat. So that's a little brief introduction about them. These guys are modest, modest engineers. So they don't toot their\n",
            "Chunk 9: own horn. So forgive me for tooting their horn in this case. But But let's jump right in about the money, funding. 41 million bucks man, that's a lot of money, right? Every entrepreneur here is saying, what the hell did these guys\n",
            "Chunk 10: do? What did the investors see to write such a big check? No, I think it's a trend, a new trend of what's going on in India. I think that for the very first time, I think the investors have looked at, you\n",
            "Chunk 11: know, let's try and build something deep tech out of the country and let's try to figure out how to build something as a foundational technology out of the country and that's really what's what's really exciting you know and I think that\n",
            "Chunk 12: about you know as as as well I was mentioning for the past 15 years I've been kind of working in kind of you know both digital public infrastructure and and and kind of a nonprofit kind of things and but when this\n",
            "Chunk 13: whole thing of generative AI came came about, we said, okay, how can I actually make a difference in this space? And I said, maybe this is the opportunity to actually come out and really build something and the only way that we\n",
            "Chunk 14: realize that you can do it is actually in the private sector and I think that's the end. Then we went out there and we said we want to build something which is a continuation, right? I mean, fundamentally the question is the\n",
            "Chunk 15: reason of what we want to do at from AI is we want to basically make generative AI available and accessible to the people in the country. And that's the intent. And when we said that we want to do this, there was\n",
            "Chunk 16: a resonance in the investment community. And I think it's a responsibility to really to show that something like this can be built out of India. So we see that as confidence and a responsibility. And I also hope it's a trend that\n",
            "Chunk 17: there are many more people like us who are backed because if you look at it maybe it's a large number in the Indian context but in the global context I think there should be many, many more entrepreneurs who are back to\n",
            "Chunk 18: do things in India. I'm going to come back to the many more entrepreneurs. I'm obviously going to ask you about Bhavesh's Kruthram. So we're going to come back to the question but again $41 million, all of what you said, you know,\n",
            "Chunk 19: $2 million, you know, that's a good amount of money for a startup which, you know, which has not yet built anything. What are you going to do with all this money? I can solve the problem. I can have a perfect solution\n",
            "Chunk 20: for the problem. I think in the last week I've got lots of calls from lots of people telling me how I can do it. No, but... I know you first, okay? I'll be landed in the country the same day. I'm in\n",
            "Chunk 21: front of the queue. No, but but but honestly I think the key thing in this is is to putting together an amazing team And we actually have an amazing team But we believe that it is talent that will drive this kind\n",
            "Chunk 22: of thing and so it is it is to get Get key talent and of course the other thing is compute. This is extremely Expensive compute wise to actually do these kinds of things and I think that those are the two primary\n",
            "Chunk 23: things that that you know We'd use this for okay I'm computing in my own head as an entrepreneur, talent, okay, you have like 20-15 people, how much are you paying these guys? But okay, we won't touch on that. But let's talk\n",
            "Chunk 24: about what you guys actually built. What is Open Hathi? How would you explain Open Hathi to many people here who might not have known about it? So I think Open Hathi is, so first of all, right, we come from, I personally\n",
            "Chunk 25: come from the open source ecosystem and also from the DPI ecosystem. So we believe that for this to work, we need the ecosystem to be successful. And as a result of that, one of the first things we did was, hey, there\n",
            "Chunk 26: are these open source large language models that exist, right? I mean, everybody knows about the llama family from Meta. They also, there are others like Mistral. There are a bunch of open source, you know, large language models. And then we said,\n",
            "Chunk 27: is there any way that they can existing open source model and teach it language skills, right? I mean, and that is really the, you know, what we decide, what we said that can we do something like that? And is this a,\n",
            "Chunk 28: you know, relatively frugal way of actually, you know, making models, you know, work in diverse languages? Because the truth is still today, I mean, if you look at the amount of data and knowledge, it is still English dominates these things. And\n",
            "Chunk 29: I think that how do you actually take and make it understand Indian language, understand Indian context and all of those things in actually a in an efficient way. And therefore this was an attempt to do that. And it's a open hearty\n",
            "Chunk 30: is you know is currently based on the llama seven billion model but we'll be releasing many more models in different languages, different sizes and things like that as part of this as part of this series. And of course you know we\n",
            "Chunk 31: will be building further models on those and doing other things to actually and we'll also have endpoints that people can use so that it's not, it's definitely something that people can use to things and that's the essence of what this OpenHarp\n",
            "Chunk 32: is. So what does it mean to people in the audience here who are either doing their own startups or a business or developers, how should they look at OpenAI? Sorry, Sarvam, not OpenAI. No, no, I think the way you look at\n",
            "Chunk 33: it is that one of the important things that we are doing is we're not just building models. We are also going to be building a platform, a platform for developers where you can actually use a combination of various different kinds of\n",
            "Chunk 34: models, some which are from us, some which are open source, some which may not be open source, and actually to actually pull together and figure out how to deploy generative AI applications scale and understand and evaluate their performance in an efficient\n",
            "Chunk 35: manner and that's something that we are planning to do at this and this platform is you know in the next couple of months will be coming out there it will be available to developers but of course those who want to start\n",
            "Chunk 36: with the open source things and hack for that of course please go ahead and do that as well. That's phenomenal but how does it compare to OpenAI itself or Google? See at least the things that we are doing now. One of\n",
            "Chunk 37: the things that when we thought about building Sarvam, we said we want to build a full stack generative AI company and different people have an understanding of full stack is that we need to know how to train models from scratch. We\n",
            "Chunk 38: need to know how to kind of figure out how to deploy models to solve real world use cases. And we need to play in the ecosystem to make sure that we can actually deploy population scale applications So we were thinking about\n",
            "Chunk 39: all of these things. But still the models we were talking about are fairly small models. They are fairly small models, right, in the seven to maybe up to 70 billion kind of range we're talking about. While these models like OpenAI and\n",
            "Chunk 40: Google are obviously much bigger models, right? But we want to understand the techniques and be able to build that muscle to do all of these things, to make it available to people. Now those models are, I mean, as I said, I\n",
            "Chunk 41: think that there is space for all of those things and I think as even Sridhar was talking about earlier in the day, we believe that these smaller models can do very, I mean, many, many kind of domain specific tasks extremely well,\n",
            "Chunk 42: probably even better than the larger models and that is really one of the key areas. And so therefore the value of these kinds of things, right, we are not aiming in these set of models to build any AGI. That's not our\n",
            "Chunk 43: goal here. Our goal is to make things that work extremely well for domain specific use cases or increase accessibility through language and all of those kinds of things. And obviously all of this unique to India. But what is unique about India?\n",
            "Chunk 44: Is there anything special in our ecosystem that makes small models focused with Indian languages better for, more suited for our problems? So I think that, I mean, there are quite a few things that are unique about India, right? The first thing\n",
            "Chunk 45: is I think that we are a voice first nation, so therefore I think voice has to be the core to doing things. The other thing, of course, India is extremely, it's a cost conscious country from a cost perspective. Now, I would\n",
            "Chunk 46: say that there are lots of interesting use cases where you can use OpenAI and the cost structure works depending on your application. But when you want to scale things to a massive level and make it work, then you have to figure\n",
            "Chunk 47: out how small models work. So that's something that is also specific to India. The third thing which is specific to India is really the success that India has had in building all this digital public infrastructure. When you add the AI layer\n",
            "Chunk 48: on top of it, then you can actually get dramatic, you know, dramatic, I think, multiplicative combinatorial effects based on doing things like that. That's a phenomenal point. Like, you know, it's like DPI to the power of AI almost in some ways.\n",
            "Chunk 49: And as a part of building Aadhaar, no better person than you. So in summary, what I'm hearing is small models specialized with, trained with Indic-specific language data suited for Indian problems at a compelling cost point will be suited for us. autonomous\n",
            "Chunk 50: vehicles or some complex problem, we're solving some basic problems specifically focused on voice with multiple languages. That is what you see as the future. Am I paraphrasing this correctly? No, yeah. So I think that certainly, I mean, voice and Indian languages\n",
            "Chunk 51: are an important part of our strategy, but we will be building custom models to solve various other kinds of problems as well. That's not just limited to, I think, in different domains, working different domains, making building things based on unique data\n",
            "Chunk 52: that enterprises have and things like that. So that's something that we'll also look at. Fair enough. So coming back to the elephant in the room, no fun intended with open Hathi, what about Babesh Akarwal and Kruthrim? What is your take on\n",
            "Chunk 53: that? I think it's great. I think it's wonderful, right? I mean, the fact that the technology AI is so important that we need multiple people working on it. The fact that there are other people thinking is actually validates that this is\n",
            "Chunk 54: an important problem to be solved. And I think that we need everybody to come together and do that. So I really welcome that. I think it's great. And I think that there will be different people will have different takes as to\n",
            "Chunk 55: how to solve this kind of problem. And hopefully as a result of that, the entire ecosystem benefits. One more question and then I want to talk about some of the predictions that you've boldly made. So Vivek, I usually ask people about\n",
            "Chunk 56: what do you think the future will be and everybody usually hedges. I asked Vivek, what do you think is going to happen by December 2024? What do you think sitting in this room one year later we can expect? And he made\n",
            "Chunk 57: three bold predictions. So I want to talk about that. Before that, I have one last question. What are the top three applications that you think are relevant for India? You heard Sridhar talk about medical. What, you know, any quick summary, what\n",
            "Chunk 58: is, what do you, what do you think your the top three apps are for India for AI? So I mean I think that as you said things like education and medical are clearly areas where I think that things can can be\n",
            "Chunk 59: leveraged. The whole idea of all these kind of the DPI aspect of it is another major application where things can happen in and here I'm talking about country specific work and I think the whole idea which Sridhar also talked about was\n",
            "Chunk 60: the the concept of software right and I think that and clearly we have a very large software industry and how to reimagine those things in this context is also something that's going to be big. Fair enough. Are you guys ready for\n",
            "Chunk 61: Vivek Raghavan's bold predictions? Yes? No? I'm not hearing any yes sir. This is like a big deal. He's like one of the smartest guys that I know. He wants to make three predictions. You don't want to hear it? All right. So\n",
            "Chunk 62: I asked him, what do you think, you know, a year later, what do you think we can expect? And he came up with three things and usually people give very blah answers when you ask question like this because they don't want\n",
            "Chunk 63: to be caught wrong. Not Vivek. Vivek is bold. So he basically said three things and I'm going to list out the three things and then he's asking about it. So number one, he says, I would prefer to talk to an automated\n",
            "Chunk 64: customer service than a real person because they'll give me a better answer. So that is Vivek Ragwan's prediction number one. So number two is that when everybody is talking about a GPU shortage, Vivek predicts that there will be a GPU glut\n",
            "Chunk 65: in India. He thinks there will be too much GPU. So if you want a short NVIDIA talk, this is a good time. And number three, which was extremely unexpected, he said some companies will suddenly die. So Vivek, these are not what\n",
            "Chunk 66: I expected. So do you want to quickly talk about each of them, why you just came up with these and then we'll throw the open for audience questions. So I don't think I quite said it the way that Pallav is kind\n",
            "Chunk 67: of making, but it's interesting. But I think the first thing that we said is I think that and I don't think that this is I think there will come a time when in areas of customer service, et cetera, when you want\n",
            "Chunk 68: to do something very specific. Today, you know, when you call some kind of a bot, you actually end up, you mostly try to disconnect the call or, you know, you're extremely upset that you're talking to a bot. But I think that\n",
            "Chunk 69: there will come a time, and I'm predicting it is sooner than later, that you will actually get better responses from the bot than what the human representative, at least the average human representative that you could talk to could give. And I\n",
            "Chunk 70: think that that's just a, I just said that there will come a time where you know it's not a human you're talking to, but it's probably more likely to solve your intent than the human person. That's just something that I think\n",
            "Chunk 71: that could happen. Okay, definitely controversial, but we'll let it go. What about the GPU glut? No, no, yeah. So I don't think that, so I think that the fact that there is a tremendous shortage right now, I think that shortage will\n",
            "Chunk 72: ease because that is how the cycles of things go, right? When, you know, I think the fact that there was such a severe shortage last year, you know, basically caused a number of different players to ramp up in various kinds of\n",
            "Chunk 73: forms and I think that that will always go in a cycle. But you may find out that there are many, many more interesting problems that people will be able to solve. I still remember you know, we were at a Gen.AI event\n",
            "Chunk 74: in Bangalore and we were talking to people and we said, you know, how many people have access to, you know, four A-hundreds? This was the question that I'd asked and nobody in the room and these are all extremely enthusiastic Gen.AI people\n",
            "Chunk 75: and nobody had access and I think that thing is going to change. You will be able to get these kinds of things and people who want to hack and do things will have access to these things without having to write a\n",
            "Chunk 76: check. Vivek is also a semiconductor guy before he went into Aadhaar. So I would take his predictions very seriously. So I don't know what I will do. I'm going to sell my NMEDIA stock. I would not do that. But that's not\n",
            "Chunk 77: what I said. I want to blame you for this if it goes up. But the third one is pretty strange. Companies are born, companies die. But you said some companies will suddenly die. What does that mean? No, I think, see, I\n",
            "Chunk 78: think the interesting thing is, and I think that it comes back to the fundamental nature of AI. AI is a tool, right? And you have to use that. And you have to use that within your business process, right? And how AI\n",
            "Chunk 79: is being used. And so what's going to happen is that, I mean, I think this is true with, you know, when someone said in terms of people, they said that the people who leverage AI will be more effective than those who\n",
            "Chunk 80: don't leverage AI. And that will stoop for organizations also. Organizations that leverage AI fundamentally in their core business processes will be more effective than those who don't. And I think that's the thing. And you won't know the difference until one day\n",
            "Chunk 81: it becomes too obvious, and it will be too late. And I think that's the reason why everybody needs to think about what it means for your business. Because everything will be fine. Everything will be fine. And one day, somebody in your,\n",
            "Chunk 82: either your competitor in your space or somebody brand new coming into your space will be reimagining your business process completely. And at that stage, you will find that it's a very big, very tall mountain to climb. And that's why I think\n",
            "Chunk 83: it's important for both people and entities to think about how they will, you know, they will upgrade themselves or they will modify their business processes to, you know, to work out this. That's a very nuanced answer and everybody here who's running\n",
            "Chunk 84: a business should really think about it because life will be the same and then suddenly, suddenly something will, you know, then it will be a step change. Vivek, I have a few more questions but I'm sure the audience has a lot\n",
            "Chunk 85: of questions for you. So, how are we doing on time? Okay. So, does, okay. does, okay, a lot of questions, so love to, is there a mic that we can pass around? Thank you. My name is Karthik. I work for IT\n",
            "Chunk 86: service industry. So you're saying that you're working on LLM, sorry, it's fine-tuned LLM on top of Lama. My basic question, fundamental question is we don't have a fund them foundational model for India most of the models are basically using English or\n",
            "Chunk 87: those kind of things for example even Andrew was talking about the tokenizers and things like that so are you working on anything like that or you do you want to use mostly the existing models and run on top of it are\n",
            "Chunk 88: you going to ask a good question you have the cherry question for him so no I think the interesting thing is that if you look at and then we have actually a blog on this on our website. I think one of\n",
            "Chunk 89: the things that we've built is we actually built a customized tokenizer which actually fundamentally changes the cost of some of these generations in Indian languages and I think that we are not just fine-tuning. We are actually, we are leveraging the existing\n",
            "Chunk 90: pre-training but we are doing what's known as continual free training which actually, but having said that you know I think I think that we have to figure out where is the data to train an extremely large model from scratch. And some\n",
            "Chunk 91: of those things are things which will happen over time. But I think that, yes, I think that we will be doing various kinds of things. But the interesting thing is that if I want to change the accessibility problem with an existing\n",
            "Chunk 92: open source model, how do I do that? And that's the problem that we think we have solved and is going to be the heart of this open-heart series. It's extremely well explained in the blog, even I could understand it. Hi, I'm\n",
            "Chunk 93: Prashant. I work for a fintech company. My question is, unlike China, we never had a consumer-facing application coming out from India, and in web one, web two, crypto and all. Why do you think it will be different this time in AI?\n",
            "Chunk 94: Because will the BPAI and other things will serve the same purpose what the great fire world did in China? Or do you think, like in NASA, because AI is a strategic sector, no outside country can work in NASA projects. Maybe all\n",
            "Chunk 95: government contracts will go to them. What exactly is the moat here for an Indian company? So I think the question is, I don't know the answer to these questions, right? I mean, I think that it's difficult to predict but I do\n",
            "Chunk 96: believe and as I'm repeating that the combinatorial effect of being using GenAI at a large scale in addition along with the DPI work that we've done in India will have people and I I think that in the end, the intent is\n",
            "Chunk 97: that people need to be able to use it and they will vote by things that are useful for them. And if that doesn't happen, you're right. I think that we have to figure out what is the mechanism of delivery of apps.\n",
            "Chunk 98: Where do Indians consume content? That's the question. I'm so sorry, but we are out of time. Vivek will be outside, so he would be able to answer the question. Do we have time for one last question? Can I just take one\n",
            "Chunk 99: last? Yeah. Thank you. Thank you. I'm Manish Kothari. I'm from ISBR Business School. Good that I got a chance to ask you this question. During lunchtime, there were a few of our educationists whom we were talking about and we were there\n",
            "Chunk 100: was one from school and we are from the MBA institutions. We were thinking of these present generations. How do we get them into what you are doing? There is one thing that they have been regularly that the concentrations that they are\n",
            "Chunk 101: working on but artificial intelligence and getting into this getting them into their academics and making them a part of it is very important including the trainers who train them making them future ready into what you are doing is amazing and the\n",
            "Chunk 102: speed that with which is growing it is calling for a lot of training that needs to be done. Can you from your angle throw some light on how we could make them future ready how these people who are who are management\n",
            "Chunk 103: graduates and from schools who are coming out how do we get into this part of technology that you spoke about? No, so this is really a challenge because I think everyone will need to understand at some level what this technology does\n",
            "Chunk 104: and I think that we have to rethink how we get everyone into this and that this kind of education has to be at many different levels, right? There are from a core set of having people who are extremely good at some\n",
            "Chunk 105: and there you don't need as many, but then there are basically vast numbers of people who can actually leverage these tools. By the way, the most important thing about, I mean, maybe that's part of what makes an LLM interesting, is that\n",
            "Chunk 106: how you use it, your mileage varies by that. And to understand how to actually leverage this in an interesting way is something that we have to widely teach many, many people. And because asking the, you know, things in the right way\n",
            "Chunk 107: and having the right kind of applications will make a huge difference to how people can use these tools. Awesome. Thank you. Thank you very much Vivek. Very good luck to Sarvam and good luck to India. I think it's going to be\n",
            "Chunk 108: a lot right on your shoulders. Thanks Bala. Thank you Mr. Raghavan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks"
      ],
      "metadata": {
        "id": "jXLtmNwALVgC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed4c45d2-3999-43f6-cd24-dd86427fcefd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Congratulations to you Mr. Raghavan for that. Thank you so much for joining us. Over to you. Hi everybody. How are you? Okay, I am not hearing this at all. This is like a post-lunch energy downer or something. Let's hear it. Are\",\n",
              " \"you guys awake? Yes. Alright. You better be because we have a superstar guest here. You heard the 41 million dollars and I didn't hear honestly anything she said after that. So we're going to ask for about 40 million dollars from him\",\n",
              " \"by the end of this conversation, okay? But let's get started. I want to introduce Vivek and Pratyush, his co-founder who's not here. We wanted to start with playing a video of what OpenHati does. I encourage all of you to go to\",\n",
              " \"the website, savrom.ai, and check it out. But let me start by introducing Vivek. Vivek is a dear friend, and he's very, very modest. One of the most modest guys that I know. But his personal journey, Vivek, you've got a PhD from\",\n",
              " \"Carnegie Mellon. You started and sold the company to Magma. And Vivek and I moved back to India. We were both in the valley on the same day, actually. And you've been in India for the last 16 years. And what most people\",\n",
              " \"don't know is your journey at Aadhaar. He spent 13 years selflessly at Aadhaar. Nobody would have heard of him, but he was a pioneering technology visionary behind Aadhaar, which we all take for granted today. So please give it up. Honestly, when\",\n",
              " \"I think of selfless service, truly selfless service, I always think of Vivek. And since then, he also was at AI for Bharat, which we're going to touch on, where he met Pratyush's co-founder. Pratyush had a PhD from ETH at Zurich. He\",\n",
              " \"was at IBM research. He was at Microsoft research playing a key role and a faculty at IIT Madras and at AI for Bharat. So that's a little brief introduction about them. These guys are modest, modest engineers. So they don't toot their\",\n",
              " \"own horn. So forgive me for tooting their horn in this case. But But let's jump right in about the money, funding. 41 million bucks man, that's a lot of money, right? Every entrepreneur here is saying, what the hell did these guys\",\n",
              " \"do? What did the investors see to write such a big check? No, I think it's a trend, a new trend of what's going on in India. I think that for the very first time, I think the investors have looked at, you\",\n",
              " \"know, let's try and build something deep tech out of the country and let's try to figure out how to build something as a foundational technology out of the country and that's really what's what's really exciting you know and I think that\",\n",
              " \"about you know as as as well I was mentioning for the past 15 years I've been kind of working in kind of you know both digital public infrastructure and and and kind of a nonprofit kind of things and but when this\",\n",
              " 'whole thing of generative AI came came about, we said, okay, how can I actually make a difference in this space? And I said, maybe this is the opportunity to actually come out and really build something and the only way that we',\n",
              " \"realize that you can do it is actually in the private sector and I think that's the end. Then we went out there and we said we want to build something which is a continuation, right? I mean, fundamentally the question is the\",\n",
              " \"reason of what we want to do at from AI is we want to basically make generative AI available and accessible to the people in the country. And that's the intent. And when we said that we want to do this, there was\",\n",
              " \"a resonance in the investment community. And I think it's a responsibility to really to show that something like this can be built out of India. So we see that as confidence and a responsibility. And I also hope it's a trend that\",\n",
              " \"there are many more people like us who are backed because if you look at it maybe it's a large number in the Indian context but in the global context I think there should be many, many more entrepreneurs who are back to\",\n",
              " \"do things in India. I'm going to come back to the many more entrepreneurs. I'm obviously going to ask you about Bhavesh's Kruthram. So we're going to come back to the question but again $41 million, all of what you said, you know,\",\n",
              " \"$2 million, you know, that's a good amount of money for a startup which, you know, which has not yet built anything. What are you going to do with all this money? I can solve the problem. I can have a perfect solution\",\n",
              " \"for the problem. I think in the last week I've got lots of calls from lots of people telling me how I can do it. No, but... I know you first, okay? I'll be landed in the country the same day. I'm in\",\n",
              " 'front of the queue. No, but but but honestly I think the key thing in this is is to putting together an amazing team And we actually have an amazing team But we believe that it is talent that will drive this kind',\n",
              " 'of thing and so it is it is to get Get key talent and of course the other thing is compute. This is extremely Expensive compute wise to actually do these kinds of things and I think that those are the two primary',\n",
              " \"things that that you know We'd use this for okay I'm computing in my own head as an entrepreneur, talent, okay, you have like 20-15 people, how much are you paying these guys? But okay, we won't touch on that. But let's talk\",\n",
              " 'about what you guys actually built. What is Open Hathi? How would you explain Open Hathi to many people here who might not have known about it? So I think Open Hathi is, so first of all, right, we come from, I personally',\n",
              " 'come from the open source ecosystem and also from the DPI ecosystem. So we believe that for this to work, we need the ecosystem to be successful. And as a result of that, one of the first things we did was, hey, there',\n",
              " 'are these open source large language models that exist, right? I mean, everybody knows about the llama family from Meta. They also, there are others like Mistral. There are a bunch of open source, you know, large language models. And then we said,',\n",
              " 'is there any way that they can existing open source model and teach it language skills, right? I mean, and that is really the, you know, what we decide, what we said that can we do something like that? And is this a,',\n",
              " 'you know, relatively frugal way of actually, you know, making models, you know, work in diverse languages? Because the truth is still today, I mean, if you look at the amount of data and knowledge, it is still English dominates these things. And',\n",
              " \"I think that how do you actually take and make it understand Indian language, understand Indian context and all of those things in actually a in an efficient way. And therefore this was an attempt to do that. And it's a open hearty\",\n",
              " \"is you know is currently based on the llama seven billion model but we'll be releasing many more models in different languages, different sizes and things like that as part of this as part of this series. And of course you know we\",\n",
              " \"will be building further models on those and doing other things to actually and we'll also have endpoints that people can use so that it's not, it's definitely something that people can use to things and that's the essence of what this OpenHarp\",\n",
              " 'is. So what does it mean to people in the audience here who are either doing their own startups or a business or developers, how should they look at OpenAI? Sorry, Sarvam, not OpenAI. No, no, I think the way you look at',\n",
              " \"it is that one of the important things that we are doing is we're not just building models. We are also going to be building a platform, a platform for developers where you can actually use a combination of various different kinds of\",\n",
              " 'models, some which are from us, some which are open source, some which may not be open source, and actually to actually pull together and figure out how to deploy generative AI applications scale and understand and evaluate their performance in an efficient',\n",
              " \"manner and that's something that we are planning to do at this and this platform is you know in the next couple of months will be coming out there it will be available to developers but of course those who want to start\",\n",
              " \"with the open source things and hack for that of course please go ahead and do that as well. That's phenomenal but how does it compare to OpenAI itself or Google? See at least the things that we are doing now. One of\",\n",
              " 'the things that when we thought about building Sarvam, we said we want to build a full stack generative AI company and different people have an understanding of full stack is that we need to know how to train models from scratch. We',\n",
              " 'need to know how to kind of figure out how to deploy models to solve real world use cases. And we need to play in the ecosystem to make sure that we can actually deploy population scale applications So we were thinking about',\n",
              " \"all of these things. But still the models we were talking about are fairly small models. They are fairly small models, right, in the seven to maybe up to 70 billion kind of range we're talking about. While these models like OpenAI and\",\n",
              " 'Google are obviously much bigger models, right? But we want to understand the techniques and be able to build that muscle to do all of these things, to make it available to people. Now those models are, I mean, as I said, I',\n",
              " 'think that there is space for all of those things and I think as even Sridhar was talking about earlier in the day, we believe that these smaller models can do very, I mean, many, many kind of domain specific tasks extremely well,',\n",
              " \"probably even better than the larger models and that is really one of the key areas. And so therefore the value of these kinds of things, right, we are not aiming in these set of models to build any AGI. That's not our\",\n",
              " 'goal here. Our goal is to make things that work extremely well for domain specific use cases or increase accessibility through language and all of those kinds of things. And obviously all of this unique to India. But what is unique about India?',\n",
              " 'Is there anything special in our ecosystem that makes small models focused with Indian languages better for, more suited for our problems? So I think that, I mean, there are quite a few things that are unique about India, right? The first thing',\n",
              " \"is I think that we are a voice first nation, so therefore I think voice has to be the core to doing things. The other thing, of course, India is extremely, it's a cost conscious country from a cost perspective. Now, I would\",\n",
              " 'say that there are lots of interesting use cases where you can use OpenAI and the cost structure works depending on your application. But when you want to scale things to a massive level and make it work, then you have to figure',\n",
              " \"out how small models work. So that's something that is also specific to India. The third thing which is specific to India is really the success that India has had in building all this digital public infrastructure. When you add the AI layer\",\n",
              " \"on top of it, then you can actually get dramatic, you know, dramatic, I think, multiplicative combinatorial effects based on doing things like that. That's a phenomenal point. Like, you know, it's like DPI to the power of AI almost in some ways.\",\n",
              " \"And as a part of building Aadhaar, no better person than you. So in summary, what I'm hearing is small models specialized with, trained with Indic-specific language data suited for Indian problems at a compelling cost point will be suited for us. autonomous\",\n",
              " \"vehicles or some complex problem, we're solving some basic problems specifically focused on voice with multiple languages. That is what you see as the future. Am I paraphrasing this correctly? No, yeah. So I think that certainly, I mean, voice and Indian languages\",\n",
              " \"are an important part of our strategy, but we will be building custom models to solve various other kinds of problems as well. That's not just limited to, I think, in different domains, working different domains, making building things based on unique data\",\n",
              " \"that enterprises have and things like that. So that's something that we'll also look at. Fair enough. So coming back to the elephant in the room, no fun intended with open Hathi, what about Babesh Akarwal and Kruthrim? What is your take on\",\n",
              " \"that? I think it's great. I think it's wonderful, right? I mean, the fact that the technology AI is so important that we need multiple people working on it. The fact that there are other people thinking is actually validates that this is\",\n",
              " \"an important problem to be solved. And I think that we need everybody to come together and do that. So I really welcome that. I think it's great. And I think that there will be different people will have different takes as to\",\n",
              " \"how to solve this kind of problem. And hopefully as a result of that, the entire ecosystem benefits. One more question and then I want to talk about some of the predictions that you've boldly made. So Vivek, I usually ask people about\",\n",
              " 'what do you think the future will be and everybody usually hedges. I asked Vivek, what do you think is going to happen by December 2024? What do you think sitting in this room one year later we can expect? And he made',\n",
              " 'three bold predictions. So I want to talk about that. Before that, I have one last question. What are the top three applications that you think are relevant for India? You heard Sridhar talk about medical. What, you know, any quick summary, what',\n",
              " 'is, what do you, what do you think your the top three apps are for India for AI? So I mean I think that as you said things like education and medical are clearly areas where I think that things can can be',\n",
              " \"leveraged. The whole idea of all these kind of the DPI aspect of it is another major application where things can happen in and here I'm talking about country specific work and I think the whole idea which Sridhar also talked about was\",\n",
              " \"the the concept of software right and I think that and clearly we have a very large software industry and how to reimagine those things in this context is also something that's going to be big. Fair enough. Are you guys ready for\",\n",
              " \"Vivek Raghavan's bold predictions? Yes? No? I'm not hearing any yes sir. This is like a big deal. He's like one of the smartest guys that I know. He wants to make three predictions. You don't want to hear it? All right. So\",\n",
              " \"I asked him, what do you think, you know, a year later, what do you think we can expect? And he came up with three things and usually people give very blah answers when you ask question like this because they don't want\",\n",
              " \"to be caught wrong. Not Vivek. Vivek is bold. So he basically said three things and I'm going to list out the three things and then he's asking about it. So number one, he says, I would prefer to talk to an automated\",\n",
              " \"customer service than a real person because they'll give me a better answer. So that is Vivek Ragwan's prediction number one. So number two is that when everybody is talking about a GPU shortage, Vivek predicts that there will be a GPU glut\",\n",
              " 'in India. He thinks there will be too much GPU. So if you want a short NVIDIA talk, this is a good time. And number three, which was extremely unexpected, he said some companies will suddenly die. So Vivek, these are not what',\n",
              " \"I expected. So do you want to quickly talk about each of them, why you just came up with these and then we'll throw the open for audience questions. So I don't think I quite said it the way that Pallav is kind\",\n",
              " \"of making, but it's interesting. But I think the first thing that we said is I think that and I don't think that this is I think there will come a time when in areas of customer service, et cetera, when you want\",\n",
              " \"to do something very specific. Today, you know, when you call some kind of a bot, you actually end up, you mostly try to disconnect the call or, you know, you're extremely upset that you're talking to a bot. But I think that\",\n",
              " \"there will come a time, and I'm predicting it is sooner than later, that you will actually get better responses from the bot than what the human representative, at least the average human representative that you could talk to could give. And I\",\n",
              " \"think that that's just a, I just said that there will come a time where you know it's not a human you're talking to, but it's probably more likely to solve your intent than the human person. That's just something that I think\",\n",
              " \"that could happen. Okay, definitely controversial, but we'll let it go. What about the GPU glut? No, no, yeah. So I don't think that, so I think that the fact that there is a tremendous shortage right now, I think that shortage will\",\n",
              " 'ease because that is how the cycles of things go, right? When, you know, I think the fact that there was such a severe shortage last year, you know, basically caused a number of different players to ramp up in various kinds of',\n",
              " 'forms and I think that that will always go in a cycle. But you may find out that there are many, many more interesting problems that people will be able to solve. I still remember you know, we were at a Gen.AI event',\n",
              " \"in Bangalore and we were talking to people and we said, you know, how many people have access to, you know, four A-hundreds? This was the question that I'd asked and nobody in the room and these are all extremely enthusiastic Gen.AI people\",\n",
              " 'and nobody had access and I think that thing is going to change. You will be able to get these kinds of things and people who want to hack and do things will have access to these things without having to write a',\n",
              " \"check. Vivek is also a semiconductor guy before he went into Aadhaar. So I would take his predictions very seriously. So I don't know what I will do. I'm going to sell my NMEDIA stock. I would not do that. But that's not\",\n",
              " 'what I said. I want to blame you for this if it goes up. But the third one is pretty strange. Companies are born, companies die. But you said some companies will suddenly die. What does that mean? No, I think, see, I',\n",
              " 'think the interesting thing is, and I think that it comes back to the fundamental nature of AI. AI is a tool, right? And you have to use that. And you have to use that within your business process, right? And how AI',\n",
              " \"is being used. And so what's going to happen is that, I mean, I think this is true with, you know, when someone said in terms of people, they said that the people who leverage AI will be more effective than those who\",\n",
              " \"don't leverage AI. And that will stoop for organizations also. Organizations that leverage AI fundamentally in their core business processes will be more effective than those who don't. And I think that's the thing. And you won't know the difference until one day\",\n",
              " \"it becomes too obvious, and it will be too late. And I think that's the reason why everybody needs to think about what it means for your business. Because everything will be fine. Everything will be fine. And one day, somebody in your,\",\n",
              " \"either your competitor in your space or somebody brand new coming into your space will be reimagining your business process completely. And at that stage, you will find that it's a very big, very tall mountain to climb. And that's why I think\",\n",
              " \"it's important for both people and entities to think about how they will, you know, they will upgrade themselves or they will modify their business processes to, you know, to work out this. That's a very nuanced answer and everybody here who's running\",\n",
              " \"a business should really think about it because life will be the same and then suddenly, suddenly something will, you know, then it will be a step change. Vivek, I have a few more questions but I'm sure the audience has a lot\",\n",
              " 'of questions for you. So, how are we doing on time? Okay. So, does, okay. does, okay, a lot of questions, so love to, is there a mic that we can pass around? Thank you. My name is Karthik. I work for IT',\n",
              " \"service industry. So you're saying that you're working on LLM, sorry, it's fine-tuned LLM on top of Lama. My basic question, fundamental question is we don't have a fund them foundational model for India most of the models are basically using English or\",\n",
              " 'those kind of things for example even Andrew was talking about the tokenizers and things like that so are you working on anything like that or you do you want to use mostly the existing models and run on top of it are',\n",
              " 'you going to ask a good question you have the cherry question for him so no I think the interesting thing is that if you look at and then we have actually a blog on this on our website. I think one of',\n",
              " \"the things that we've built is we actually built a customized tokenizer which actually fundamentally changes the cost of some of these generations in Indian languages and I think that we are not just fine-tuning. We are actually, we are leveraging the existing\",\n",
              " \"pre-training but we are doing what's known as continual free training which actually, but having said that you know I think I think that we have to figure out where is the data to train an extremely large model from scratch. And some\",\n",
              " 'of those things are things which will happen over time. But I think that, yes, I think that we will be doing various kinds of things. But the interesting thing is that if I want to change the accessibility problem with an existing',\n",
              " \"open source model, how do I do that? And that's the problem that we think we have solved and is going to be the heart of this open-heart series. It's extremely well explained in the blog, even I could understand it. Hi, I'm\",\n",
              " 'Prashant. I work for a fintech company. My question is, unlike China, we never had a consumer-facing application coming out from India, and in web one, web two, crypto and all. Why do you think it will be different this time in AI?',\n",
              " 'Because will the BPAI and other things will serve the same purpose what the great fire world did in China? Or do you think, like in NASA, because AI is a strategic sector, no outside country can work in NASA projects. Maybe all',\n",
              " \"government contracts will go to them. What exactly is the moat here for an Indian company? So I think the question is, I don't know the answer to these questions, right? I mean, I think that it's difficult to predict but I do\",\n",
              " \"believe and as I'm repeating that the combinatorial effect of being using GenAI at a large scale in addition along with the DPI work that we've done in India will have people and I I think that in the end, the intent is\",\n",
              " \"that people need to be able to use it and they will vote by things that are useful for them. And if that doesn't happen, you're right. I think that we have to figure out what is the mechanism of delivery of apps.\",\n",
              " \"Where do Indians consume content? That's the question. I'm so sorry, but we are out of time. Vivek will be outside, so he would be able to answer the question. Do we have time for one last question? Can I just take one\",\n",
              " \"last? Yeah. Thank you. Thank you. I'm Manish Kothari. I'm from ISBR Business School. Good that I got a chance to ask you this question. During lunchtime, there were a few of our educationists whom we were talking about and we were there\",\n",
              " 'was one from school and we are from the MBA institutions. We were thinking of these present generations. How do we get them into what you are doing? There is one thing that they have been regularly that the concentrations that they are',\n",
              " 'working on but artificial intelligence and getting into this getting them into their academics and making them a part of it is very important including the trainers who train them making them future ready into what you are doing is amazing and the',\n",
              " 'speed that with which is growing it is calling for a lot of training that needs to be done. Can you from your angle throw some light on how we could make them future ready how these people who are who are management',\n",
              " 'graduates and from schools who are coming out how do we get into this part of technology that you spoke about? No, so this is really a challenge because I think everyone will need to understand at some level what this technology does',\n",
              " 'and I think that we have to rethink how we get everyone into this and that this kind of education has to be at many different levels, right? There are from a core set of having people who are extremely good at some',\n",
              " \"and there you don't need as many, but then there are basically vast numbers of people who can actually leverage these tools. By the way, the most important thing about, I mean, maybe that's part of what makes an LLM interesting, is that\",\n",
              " 'how you use it, your mileage varies by that. And to understand how to actually leverage this in an interesting way is something that we have to widely teach many, many people. And because asking the, you know, things in the right way',\n",
              " \"and having the right kind of applications will make a huge difference to how people can use these tools. Awesome. Thank you. Thank you very much Vivek. Very good luck to Sarvam and good luck to India. I think it's going to be\",\n",
              " 'a lot right on your shoulders. Thanks Bala. Thank you Mr. Raghavan.']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PosiA58sB_cb"
      },
      "source": [
        "Generating the text chunks into the desired output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Function to generate output in the specified format\n",
        "def generate_output(chunks, total_duration):\n",
        "    output_list = []\n",
        "    start_time = 0.0\n",
        "\n",
        "    # Calculate the average duration per word\n",
        "    total_words = sum(len(chunk.split()) for chunk in chunks)\n",
        "    average_word_duration = total_duration / total_words\n",
        "\n",
        "    for i, chunk_text in enumerate(chunks):\n",
        "        # Calculate the length of the current chunk in seconds based on word count\n",
        "        chunk_words = len(chunk_text.split())\n",
        "        chunk_length = chunk_words * average_word_duration\n",
        "\n",
        "        # Calculate the end time of the current chunk\n",
        "        end_time = start_time + chunk_length\n",
        "\n",
        "        # Append a dictionary representing the current chunk to the output list\n",
        "        output_list.append({\n",
        "            \"chunk_id\": i + 1,\n",
        "            \"chunk_length\": chunk_length,\n",
        "            \"text\": chunk_text,\n",
        "            \"start_time\": start_time,\n",
        "            \"end_time\": end_time\n",
        "        })\n",
        "        start_time = end_time\n",
        "    return output_list"
      ],
      "metadata": {
        "id": "zl_t4lfHLMx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_list = generate_output(chunks,total_duration)"
      ],
      "metadata": {
        "id": "dFJZG2kdWYYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vhiffm6BCJTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6187a223-6dd2-4e20-eed6-53502433565e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'chunk_id': 1, 'chunk_length': 14.682724257533057, 'text': \"Congratulations to you Mr. Raghavan for that. Thank you so much for joining us. Over to you. Hi everybody. How are you? Okay, I am not hearing this at all. This is like a post-lunch energy downer or something. Let's hear it. Are\", 'start_time': 0.0, 'end_time': 14.682724257533057}\n",
            "{'chunk_id': 2, 'chunk_length': 14.682724257533057, 'text': \"you guys awake? Yes. Alright. You better be because we have a superstar guest here. You heard the 41 million dollars and I didn't hear honestly anything she said after that. So we're going to ask for about 40 million dollars from him\", 'start_time': 14.682724257533057, 'end_time': 29.365448515066113}\n",
            "{'chunk_id': 3, 'chunk_length': 14.682724257533057, 'text': \"by the end of this conversation, okay? But let's get started. I want to introduce Vivek and Pratyush, his co-founder who's not here. We wanted to start with playing a video of what OpenHati does. I encourage all of you to go to\", 'start_time': 29.365448515066113, 'end_time': 44.04817277259917}\n",
            "{'chunk_id': 4, 'chunk_length': 14.682724257533057, 'text': \"the website, savrom.ai, and check it out. But let me start by introducing Vivek. Vivek is a dear friend, and he's very, very modest. One of the most modest guys that I know. But his personal journey, Vivek, you've got a PhD from\", 'start_time': 44.04817277259917, 'end_time': 58.730897030132226}\n",
            "{'chunk_id': 5, 'chunk_length': 14.682724257533057, 'text': \"Carnegie Mellon. You started and sold the company to Magma. And Vivek and I moved back to India. We were both in the valley on the same day, actually. And you've been in India for the last 16 years. And what most people\", 'start_time': 58.730897030132226, 'end_time': 73.41362128766528}\n",
            "{'chunk_id': 6, 'chunk_length': 14.682724257533057, 'text': \"don't know is your journey at Aadhaar. He spent 13 years selflessly at Aadhaar. Nobody would have heard of him, but he was a pioneering technology visionary behind Aadhaar, which we all take for granted today. So please give it up. Honestly, when\", 'start_time': 73.41362128766528, 'end_time': 88.09634554519833}\n",
            "{'chunk_id': 7, 'chunk_length': 14.682724257533057, 'text': \"I think of selfless service, truly selfless service, I always think of Vivek. And since then, he also was at AI for Bharat, which we're going to touch on, where he met Pratyush's co-founder. Pratyush had a PhD from ETH at Zurich. He\", 'start_time': 88.09634554519833, 'end_time': 102.77906980273139}\n",
            "{'chunk_id': 8, 'chunk_length': 14.682724257533057, 'text': \"was at IBM research. He was at Microsoft research playing a key role and a faculty at IIT Madras and at AI for Bharat. So that's a little brief introduction about them. These guys are modest, modest engineers. So they don't toot their\", 'start_time': 102.77906980273139, 'end_time': 117.46179406026444}\n",
            "{'chunk_id': 9, 'chunk_length': 14.682724257533057, 'text': \"own horn. So forgive me for tooting their horn in this case. But But let's jump right in about the money, funding. 41 million bucks man, that's a lot of money, right? Every entrepreneur here is saying, what the hell did these guys\", 'start_time': 117.46179406026444, 'end_time': 132.1445183177975}\n",
            "{'chunk_id': 10, 'chunk_length': 14.682724257533057, 'text': \"do? What did the investors see to write such a big check? No, I think it's a trend, a new trend of what's going on in India. I think that for the very first time, I think the investors have looked at, you\", 'start_time': 132.1445183177975, 'end_time': 146.82724257533056}\n",
            "{'chunk_id': 11, 'chunk_length': 14.682724257533057, 'text': \"know, let's try and build something deep tech out of the country and let's try to figure out how to build something as a foundational technology out of the country and that's really what's what's really exciting you know and I think that\", 'start_time': 146.82724257533056, 'end_time': 161.50996683286363}\n",
            "{'chunk_id': 12, 'chunk_length': 14.682724257533057, 'text': \"about you know as as as well I was mentioning for the past 15 years I've been kind of working in kind of you know both digital public infrastructure and and and kind of a nonprofit kind of things and but when this\", 'start_time': 161.50996683286363, 'end_time': 176.1926910903967}\n",
            "{'chunk_id': 13, 'chunk_length': 14.682724257533057, 'text': 'whole thing of generative AI came came about, we said, okay, how can I actually make a difference in this space? And I said, maybe this is the opportunity to actually come out and really build something and the only way that we', 'start_time': 176.1926910903967, 'end_time': 190.87541534792976}\n",
            "{'chunk_id': 14, 'chunk_length': 14.682724257533057, 'text': \"realize that you can do it is actually in the private sector and I think that's the end. Then we went out there and we said we want to build something which is a continuation, right? I mean, fundamentally the question is the\", 'start_time': 190.87541534792976, 'end_time': 205.55813960546283}\n",
            "{'chunk_id': 15, 'chunk_length': 14.682724257533057, 'text': \"reason of what we want to do at from AI is we want to basically make generative AI available and accessible to the people in the country. And that's the intent. And when we said that we want to do this, there was\", 'start_time': 205.55813960546283, 'end_time': 220.2408638629959}\n",
            "{'chunk_id': 16, 'chunk_length': 14.682724257533057, 'text': \"a resonance in the investment community. And I think it's a responsibility to really to show that something like this can be built out of India. So we see that as confidence and a responsibility. And I also hope it's a trend that\", 'start_time': 220.2408638629959, 'end_time': 234.92358812052896}\n",
            "{'chunk_id': 17, 'chunk_length': 14.682724257533057, 'text': \"there are many more people like us who are backed because if you look at it maybe it's a large number in the Indian context but in the global context I think there should be many, many more entrepreneurs who are back to\", 'start_time': 234.92358812052896, 'end_time': 249.60631237806203}\n",
            "{'chunk_id': 18, 'chunk_length': 14.682724257533057, 'text': \"do things in India. I'm going to come back to the many more entrepreneurs. I'm obviously going to ask you about Bhavesh's Kruthram. So we're going to come back to the question but again $41 million, all of what you said, you know,\", 'start_time': 249.60631237806203, 'end_time': 264.2890366355951}\n",
            "{'chunk_id': 19, 'chunk_length': 14.682724257533057, 'text': \"$2 million, you know, that's a good amount of money for a startup which, you know, which has not yet built anything. What are you going to do with all this money? I can solve the problem. I can have a perfect solution\", 'start_time': 264.2890366355951, 'end_time': 278.97176089312813}\n",
            "{'chunk_id': 20, 'chunk_length': 14.682724257533057, 'text': \"for the problem. I think in the last week I've got lots of calls from lots of people telling me how I can do it. No, but... I know you first, okay? I'll be landed in the country the same day. I'm in\", 'start_time': 278.97176089312813, 'end_time': 293.6544851506612}\n",
            "{'chunk_id': 21, 'chunk_length': 14.682724257533057, 'text': 'front of the queue. No, but but but honestly I think the key thing in this is is to putting together an amazing team And we actually have an amazing team But we believe that it is talent that will drive this kind', 'start_time': 293.6544851506612, 'end_time': 308.3372094081942}\n",
            "{'chunk_id': 22, 'chunk_length': 14.682724257533057, 'text': 'of thing and so it is it is to get Get key talent and of course the other thing is compute. This is extremely Expensive compute wise to actually do these kinds of things and I think that those are the two primary', 'start_time': 308.3372094081942, 'end_time': 323.01993366572725}\n",
            "{'chunk_id': 23, 'chunk_length': 14.682724257533057, 'text': \"things that that you know We'd use this for okay I'm computing in my own head as an entrepreneur, talent, okay, you have like 20-15 people, how much are you paying these guys? But okay, we won't touch on that. But let's talk\", 'start_time': 323.01993366572725, 'end_time': 337.7026579232603}\n",
            "{'chunk_id': 24, 'chunk_length': 14.682724257533057, 'text': 'about what you guys actually built. What is Open Hathi? How would you explain Open Hathi to many people here who might not have known about it? So I think Open Hathi is, so first of all, right, we come from, I personally', 'start_time': 337.7026579232603, 'end_time': 352.38538218079333}\n",
            "{'chunk_id': 25, 'chunk_length': 14.682724257533057, 'text': 'come from the open source ecosystem and also from the DPI ecosystem. So we believe that for this to work, we need the ecosystem to be successful. And as a result of that, one of the first things we did was, hey, there', 'start_time': 352.38538218079333, 'end_time': 367.06810643832637}\n",
            "{'chunk_id': 26, 'chunk_length': 14.682724257533057, 'text': 'are these open source large language models that exist, right? I mean, everybody knows about the llama family from Meta. They also, there are others like Mistral. There are a bunch of open source, you know, large language models. And then we said,', 'start_time': 367.06810643832637, 'end_time': 381.7508306958594}\n",
            "{'chunk_id': 27, 'chunk_length': 14.682724257533057, 'text': 'is there any way that they can existing open source model and teach it language skills, right? I mean, and that is really the, you know, what we decide, what we said that can we do something like that? And is this a,', 'start_time': 381.7508306958594, 'end_time': 396.43355495339244}\n",
            "{'chunk_id': 28, 'chunk_length': 14.682724257533057, 'text': 'you know, relatively frugal way of actually, you know, making models, you know, work in diverse languages? Because the truth is still today, I mean, if you look at the amount of data and knowledge, it is still English dominates these things. And', 'start_time': 396.43355495339244, 'end_time': 411.1162792109255}\n",
            "{'chunk_id': 29, 'chunk_length': 14.682724257533057, 'text': \"I think that how do you actually take and make it understand Indian language, understand Indian context and all of those things in actually a in an efficient way. And therefore this was an attempt to do that. And it's a open hearty\", 'start_time': 411.1162792109255, 'end_time': 425.7990034684585}\n",
            "{'chunk_id': 30, 'chunk_length': 14.682724257533057, 'text': \"is you know is currently based on the llama seven billion model but we'll be releasing many more models in different languages, different sizes and things like that as part of this as part of this series. And of course you know we\", 'start_time': 425.7990034684585, 'end_time': 440.48172772599156}\n",
            "{'chunk_id': 31, 'chunk_length': 14.682724257533057, 'text': \"will be building further models on those and doing other things to actually and we'll also have endpoints that people can use so that it's not, it's definitely something that people can use to things and that's the essence of what this OpenHarp\", 'start_time': 440.48172772599156, 'end_time': 455.1644519835246}\n",
            "{'chunk_id': 32, 'chunk_length': 14.682724257533057, 'text': 'is. So what does it mean to people in the audience here who are either doing their own startups or a business or developers, how should they look at OpenAI? Sorry, Sarvam, not OpenAI. No, no, I think the way you look at', 'start_time': 455.1644519835246, 'end_time': 469.84717624105764}\n",
            "{'chunk_id': 33, 'chunk_length': 14.682724257533057, 'text': \"it is that one of the important things that we are doing is we're not just building models. We are also going to be building a platform, a platform for developers where you can actually use a combination of various different kinds of\", 'start_time': 469.84717624105764, 'end_time': 484.5299004985907}\n",
            "{'chunk_id': 34, 'chunk_length': 14.682724257533057, 'text': 'models, some which are from us, some which are open source, some which may not be open source, and actually to actually pull together and figure out how to deploy generative AI applications scale and understand and evaluate their performance in an efficient', 'start_time': 484.5299004985907, 'end_time': 499.2126247561237}\n",
            "{'chunk_id': 35, 'chunk_length': 14.682724257533057, 'text': \"manner and that's something that we are planning to do at this and this platform is you know in the next couple of months will be coming out there it will be available to developers but of course those who want to start\", 'start_time': 499.2126247561237, 'end_time': 513.8953490136568}\n",
            "{'chunk_id': 36, 'chunk_length': 14.682724257533057, 'text': \"with the open source things and hack for that of course please go ahead and do that as well. That's phenomenal but how does it compare to OpenAI itself or Google? See at least the things that we are doing now. One of\", 'start_time': 513.8953490136568, 'end_time': 528.5780732711899}\n",
            "{'chunk_id': 37, 'chunk_length': 14.682724257533057, 'text': 'the things that when we thought about building Sarvam, we said we want to build a full stack generative AI company and different people have an understanding of full stack is that we need to know how to train models from scratch. We', 'start_time': 528.5780732711899, 'end_time': 543.260797528723}\n",
            "{'chunk_id': 38, 'chunk_length': 14.682724257533057, 'text': 'need to know how to kind of figure out how to deploy models to solve real world use cases. And we need to play in the ecosystem to make sure that we can actually deploy population scale applications So we were thinking about', 'start_time': 543.260797528723, 'end_time': 557.943521786256}\n",
            "{'chunk_id': 39, 'chunk_length': 14.682724257533057, 'text': \"all of these things. But still the models we were talking about are fairly small models. They are fairly small models, right, in the seven to maybe up to 70 billion kind of range we're talking about. While these models like OpenAI and\", 'start_time': 557.943521786256, 'end_time': 572.6262460437891}\n",
            "{'chunk_id': 40, 'chunk_length': 14.682724257533057, 'text': 'Google are obviously much bigger models, right? But we want to understand the techniques and be able to build that muscle to do all of these things, to make it available to people. Now those models are, I mean, as I said, I', 'start_time': 572.6262460437891, 'end_time': 587.3089703013222}\n",
            "{'chunk_id': 41, 'chunk_length': 14.682724257533057, 'text': 'think that there is space for all of those things and I think as even Sridhar was talking about earlier in the day, we believe that these smaller models can do very, I mean, many, many kind of domain specific tasks extremely well,', 'start_time': 587.3089703013222, 'end_time': 601.9916945588553}\n",
            "{'chunk_id': 42, 'chunk_length': 14.682724257533057, 'text': \"probably even better than the larger models and that is really one of the key areas. And so therefore the value of these kinds of things, right, we are not aiming in these set of models to build any AGI. That's not our\", 'start_time': 601.9916945588553, 'end_time': 616.6744188163884}\n",
            "{'chunk_id': 43, 'chunk_length': 14.682724257533057, 'text': 'goal here. Our goal is to make things that work extremely well for domain specific use cases or increase accessibility through language and all of those kinds of things. And obviously all of this unique to India. But what is unique about India?', 'start_time': 616.6744188163884, 'end_time': 631.3571430739215}\n",
            "{'chunk_id': 44, 'chunk_length': 14.682724257533057, 'text': 'Is there anything special in our ecosystem that makes small models focused with Indian languages better for, more suited for our problems? So I think that, I mean, there are quite a few things that are unique about India, right? The first thing', 'start_time': 631.3571430739215, 'end_time': 646.0398673314546}\n",
            "{'chunk_id': 45, 'chunk_length': 14.682724257533057, 'text': \"is I think that we are a voice first nation, so therefore I think voice has to be the core to doing things. The other thing, of course, India is extremely, it's a cost conscious country from a cost perspective. Now, I would\", 'start_time': 646.0398673314546, 'end_time': 660.7225915889877}\n",
            "{'chunk_id': 46, 'chunk_length': 14.682724257533057, 'text': 'say that there are lots of interesting use cases where you can use OpenAI and the cost structure works depending on your application. But when you want to scale things to a massive level and make it work, then you have to figure', 'start_time': 660.7225915889877, 'end_time': 675.4053158465208}\n",
            "{'chunk_id': 47, 'chunk_length': 14.682724257533057, 'text': \"out how small models work. So that's something that is also specific to India. The third thing which is specific to India is really the success that India has had in building all this digital public infrastructure. When you add the AI layer\", 'start_time': 675.4053158465208, 'end_time': 690.0880401040539}\n",
            "{'chunk_id': 48, 'chunk_length': 14.682724257533057, 'text': \"on top of it, then you can actually get dramatic, you know, dramatic, I think, multiplicative combinatorial effects based on doing things like that. That's a phenomenal point. Like, you know, it's like DPI to the power of AI almost in some ways.\", 'start_time': 690.0880401040539, 'end_time': 704.770764361587}\n",
            "{'chunk_id': 49, 'chunk_length': 14.682724257533057, 'text': \"And as a part of building Aadhaar, no better person than you. So in summary, what I'm hearing is small models specialized with, trained with Indic-specific language data suited for Indian problems at a compelling cost point will be suited for us. autonomous\", 'start_time': 704.770764361587, 'end_time': 719.4534886191201}\n",
            "{'chunk_id': 50, 'chunk_length': 14.682724257533057, 'text': \"vehicles or some complex problem, we're solving some basic problems specifically focused on voice with multiple languages. That is what you see as the future. Am I paraphrasing this correctly? No, yeah. So I think that certainly, I mean, voice and Indian languages\", 'start_time': 719.4534886191201, 'end_time': 734.1362128766532}\n",
            "{'chunk_id': 51, 'chunk_length': 14.682724257533057, 'text': \"are an important part of our strategy, but we will be building custom models to solve various other kinds of problems as well. That's not just limited to, I think, in different domains, working different domains, making building things based on unique data\", 'start_time': 734.1362128766532, 'end_time': 748.8189371341863}\n",
            "{'chunk_id': 52, 'chunk_length': 14.682724257533057, 'text': \"that enterprises have and things like that. So that's something that we'll also look at. Fair enough. So coming back to the elephant in the room, no fun intended with open Hathi, what about Babesh Akarwal and Kruthrim? What is your take on\", 'start_time': 748.8189371341863, 'end_time': 763.5016613917194}\n",
            "{'chunk_id': 53, 'chunk_length': 14.682724257533057, 'text': \"that? I think it's great. I think it's wonderful, right? I mean, the fact that the technology AI is so important that we need multiple people working on it. The fact that there are other people thinking is actually validates that this is\", 'start_time': 763.5016613917194, 'end_time': 778.1843856492525}\n",
            "{'chunk_id': 54, 'chunk_length': 14.682724257533057, 'text': \"an important problem to be solved. And I think that we need everybody to come together and do that. So I really welcome that. I think it's great. And I think that there will be different people will have different takes as to\", 'start_time': 778.1843856492525, 'end_time': 792.8671099067856}\n",
            "{'chunk_id': 55, 'chunk_length': 14.682724257533057, 'text': \"how to solve this kind of problem. And hopefully as a result of that, the entire ecosystem benefits. One more question and then I want to talk about some of the predictions that you've boldly made. So Vivek, I usually ask people about\", 'start_time': 792.8671099067856, 'end_time': 807.5498341643187}\n",
            "{'chunk_id': 56, 'chunk_length': 14.682724257533057, 'text': 'what do you think the future will be and everybody usually hedges. I asked Vivek, what do you think is going to happen by December 2024? What do you think sitting in this room one year later we can expect? And he made', 'start_time': 807.5498341643187, 'end_time': 822.2325584218518}\n",
            "{'chunk_id': 57, 'chunk_length': 14.682724257533057, 'text': 'three bold predictions. So I want to talk about that. Before that, I have one last question. What are the top three applications that you think are relevant for India? You heard Sridhar talk about medical. What, you know, any quick summary, what', 'start_time': 822.2325584218518, 'end_time': 836.9152826793849}\n",
            "{'chunk_id': 58, 'chunk_length': 14.682724257533057, 'text': 'is, what do you, what do you think your the top three apps are for India for AI? So I mean I think that as you said things like education and medical are clearly areas where I think that things can can be', 'start_time': 836.9152826793849, 'end_time': 851.598006936918}\n",
            "{'chunk_id': 59, 'chunk_length': 14.682724257533057, 'text': \"leveraged. The whole idea of all these kind of the DPI aspect of it is another major application where things can happen in and here I'm talking about country specific work and I think the whole idea which Sridhar also talked about was\", 'start_time': 851.598006936918, 'end_time': 866.280731194451}\n",
            "{'chunk_id': 60, 'chunk_length': 14.682724257533057, 'text': \"the the concept of software right and I think that and clearly we have a very large software industry and how to reimagine those things in this context is also something that's going to be big. Fair enough. Are you guys ready for\", 'start_time': 866.280731194451, 'end_time': 880.9634554519841}\n",
            "{'chunk_id': 61, 'chunk_length': 14.682724257533057, 'text': \"Vivek Raghavan's bold predictions? Yes? No? I'm not hearing any yes sir. This is like a big deal. He's like one of the smartest guys that I know. He wants to make three predictions. You don't want to hear it? All right. So\", 'start_time': 880.9634554519841, 'end_time': 895.6461797095172}\n",
            "{'chunk_id': 62, 'chunk_length': 14.682724257533057, 'text': \"I asked him, what do you think, you know, a year later, what do you think we can expect? And he came up with three things and usually people give very blah answers when you ask question like this because they don't want\", 'start_time': 895.6461797095172, 'end_time': 910.3289039670503}\n",
            "{'chunk_id': 63, 'chunk_length': 14.682724257533057, 'text': \"to be caught wrong. Not Vivek. Vivek is bold. So he basically said three things and I'm going to list out the three things and then he's asking about it. So number one, he says, I would prefer to talk to an automated\", 'start_time': 910.3289039670503, 'end_time': 925.0116282245834}\n",
            "{'chunk_id': 64, 'chunk_length': 14.682724257533057, 'text': \"customer service than a real person because they'll give me a better answer. So that is Vivek Ragwan's prediction number one. So number two is that when everybody is talking about a GPU shortage, Vivek predicts that there will be a GPU glut\", 'start_time': 925.0116282245834, 'end_time': 939.6943524821165}\n",
            "{'chunk_id': 65, 'chunk_length': 14.682724257533057, 'text': 'in India. He thinks there will be too much GPU. So if you want a short NVIDIA talk, this is a good time. And number three, which was extremely unexpected, he said some companies will suddenly die. So Vivek, these are not what', 'start_time': 939.6943524821165, 'end_time': 954.3770767396496}\n",
            "{'chunk_id': 66, 'chunk_length': 14.682724257533057, 'text': \"I expected. So do you want to quickly talk about each of them, why you just came up with these and then we'll throw the open for audience questions. So I don't think I quite said it the way that Pallav is kind\", 'start_time': 954.3770767396496, 'end_time': 969.0598009971827}\n",
            "{'chunk_id': 67, 'chunk_length': 14.682724257533057, 'text': \"of making, but it's interesting. But I think the first thing that we said is I think that and I don't think that this is I think there will come a time when in areas of customer service, et cetera, when you want\", 'start_time': 969.0598009971827, 'end_time': 983.7425252547158}\n",
            "{'chunk_id': 68, 'chunk_length': 14.682724257533057, 'text': \"to do something very specific. Today, you know, when you call some kind of a bot, you actually end up, you mostly try to disconnect the call or, you know, you're extremely upset that you're talking to a bot. But I think that\", 'start_time': 983.7425252547158, 'end_time': 998.4252495122489}\n",
            "{'chunk_id': 69, 'chunk_length': 14.682724257533057, 'text': \"there will come a time, and I'm predicting it is sooner than later, that you will actually get better responses from the bot than what the human representative, at least the average human representative that you could talk to could give. And I\", 'start_time': 998.4252495122489, 'end_time': 1013.107973769782}\n",
            "{'chunk_id': 70, 'chunk_length': 14.682724257533057, 'text': \"think that that's just a, I just said that there will come a time where you know it's not a human you're talking to, but it's probably more likely to solve your intent than the human person. That's just something that I think\", 'start_time': 1013.107973769782, 'end_time': 1027.790698027315}\n",
            "{'chunk_id': 71, 'chunk_length': 14.682724257533057, 'text': \"that could happen. Okay, definitely controversial, but we'll let it go. What about the GPU glut? No, no, yeah. So I don't think that, so I think that the fact that there is a tremendous shortage right now, I think that shortage will\", 'start_time': 1027.790698027315, 'end_time': 1042.473422284848}\n",
            "{'chunk_id': 72, 'chunk_length': 14.682724257533057, 'text': 'ease because that is how the cycles of things go, right? When, you know, I think the fact that there was such a severe shortage last year, you know, basically caused a number of different players to ramp up in various kinds of', 'start_time': 1042.473422284848, 'end_time': 1057.156146542381}\n",
            "{'chunk_id': 73, 'chunk_length': 14.682724257533057, 'text': 'forms and I think that that will always go in a cycle. But you may find out that there are many, many more interesting problems that people will be able to solve. I still remember you know, we were at a Gen.AI event', 'start_time': 1057.156146542381, 'end_time': 1071.838870799914}\n",
            "{'chunk_id': 74, 'chunk_length': 14.682724257533057, 'text': \"in Bangalore and we were talking to people and we said, you know, how many people have access to, you know, four A-hundreds? This was the question that I'd asked and nobody in the room and these are all extremely enthusiastic Gen.AI people\", 'start_time': 1071.838870799914, 'end_time': 1086.521595057447}\n",
            "{'chunk_id': 75, 'chunk_length': 14.682724257533057, 'text': 'and nobody had access and I think that thing is going to change. You will be able to get these kinds of things and people who want to hack and do things will have access to these things without having to write a', 'start_time': 1086.521595057447, 'end_time': 1101.20431931498}\n",
            "{'chunk_id': 76, 'chunk_length': 14.682724257533057, 'text': \"check. Vivek is also a semiconductor guy before he went into Aadhaar. So I would take his predictions very seriously. So I don't know what I will do. I'm going to sell my NMEDIA stock. I would not do that. But that's not\", 'start_time': 1101.20431931498, 'end_time': 1115.887043572513}\n",
            "{'chunk_id': 77, 'chunk_length': 14.682724257533057, 'text': 'what I said. I want to blame you for this if it goes up. But the third one is pretty strange. Companies are born, companies die. But you said some companies will suddenly die. What does that mean? No, I think, see, I', 'start_time': 1115.887043572513, 'end_time': 1130.569767830046}\n",
            "{'chunk_id': 78, 'chunk_length': 14.682724257533057, 'text': 'think the interesting thing is, and I think that it comes back to the fundamental nature of AI. AI is a tool, right? And you have to use that. And you have to use that within your business process, right? And how AI', 'start_time': 1130.569767830046, 'end_time': 1145.252492087579}\n",
            "{'chunk_id': 79, 'chunk_length': 14.682724257533057, 'text': \"is being used. And so what's going to happen is that, I mean, I think this is true with, you know, when someone said in terms of people, they said that the people who leverage AI will be more effective than those who\", 'start_time': 1145.252492087579, 'end_time': 1159.935216345112}\n",
            "{'chunk_id': 80, 'chunk_length': 14.682724257533057, 'text': \"don't leverage AI. And that will stoop for organizations also. Organizations that leverage AI fundamentally in their core business processes will be more effective than those who don't. And I think that's the thing. And you won't know the difference until one day\", 'start_time': 1159.935216345112, 'end_time': 1174.617940602645}\n",
            "{'chunk_id': 81, 'chunk_length': 14.682724257533057, 'text': \"it becomes too obvious, and it will be too late. And I think that's the reason why everybody needs to think about what it means for your business. Because everything will be fine. Everything will be fine. And one day, somebody in your,\", 'start_time': 1174.617940602645, 'end_time': 1189.300664860178}\n",
            "{'chunk_id': 82, 'chunk_length': 14.682724257533057, 'text': \"either your competitor in your space or somebody brand new coming into your space will be reimagining your business process completely. And at that stage, you will find that it's a very big, very tall mountain to climb. And that's why I think\", 'start_time': 1189.300664860178, 'end_time': 1203.9833891177109}\n",
            "{'chunk_id': 83, 'chunk_length': 14.682724257533057, 'text': \"it's important for both people and entities to think about how they will, you know, they will upgrade themselves or they will modify their business processes to, you know, to work out this. That's a very nuanced answer and everybody here who's running\", 'start_time': 1203.9833891177109, 'end_time': 1218.6661133752439}\n",
            "{'chunk_id': 84, 'chunk_length': 14.682724257533057, 'text': \"a business should really think about it because life will be the same and then suddenly, suddenly something will, you know, then it will be a step change. Vivek, I have a few more questions but I'm sure the audience has a lot\", 'start_time': 1218.6661133752439, 'end_time': 1233.3488376327768}\n",
            "{'chunk_id': 85, 'chunk_length': 14.682724257533057, 'text': 'of questions for you. So, how are we doing on time? Okay. So, does, okay. does, okay, a lot of questions, so love to, is there a mic that we can pass around? Thank you. My name is Karthik. I work for IT', 'start_time': 1233.3488376327768, 'end_time': 1248.0315618903098}\n",
            "{'chunk_id': 86, 'chunk_length': 14.682724257533057, 'text': \"service industry. So you're saying that you're working on LLM, sorry, it's fine-tuned LLM on top of Lama. My basic question, fundamental question is we don't have a fund them foundational model for India most of the models are basically using English or\", 'start_time': 1248.0315618903098, 'end_time': 1262.7142861478428}\n",
            "{'chunk_id': 87, 'chunk_length': 14.682724257533057, 'text': 'those kind of things for example even Andrew was talking about the tokenizers and things like that so are you working on anything like that or you do you want to use mostly the existing models and run on top of it are', 'start_time': 1262.7142861478428, 'end_time': 1277.3970104053758}\n",
            "{'chunk_id': 88, 'chunk_length': 14.682724257533057, 'text': 'you going to ask a good question you have the cherry question for him so no I think the interesting thing is that if you look at and then we have actually a blog on this on our website. I think one of', 'start_time': 1277.3970104053758, 'end_time': 1292.0797346629088}\n",
            "{'chunk_id': 89, 'chunk_length': 14.682724257533057, 'text': \"the things that we've built is we actually built a customized tokenizer which actually fundamentally changes the cost of some of these generations in Indian languages and I think that we are not just fine-tuning. We are actually, we are leveraging the existing\", 'start_time': 1292.0797346629088, 'end_time': 1306.7624589204418}\n",
            "{'chunk_id': 90, 'chunk_length': 14.682724257533057, 'text': \"pre-training but we are doing what's known as continual free training which actually, but having said that you know I think I think that we have to figure out where is the data to train an extremely large model from scratch. And some\", 'start_time': 1306.7624589204418, 'end_time': 1321.4451831779747}\n",
            "{'chunk_id': 91, 'chunk_length': 14.682724257533057, 'text': 'of those things are things which will happen over time. But I think that, yes, I think that we will be doing various kinds of things. But the interesting thing is that if I want to change the accessibility problem with an existing', 'start_time': 1321.4451831779747, 'end_time': 1336.1279074355077}\n",
            "{'chunk_id': 92, 'chunk_length': 14.682724257533057, 'text': \"open source model, how do I do that? And that's the problem that we think we have solved and is going to be the heart of this open-heart series. It's extremely well explained in the blog, even I could understand it. Hi, I'm\", 'start_time': 1336.1279074355077, 'end_time': 1350.8106316930407}\n",
            "{'chunk_id': 93, 'chunk_length': 14.682724257533057, 'text': 'Prashant. I work for a fintech company. My question is, unlike China, we never had a consumer-facing application coming out from India, and in web one, web two, crypto and all. Why do you think it will be different this time in AI?', 'start_time': 1350.8106316930407, 'end_time': 1365.4933559505737}\n",
            "{'chunk_id': 94, 'chunk_length': 14.682724257533057, 'text': 'Because will the BPAI and other things will serve the same purpose what the great fire world did in China? Or do you think, like in NASA, because AI is a strategic sector, no outside country can work in NASA projects. Maybe all', 'start_time': 1365.4933559505737, 'end_time': 1380.1760802081067}\n",
            "{'chunk_id': 95, 'chunk_length': 14.682724257533057, 'text': \"government contracts will go to them. What exactly is the moat here for an Indian company? So I think the question is, I don't know the answer to these questions, right? I mean, I think that it's difficult to predict but I do\", 'start_time': 1380.1760802081067, 'end_time': 1394.8588044656397}\n",
            "{'chunk_id': 96, 'chunk_length': 14.682724257533057, 'text': \"believe and as I'm repeating that the combinatorial effect of being using GenAI at a large scale in addition along with the DPI work that we've done in India will have people and I I think that in the end, the intent is\", 'start_time': 1394.8588044656397, 'end_time': 1409.5415287231726}\n",
            "{'chunk_id': 97, 'chunk_length': 14.682724257533057, 'text': \"that people need to be able to use it and they will vote by things that are useful for them. And if that doesn't happen, you're right. I think that we have to figure out what is the mechanism of delivery of apps.\", 'start_time': 1409.5415287231726, 'end_time': 1424.2242529807056}\n",
            "{'chunk_id': 98, 'chunk_length': 14.682724257533057, 'text': \"Where do Indians consume content? That's the question. I'm so sorry, but we are out of time. Vivek will be outside, so he would be able to answer the question. Do we have time for one last question? Can I just take one\", 'start_time': 1424.2242529807056, 'end_time': 1438.9069772382386}\n",
            "{'chunk_id': 99, 'chunk_length': 14.682724257533057, 'text': \"last? Yeah. Thank you. Thank you. I'm Manish Kothari. I'm from ISBR Business School. Good that I got a chance to ask you this question. During lunchtime, there were a few of our educationists whom we were talking about and we were there\", 'start_time': 1438.9069772382386, 'end_time': 1453.5897014957716}\n",
            "{'chunk_id': 100, 'chunk_length': 14.682724257533057, 'text': 'was one from school and we are from the MBA institutions. We were thinking of these present generations. How do we get them into what you are doing? There is one thing that they have been regularly that the concentrations that they are', 'start_time': 1453.5897014957716, 'end_time': 1468.2724257533046}\n",
            "{'chunk_id': 101, 'chunk_length': 14.682724257533057, 'text': 'working on but artificial intelligence and getting into this getting them into their academics and making them a part of it is very important including the trainers who train them making them future ready into what you are doing is amazing and the', 'start_time': 1468.2724257533046, 'end_time': 1482.9551500108375}\n",
            "{'chunk_id': 102, 'chunk_length': 14.682724257533057, 'text': 'speed that with which is growing it is calling for a lot of training that needs to be done. Can you from your angle throw some light on how we could make them future ready how these people who are who are management', 'start_time': 1482.9551500108375, 'end_time': 1497.6378742683705}\n",
            "{'chunk_id': 103, 'chunk_length': 14.682724257533057, 'text': 'graduates and from schools who are coming out how do we get into this part of technology that you spoke about? No, so this is really a challenge because I think everyone will need to understand at some level what this technology does', 'start_time': 1497.6378742683705, 'end_time': 1512.3205985259035}\n",
            "{'chunk_id': 104, 'chunk_length': 14.682724257533057, 'text': 'and I think that we have to rethink how we get everyone into this and that this kind of education has to be at many different levels, right? There are from a core set of having people who are extremely good at some', 'start_time': 1512.3205985259035, 'end_time': 1527.0033227834365}\n",
            "{'chunk_id': 105, 'chunk_length': 14.682724257533057, 'text': \"and there you don't need as many, but then there are basically vast numbers of people who can actually leverage these tools. By the way, the most important thing about, I mean, maybe that's part of what makes an LLM interesting, is that\", 'start_time': 1527.0033227834365, 'end_time': 1541.6860470409695}\n",
            "{'chunk_id': 106, 'chunk_length': 14.682724257533057, 'text': 'how you use it, your mileage varies by that. And to understand how to actually leverage this in an interesting way is something that we have to widely teach many, many people. And because asking the, you know, things in the right way', 'start_time': 1541.6860470409695, 'end_time': 1556.3687712985025}\n",
            "{'chunk_id': 107, 'chunk_length': 14.682724257533057, 'text': \"and having the right kind of applications will make a huge difference to how people can use these tools. Awesome. Thank you. Thank you very much Vivek. Very good luck to Sarvam and good luck to India. I think it's going to be\", 'start_time': 1556.3687712985025, 'end_time': 1571.0514955560354}\n",
            "{'chunk_id': 108, 'chunk_length': 4.0975044439627135, 'text': 'a lot right on your shoulders. Thanks Bala. Thank you Mr. Raghavan.', 'start_time': 1571.0514955560354, 'end_time': 1575.148999999998}\n"
          ]
        }
      ],
      "source": [
        "# Print the output\n",
        "for chunk in output_list:\n",
        "    print(chunk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvayudWbB0nu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc02c20e-11f4-4a15-d23e-fc2f1507b3cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1: Congratulations to you Mr. Raghavan for that. Thank you so much for joining us. Over to you. Hi everybody. How are you? Okay, I am not hearing this at all. This is like a post-lunch energy downer or something. Let's hear it. Are\n",
            "Chunk 2: you guys awake? Yes. Alright. You better be because we have a superstar guest here. You heard the 41 million dollars and I didn't hear honestly anything she said after that. So we're going to ask for about 40 million dollars from him\n",
            "Chunk 3: by the end of this conversation, okay? But let's get started. I want to introduce Vivek and Pratyush, his co-founder who's not here. We wanted to start with playing a video of what OpenHati does. I encourage all of you to go to\n",
            "Chunk 4: the website, savrom.ai, and check it out. But let me start by introducing Vivek. Vivek is a dear friend, and he's very, very modest. One of the most modest guys that I know. But his personal journey, Vivek, you've got a PhD from\n",
            "Chunk 5: Carnegie Mellon. You started and sold the company to Magma. And Vivek and I moved back to India. We were both in the valley on the same day, actually. And you've been in India for the last 16 years. And what most people\n",
            "Chunk 6: don't know is your journey at Aadhaar. He spent 13 years selflessly at Aadhaar. Nobody would have heard of him, but he was a pioneering technology visionary behind Aadhaar, which we all take for granted today. So please give it up. Honestly, when\n",
            "Chunk 7: I think of selfless service, truly selfless service, I always think of Vivek. And since then, he also was at AI for Bharat, which we're going to touch on, where he met Pratyush's co-founder. Pratyush had a PhD from ETH at Zurich. He\n",
            "Chunk 8: was at IBM research. He was at Microsoft research playing a key role and a faculty at IIT Madras and at AI for Bharat. So that's a little brief introduction about them. These guys are modest, modest engineers. So they don't toot their\n",
            "Chunk 9: own horn. So forgive me for tooting their horn in this case. But But let's jump right in about the money, funding. 41 million bucks man, that's a lot of money, right? Every entrepreneur here is saying, what the hell did these guys\n",
            "Chunk 10: do? What did the investors see to write such a big check? No, I think it's a trend, a new trend of what's going on in India. I think that for the very first time, I think the investors have looked at, you\n",
            "Chunk 11: know, let's try and build something deep tech out of the country and let's try to figure out how to build something as a foundational technology out of the country and that's really what's what's really exciting you know and I think that\n",
            "Chunk 12: about you know as as as well I was mentioning for the past 15 years I've been kind of working in kind of you know both digital public infrastructure and and and kind of a nonprofit kind of things and but when this\n",
            "Chunk 13: whole thing of generative AI came came about, we said, okay, how can I actually make a difference in this space? And I said, maybe this is the opportunity to actually come out and really build something and the only way that we\n",
            "Chunk 14: realize that you can do it is actually in the private sector and I think that's the end. Then we went out there and we said we want to build something which is a continuation, right? I mean, fundamentally the question is the\n",
            "Chunk 15: reason of what we want to do at from AI is we want to basically make generative AI available and accessible to the people in the country. And that's the intent. And when we said that we want to do this, there was\n",
            "Chunk 16: a resonance in the investment community. And I think it's a responsibility to really to show that something like this can be built out of India. So we see that as confidence and a responsibility. And I also hope it's a trend that\n",
            "Chunk 17: there are many more people like us who are backed because if you look at it maybe it's a large number in the Indian context but in the global context I think there should be many, many more entrepreneurs who are back to\n",
            "Chunk 18: do things in India. I'm going to come back to the many more entrepreneurs. I'm obviously going to ask you about Bhavesh's Kruthram. So we're going to come back to the question but again $41 million, all of what you said, you know,\n",
            "Chunk 19: $2 million, you know, that's a good amount of money for a startup which, you know, which has not yet built anything. What are you going to do with all this money? I can solve the problem. I can have a perfect solution\n",
            "Chunk 20: for the problem. I think in the last week I've got lots of calls from lots of people telling me how I can do it. No, but... I know you first, okay? I'll be landed in the country the same day. I'm in\n",
            "Chunk 21: front of the queue. No, but but but honestly I think the key thing in this is is to putting together an amazing team And we actually have an amazing team But we believe that it is talent that will drive this kind\n",
            "Chunk 22: of thing and so it is it is to get Get key talent and of course the other thing is compute. This is extremely Expensive compute wise to actually do these kinds of things and I think that those are the two primary\n",
            "Chunk 23: things that that you know We'd use this for okay I'm computing in my own head as an entrepreneur, talent, okay, you have like 20-15 people, how much are you paying these guys? But okay, we won't touch on that. But let's talk\n",
            "Chunk 24: about what you guys actually built. What is Open Hathi? How would you explain Open Hathi to many people here who might not have known about it? So I think Open Hathi is, so first of all, right, we come from, I personally\n",
            "Chunk 25: come from the open source ecosystem and also from the DPI ecosystem. So we believe that for this to work, we need the ecosystem to be successful. And as a result of that, one of the first things we did was, hey, there\n",
            "Chunk 26: are these open source large language models that exist, right? I mean, everybody knows about the llama family from Meta. They also, there are others like Mistral. There are a bunch of open source, you know, large language models. And then we said,\n",
            "Chunk 27: is there any way that they can existing open source model and teach it language skills, right? I mean, and that is really the, you know, what we decide, what we said that can we do something like that? And is this a,\n",
            "Chunk 28: you know, relatively frugal way of actually, you know, making models, you know, work in diverse languages? Because the truth is still today, I mean, if you look at the amount of data and knowledge, it is still English dominates these things. And\n",
            "Chunk 29: I think that how do you actually take and make it understand Indian language, understand Indian context and all of those things in actually a in an efficient way. And therefore this was an attempt to do that. And it's a open hearty\n",
            "Chunk 30: is you know is currently based on the llama seven billion model but we'll be releasing many more models in different languages, different sizes and things like that as part of this as part of this series. And of course you know we\n",
            "Chunk 31: will be building further models on those and doing other things to actually and we'll also have endpoints that people can use so that it's not, it's definitely something that people can use to things and that's the essence of what this OpenHarp\n",
            "Chunk 32: is. So what does it mean to people in the audience here who are either doing their own startups or a business or developers, how should they look at OpenAI? Sorry, Sarvam, not OpenAI. No, no, I think the way you look at\n",
            "Chunk 33: it is that one of the important things that we are doing is we're not just building models. We are also going to be building a platform, a platform for developers where you can actually use a combination of various different kinds of\n",
            "Chunk 34: models, some which are from us, some which are open source, some which may not be open source, and actually to actually pull together and figure out how to deploy generative AI applications scale and understand and evaluate their performance in an efficient\n",
            "Chunk 35: manner and that's something that we are planning to do at this and this platform is you know in the next couple of months will be coming out there it will be available to developers but of course those who want to start\n",
            "Chunk 36: with the open source things and hack for that of course please go ahead and do that as well. That's phenomenal but how does it compare to OpenAI itself or Google? See at least the things that we are doing now. One of\n",
            "Chunk 37: the things that when we thought about building Sarvam, we said we want to build a full stack generative AI company and different people have an understanding of full stack is that we need to know how to train models from scratch. We\n",
            "Chunk 38: need to know how to kind of figure out how to deploy models to solve real world use cases. And we need to play in the ecosystem to make sure that we can actually deploy population scale applications So we were thinking about\n",
            "Chunk 39: all of these things. But still the models we were talking about are fairly small models. They are fairly small models, right, in the seven to maybe up to 70 billion kind of range we're talking about. While these models like OpenAI and\n",
            "Chunk 40: Google are obviously much bigger models, right? But we want to understand the techniques and be able to build that muscle to do all of these things, to make it available to people. Now those models are, I mean, as I said, I\n",
            "Chunk 41: think that there is space for all of those things and I think as even Sridhar was talking about earlier in the day, we believe that these smaller models can do very, I mean, many, many kind of domain specific tasks extremely well,\n",
            "Chunk 42: probably even better than the larger models and that is really one of the key areas. And so therefore the value of these kinds of things, right, we are not aiming in these set of models to build any AGI. That's not our\n",
            "Chunk 43: goal here. Our goal is to make things that work extremely well for domain specific use cases or increase accessibility through language and all of those kinds of things. And obviously all of this unique to India. But what is unique about India?\n",
            "Chunk 44: Is there anything special in our ecosystem that makes small models focused with Indian languages better for, more suited for our problems? So I think that, I mean, there are quite a few things that are unique about India, right? The first thing\n",
            "Chunk 45: is I think that we are a voice first nation, so therefore I think voice has to be the core to doing things. The other thing, of course, India is extremely, it's a cost conscious country from a cost perspective. Now, I would\n",
            "Chunk 46: say that there are lots of interesting use cases where you can use OpenAI and the cost structure works depending on your application. But when you want to scale things to a massive level and make it work, then you have to figure\n",
            "Chunk 47: out how small models work. So that's something that is also specific to India. The third thing which is specific to India is really the success that India has had in building all this digital public infrastructure. When you add the AI layer\n",
            "Chunk 48: on top of it, then you can actually get dramatic, you know, dramatic, I think, multiplicative combinatorial effects based on doing things like that. That's a phenomenal point. Like, you know, it's like DPI to the power of AI almost in some ways.\n",
            "Chunk 49: And as a part of building Aadhaar, no better person than you. So in summary, what I'm hearing is small models specialized with, trained with Indic-specific language data suited for Indian problems at a compelling cost point will be suited for us. autonomous\n",
            "Chunk 50: vehicles or some complex problem, we're solving some basic problems specifically focused on voice with multiple languages. That is what you see as the future. Am I paraphrasing this correctly? No, yeah. So I think that certainly, I mean, voice and Indian languages\n",
            "Chunk 51: are an important part of our strategy, but we will be building custom models to solve various other kinds of problems as well. That's not just limited to, I think, in different domains, working different domains, making building things based on unique data\n",
            "Chunk 52: that enterprises have and things like that. So that's something that we'll also look at. Fair enough. So coming back to the elephant in the room, no fun intended with open Hathi, what about Babesh Akarwal and Kruthrim? What is your take on\n",
            "Chunk 53: that? I think it's great. I think it's wonderful, right? I mean, the fact that the technology AI is so important that we need multiple people working on it. The fact that there are other people thinking is actually validates that this is\n",
            "Chunk 54: an important problem to be solved. And I think that we need everybody to come together and do that. So I really welcome that. I think it's great. And I think that there will be different people will have different takes as to\n",
            "Chunk 55: how to solve this kind of problem. And hopefully as a result of that, the entire ecosystem benefits. One more question and then I want to talk about some of the predictions that you've boldly made. So Vivek, I usually ask people about\n",
            "Chunk 56: what do you think the future will be and everybody usually hedges. I asked Vivek, what do you think is going to happen by December 2024? What do you think sitting in this room one year later we can expect? And he made\n",
            "Chunk 57: three bold predictions. So I want to talk about that. Before that, I have one last question. What are the top three applications that you think are relevant for India? You heard Sridhar talk about medical. What, you know, any quick summary, what\n",
            "Chunk 58: is, what do you, what do you think your the top three apps are for India for AI? So I mean I think that as you said things like education and medical are clearly areas where I think that things can can be\n",
            "Chunk 59: leveraged. The whole idea of all these kind of the DPI aspect of it is another major application where things can happen in and here I'm talking about country specific work and I think the whole idea which Sridhar also talked about was\n",
            "Chunk 60: the the concept of software right and I think that and clearly we have a very large software industry and how to reimagine those things in this context is also something that's going to be big. Fair enough. Are you guys ready for\n",
            "Chunk 61: Vivek Raghavan's bold predictions? Yes? No? I'm not hearing any yes sir. This is like a big deal. He's like one of the smartest guys that I know. He wants to make three predictions. You don't want to hear it? All right. So\n",
            "Chunk 62: I asked him, what do you think, you know, a year later, what do you think we can expect? And he came up with three things and usually people give very blah answers when you ask question like this because they don't want\n",
            "Chunk 63: to be caught wrong. Not Vivek. Vivek is bold. So he basically said three things and I'm going to list out the three things and then he's asking about it. So number one, he says, I would prefer to talk to an automated\n",
            "Chunk 64: customer service than a real person because they'll give me a better answer. So that is Vivek Ragwan's prediction number one. So number two is that when everybody is talking about a GPU shortage, Vivek predicts that there will be a GPU glut\n",
            "Chunk 65: in India. He thinks there will be too much GPU. So if you want a short NVIDIA talk, this is a good time. And number three, which was extremely unexpected, he said some companies will suddenly die. So Vivek, these are not what\n",
            "Chunk 66: I expected. So do you want to quickly talk about each of them, why you just came up with these and then we'll throw the open for audience questions. So I don't think I quite said it the way that Pallav is kind\n",
            "Chunk 67: of making, but it's interesting. But I think the first thing that we said is I think that and I don't think that this is I think there will come a time when in areas of customer service, et cetera, when you want\n",
            "Chunk 68: to do something very specific. Today, you know, when you call some kind of a bot, you actually end up, you mostly try to disconnect the call or, you know, you're extremely upset that you're talking to a bot. But I think that\n",
            "Chunk 69: there will come a time, and I'm predicting it is sooner than later, that you will actually get better responses from the bot than what the human representative, at least the average human representative that you could talk to could give. And I\n",
            "Chunk 70: think that that's just a, I just said that there will come a time where you know it's not a human you're talking to, but it's probably more likely to solve your intent than the human person. That's just something that I think\n",
            "Chunk 71: that could happen. Okay, definitely controversial, but we'll let it go. What about the GPU glut? No, no, yeah. So I don't think that, so I think that the fact that there is a tremendous shortage right now, I think that shortage will\n",
            "Chunk 72: ease because that is how the cycles of things go, right? When, you know, I think the fact that there was such a severe shortage last year, you know, basically caused a number of different players to ramp up in various kinds of\n",
            "Chunk 73: forms and I think that that will always go in a cycle. But you may find out that there are many, many more interesting problems that people will be able to solve. I still remember you know, we were at a Gen.AI event\n",
            "Chunk 74: in Bangalore and we were talking to people and we said, you know, how many people have access to, you know, four A-hundreds? This was the question that I'd asked and nobody in the room and these are all extremely enthusiastic Gen.AI people\n",
            "Chunk 75: and nobody had access and I think that thing is going to change. You will be able to get these kinds of things and people who want to hack and do things will have access to these things without having to write a\n",
            "Chunk 76: check. Vivek is also a semiconductor guy before he went into Aadhaar. So I would take his predictions very seriously. So I don't know what I will do. I'm going to sell my NMEDIA stock. I would not do that. But that's not\n",
            "Chunk 77: what I said. I want to blame you for this if it goes up. But the third one is pretty strange. Companies are born, companies die. But you said some companies will suddenly die. What does that mean? No, I think, see, I\n",
            "Chunk 78: think the interesting thing is, and I think that it comes back to the fundamental nature of AI. AI is a tool, right? And you have to use that. And you have to use that within your business process, right? And how AI\n",
            "Chunk 79: is being used. And so what's going to happen is that, I mean, I think this is true with, you know, when someone said in terms of people, they said that the people who leverage AI will be more effective than those who\n",
            "Chunk 80: don't leverage AI. And that will stoop for organizations also. Organizations that leverage AI fundamentally in their core business processes will be more effective than those who don't. And I think that's the thing. And you won't know the difference until one day\n",
            "Chunk 81: it becomes too obvious, and it will be too late. And I think that's the reason why everybody needs to think about what it means for your business. Because everything will be fine. Everything will be fine. And one day, somebody in your,\n",
            "Chunk 82: either your competitor in your space or somebody brand new coming into your space will be reimagining your business process completely. And at that stage, you will find that it's a very big, very tall mountain to climb. And that's why I think\n",
            "Chunk 83: it's important for both people and entities to think about how they will, you know, they will upgrade themselves or they will modify their business processes to, you know, to work out this. That's a very nuanced answer and everybody here who's running\n",
            "Chunk 84: a business should really think about it because life will be the same and then suddenly, suddenly something will, you know, then it will be a step change. Vivek, I have a few more questions but I'm sure the audience has a lot\n",
            "Chunk 85: of questions for you. So, how are we doing on time? Okay. So, does, okay. does, okay, a lot of questions, so love to, is there a mic that we can pass around? Thank you. My name is Karthik. I work for IT\n",
            "Chunk 86: service industry. So you're saying that you're working on LLM, sorry, it's fine-tuned LLM on top of Lama. My basic question, fundamental question is we don't have a fund them foundational model for India most of the models are basically using English or\n",
            "Chunk 87: those kind of things for example even Andrew was talking about the tokenizers and things like that so are you working on anything like that or you do you want to use mostly the existing models and run on top of it are\n",
            "Chunk 88: you going to ask a good question you have the cherry question for him so no I think the interesting thing is that if you look at and then we have actually a blog on this on our website. I think one of\n",
            "Chunk 89: the things that we've built is we actually built a customized tokenizer which actually fundamentally changes the cost of some of these generations in Indian languages and I think that we are not just fine-tuning. We are actually, we are leveraging the existing\n",
            "Chunk 90: pre-training but we are doing what's known as continual free training which actually, but having said that you know I think I think that we have to figure out where is the data to train an extremely large model from scratch. And some\n",
            "Chunk 91: of those things are things which will happen over time. But I think that, yes, I think that we will be doing various kinds of things. But the interesting thing is that if I want to change the accessibility problem with an existing\n",
            "Chunk 92: open source model, how do I do that? And that's the problem that we think we have solved and is going to be the heart of this open-heart series. It's extremely well explained in the blog, even I could understand it. Hi, I'm\n",
            "Chunk 93: Prashant. I work for a fintech company. My question is, unlike China, we never had a consumer-facing application coming out from India, and in web one, web two, crypto and all. Why do you think it will be different this time in AI?\n",
            "Chunk 94: Because will the BPAI and other things will serve the same purpose what the great fire world did in China? Or do you think, like in NASA, because AI is a strategic sector, no outside country can work in NASA projects. Maybe all\n",
            "Chunk 95: government contracts will go to them. What exactly is the moat here for an Indian company? So I think the question is, I don't know the answer to these questions, right? I mean, I think that it's difficult to predict but I do\n",
            "Chunk 96: believe and as I'm repeating that the combinatorial effect of being using GenAI at a large scale in addition along with the DPI work that we've done in India will have people and I I think that in the end, the intent is\n",
            "Chunk 97: that people need to be able to use it and they will vote by things that are useful for them. And if that doesn't happen, you're right. I think that we have to figure out what is the mechanism of delivery of apps.\n",
            "Chunk 98: Where do Indians consume content? That's the question. I'm so sorry, but we are out of time. Vivek will be outside, so he would be able to answer the question. Do we have time for one last question? Can I just take one\n",
            "Chunk 99: last? Yeah. Thank you. Thank you. I'm Manish Kothari. I'm from ISBR Business School. Good that I got a chance to ask you this question. During lunchtime, there were a few of our educationists whom we were talking about and we were there\n",
            "Chunk 100: was one from school and we are from the MBA institutions. We were thinking of these present generations. How do we get them into what you are doing? There is one thing that they have been regularly that the concentrations that they are\n",
            "Chunk 101: working on but artificial intelligence and getting into this getting them into their academics and making them a part of it is very important including the trainers who train them making them future ready into what you are doing is amazing and the\n",
            "Chunk 102: speed that with which is growing it is calling for a lot of training that needs to be done. Can you from your angle throw some light on how we could make them future ready how these people who are who are management\n",
            "Chunk 103: graduates and from schools who are coming out how do we get into this part of technology that you spoke about? No, so this is really a challenge because I think everyone will need to understand at some level what this technology does\n",
            "Chunk 104: and I think that we have to rethink how we get everyone into this and that this kind of education has to be at many different levels, right? There are from a core set of having people who are extremely good at some\n",
            "Chunk 105: and there you don't need as many, but then there are basically vast numbers of people who can actually leverage these tools. By the way, the most important thing about, I mean, maybe that's part of what makes an LLM interesting, is that\n",
            "Chunk 106: how you use it, your mileage varies by that. And to understand how to actually leverage this in an interesting way is something that we have to widely teach many, many people. And because asking the, you know, things in the right way\n",
            "Chunk 107: and having the right kind of applications will make a huge difference to how people can use these tools. Awesome. Thank you. Thank you very much Vivek. Very good luck to Sarvam and good luck to India. I think it's going to be\n",
            "Chunk 108: a lot right on your shoulders. Thanks Bala. Thank you Mr. Raghavan.\n"
          ]
        }
      ],
      "source": [
        "# Get the total duration of the audio\n",
        "total_duration = get_audio_duration(audio_path)\n",
        "\n",
        "# Perform semantic chunking\n",
        "chunks = semantic_chunking(transcript, total_duration)\n",
        "for i, chunk in enumerate(chunks):\n",
        "    print(f\"Chunk {i+1}: {chunk}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvxZEmX5Dto8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18f7bfc9-9501-4f74-a775-1cb1a3009fdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a01DF3smVmK8"
      },
      "source": [
        "**Bonus-1: Gradio-App Interface:**\n",
        "To create a Gradio app that takes a YouTube link as input and displays the semantic chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQmMRf_qNLDy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "outputId": "4a37a3f3-c362-422c-e6f9-8f1109dd77a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "INFO:huggingsound.speech_recognition.model:Loading model...\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://49c84d9bebb5015431.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://49c84d9bebb5015431.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from pytube import YouTube\n",
        "import os\n",
        "from huggingsound import SpeechRecognitionModel\n",
        "import torch\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Ensure necessary data is downloaded\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Define the device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Initialize the speech recognition model\n",
        "model = SpeechRecognitionModel(\"jonatasgrosman/wav2vec2-large-xlsr-53-english\", device=device)\n",
        "\n",
        "def transcribe_youtube_video(url):\n",
        "    # Download video and extract audio\n",
        "    yt = YouTube(url)\n",
        "    audio_stream = yt.streams.filter(only_audio=True, file_extension='mp4').first()\n",
        "    audio_stream.download(filename='ytaudio.mp4')\n",
        "    os.system('ffmpeg -i ytaudio.mp4 -acodec pcm_s16le -ar 16000 ytaudio.wav')\n",
        "\n",
        "    # Stream over 15 seconds chunks\n",
        "    input_file = 'ytaudio.wav'\n",
        "    stream = librosa.stream(\n",
        "        input_file,\n",
        "        block_length=15,\n",
        "        frame_length=16000,\n",
        "        hop_length=16000\n",
        "    )\n",
        "\n",
        "    # Create directory to save chunks\n",
        "    os.makedirs('chunks', exist_ok=True)\n",
        "\n",
        "    # Save the chunks\n",
        "    for i, speech in enumerate(stream):\n",
        "        sf.write(f'chunks/{i}.wav', speech, 16000)\n",
        "\n",
        "    # List of paths to chunk files\n",
        "    audio_paths = [f'chunks/{i}.wav' for i in range(len(os.listdir('chunks')))]\n",
        "\n",
        "    # Transcribe the chunks\n",
        "    transcriptions = model.transcribe(audio_paths)\n",
        "\n",
        "    # Combine the transcriptions\n",
        "    full_transcript = ' '.join([''.join(item['transcription']) for item in transcriptions])\n",
        "\n",
        "    # Segment the full transcript into sentences\n",
        "    sentences = sent_tokenize(full_transcript)\n",
        "\n",
        "    # Generate the output list\n",
        "    output_list = []\n",
        "    current_start_time = 0.0\n",
        "\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        # Calculate the length of the sentence audio chunk\n",
        "        duration = librosa.get_duration(filename=audio_paths[i])\n",
        "        chunk_length = min(15.0, duration)\n",
        "\n",
        "        output_list.append({\n",
        "            \"chunk_id\": i + 1,\n",
        "            \"chunk_length\": chunk_length,\n",
        "            \"text\": sentence,\n",
        "            \"start_time\": current_start_time,\n",
        "            \"end_time\": current_start_time + chunk_length\n",
        "        })\n",
        "\n",
        "        # Update the current start time\n",
        "        current_start_time += chunk_length\n",
        "\n",
        "    return output_list\n",
        "\n",
        "# Create the Gradio interface\n",
        "gr_interface = gr.Interface(\n",
        "    fn=transcribe_youtube_video,\n",
        "    inputs=gr.Textbox(lines=1, placeholder=\"https://www.youtube.com/watch?v=Sby1uJ_NFIY\"),\n",
        "    outputs=gr.JSON(),\n",
        "    title=\"YouTube Video Semantic Chunker\",\n",
        "    description=\"Enter a YouTube URL to get semantic chunks of the video's audio.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio app\n",
        "gr_interface.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54UForsOVJLP"
      },
      "source": [
        "**Bonus-2: Utilizing Ground-Truth Transcripts:**\n",
        "To improve transcription quality using a ground-truth transcript, you can use alignment algorithms such as Dynamic Time Warping (DTW). Here’s an outline of how you might approach this:\n",
        "\n",
        "Transcribe the audio using the ASR model.\n",
        "Align the ASR output with the ground-truth transcript using DTW to find the best matching segments.\n",
        "Correct the ASR output based on the alignment, replacing ASR segments with ground-truth text where appropriate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ve1ScWAXCP1"
      },
      "source": [
        "\n",
        "Explanation:\n",
        "\n",
        "1. **Tokenization**: The ASR transcription and the ground truth transcription are tokenized into words using `nltk.word_tokenize`.\n",
        "2. **Cost Matrix Initialization**: A cost matrix is initialized where the cost of mismatching words is set to 1, and matching words is 0.\n",
        "3. **DTW Algorithm**: The cost matrix is filled based on the minimal cost path using dynamic time warping.\n",
        "4. **Alignment**: The best alignment path is traced back from the bottom-right to the top-left of the cost matrix.\n",
        "5. **Correction**: The corrected transcription is generated based on the alignment.\n",
        "\n",
        "This code ensures that your ASR transcription is aligned with the ground truth transcription, improving the overall quality of the transcription."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr4mM04rZjld"
      },
      "source": [
        "Method to Improve Transcript Quality Using Ground-Truth Transcript\n",
        "Hypothesis:\n",
        "\n",
        "By aligning the ASR-generated transcript with a provided ground-truth transcript using dynamic time warping (DTW) or similar alignment techniques, we can significantly improve the accuracy of the ASR output. The alignment process will correct errors in the ASR transcript by matching the ASR tokens with the corresponding ground-truth tokens, thereby leveraging the high-quality ground-truth data to refine the transcription.\n",
        "\n",
        "Proposed Method:\n",
        "Preprocessing:\n",
        "\n",
        "Tokenization: Tokenize both the ASR-generated transcript and the ground-truth transcript into words or subwords. This ensures that the alignment process works at the appropriate granularity.\n",
        "Normalization: Convert both transcripts to a common format (e.g., lowercasing, removing punctuation) to minimize mismatches due to case or punctuation differences.\n",
        "Dynamic Time Warping (DTW) Alignment:\n",
        "\n",
        "Cost Matrix Calculation: Use DTW to compute a cost matrix based on word similarity. The cost can be defined as 0 for exact matches and 1 for mismatches, with penalties for insertions and deletions.\n",
        "Alignment Path: Trace back through the cost matrix to find the optimal alignment path between the ASR transcript and the ground-truth transcript.\n",
        "Transcript Correction:\n",
        "\n",
        "Alignment Mapping: Map the ASR tokens to the corresponding ground-truth tokens using the alignment path.\n",
        "Correction Application: Replace the ASR tokens with the ground-truth tokens as per the alignment, thereby correcting errors in the ASR transcript.\n",
        "Post-processing:\n",
        "\n",
        "Formatting: Convert the corrected transcript back to its original format (e.g., reinserting punctuation, restoring case).\n",
        "Validation: Optionally, validate the corrected transcript against the audio to ensure that the alignment did not introduce new errors.\n",
        "Implementation Steps:\n",
        "Tokenization and Normalization:\n",
        "\n",
        "Tokenize and normalize both transcripts to ensure consistency in the alignment process.\n",
        "DTW-based Alignment:\n",
        "\n",
        "Use DTW to align the ASR and ground-truth tokens, calculating the optimal path that minimizes the alignment cost.\n",
        "Correction Application:\n",
        "\n",
        "Replace ASR tokens with ground-truth tokens based on the DTW alignment, ensuring that each ASR token is matched with the most appropriate ground-truth token.\n",
        "Advantages of This Approach:\n",
        "Precision\n",
        "Error Correction\n",
        "Context Preservation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtCnLO2MOkPR",
        "outputId": "8c84db43-0414-4c72-c47a-4619f7efbee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-3.0.4-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Collecting rapidfuzz<4,>=3 (from jiwer)\n",
            "  Downloading rapidfuzz-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.0.4 rapidfuzz-3.9.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy**"
      ],
      "metadata": {
        "id": "31gE9Ogd6x1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from jiwer import wer, cer\n",
        "\n",
        "# Initialize the Whisper pipeline\n",
        "whisper = pipeline('automatic-speech-recognition', model='openai/whisper-medium')\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    result = whisper(audio_path)\n",
        "    return result['text']\n",
        "\n",
        "def evaluate_transcriptions(audio_paths, ground_truths):\n",
        "    total_wer = 0\n",
        "    total_cer = 0\n",
        "    for audio_path, ground_truth in zip(audio_paths, ground_truths):\n",
        "        predicted_transcription = transcribe_audio(audio_path)\n",
        "        total_wer += wer(ground_truth, predicted_transcription)\n",
        "        total_cer += cer(ground_truth, predicted_transcription)\n",
        "    average_wer = total_wer / len(audio_paths)\n",
        "    average_cer = total_cer / len(audio_paths)\n",
        "    return average_wer, average_cer\n",
        "\n",
        "# Example data\n",
        "audio_paths = [\"/content/audio\"]\n",
        "ground_truths = [\"ground truth for audio1\"]\n",
        "\n",
        "# Evaluate the model\n",
        "average_wer, average_cer = evaluate_transcriptions(audio_paths, ground_truths)\n",
        "print(f\"Average WER: {average_wer}\")\n",
        "print(f\"Average CER: {average_cer}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k9y-1fP6wRK",
        "outputId": "07efcfb4-4d00-4561-d008-4d8a59f708cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average WER: 1152.75\n",
            "Average CER: 1068.304347826087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPwUuRt9Zta5"
      },
      "source": [
        "**Task-2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR73F_rD1We4"
      },
      "source": [
        "Importing Necessary Modules for Web Scrapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_J0-Rd81XdM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b84d04ba-fc07-4b79-fe1a-52873ea5de5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.21.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.25.1-py3-none-any.whl (467 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.7/467.7 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.6.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.7)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.21.0 trio-0.25.1 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3j31XaS1gCZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e15ac601-7b74-4140-dbbb-1a0d30f179c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting webdriver_manager\n",
            "  Downloading webdriver_manager-4.0.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from webdriver_manager) (2.31.0)\n",
            "Collecting python-dotenv (from webdriver_manager)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from webdriver_manager) (24.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver_manager) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver_manager) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver_manager) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver_manager) (2024.6.2)\n",
            "Installing collected packages: python-dotenv, webdriver_manager\n",
            "Successfully installed python-dotenv-1.0.1 webdriver_manager-4.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install webdriver_manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLEFrxdK1juE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e095d283-0fdd-4551-a220-cdbdd1770a1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.21.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.25.1)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.6.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "pip install selenium requests beautifulsoup4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsUdLoV21rwY"
      },
      "source": [
        "Web Scrapping using Selenium and Beautiful Soup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DT2Aq2zA1rML"
      },
      "outputs": [],
      "source": [
        " #Books and their chapter counts\n",
        "info = {'MAT': 28, 'MRK': 16,'LUK':24,'JHN':21,'ACT':21,'ROM':11,'1CO':16,'2CO':13,'GAL':6,\n",
        "         'EPH':6,'PHP':4,'COL':4,'1TH':5,'2TH':3,'1TI':6,'2TI':4,'TIT':3,'PHM':1,'HEB':13,'JAS':5,\n",
        "         '1PE':5,'2PE':3,'1JN':5,'2JN':1,'3JN':1,'JUD':1,'REV':22}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oH0jCNZ13-X"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.by import By"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JytHyksO2ESG"
      },
      "outputs": [],
      "source": [
        "# Global settings\n",
        "text_dir = 'text_files'  # Directory to save text files\n",
        "audio_dir = 'audio_files'  # Directory to save audio files\n",
        "base_url = 'https://live.bible.is/bible/MALNIB/'  # Base URL for the Bible website\n",
        "page_load_timeout = 50  # Page load timeout in seconds\n",
        "implicit_wait_time = 40  # Implicit wait time for Selenium in seconds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYUXL1mm2PyL"
      },
      "outputs": [],
      "source": [
        "def download_file(url, filename):\n",
        "    \"\"\"\n",
        "    Downloads a file from a URL and saves it locally.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url)  # Send a GET request to the URL\n",
        "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "        with open(filename, 'wb') as file:  # Open a file for writing in binary mode\n",
        "            file.write(response.content)  # Write the content of the response to the file\n",
        "        print(f\"Downloaded: {filename}\")  # Print success message\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Failed to download {url}: {e}\")  # Print error message if download fails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87Um94IW2StZ"
      },
      "outputs": [],
      "source": [
        "def extract_text(chapter_url):\n",
        "    \"\"\"\n",
        "    Extracts text from a chapter URL.\n",
        "    \"\"\"\n",
        "    text_content = ''\n",
        "    try:\n",
        "        response = requests.get(chapter_url)  # Send a GET request to the chapter URL\n",
        "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')  # Parse the HTML content with BeautifulSoup\n",
        "        verse_elements = soup.find_all(\"span\", {\"data-verseid\": True})  # Find all span elements with a data-verseid attribute\n",
        "        text_content = \"\\n\".join(verse.get_text(strip=True) for verse in verse_elements)  # Extract text from each verse element and join with newline\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Failed to extract text from {chapter_url}: {e}\")  # Print error message if extraction fails\n",
        "    return text_content  # Return the extracted text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWKD6cw22Yum"
      },
      "outputs": [],
      "source": [
        "def extract_audio(chapter_url):\n",
        "    \"\"\"\n",
        "    Extracts audio URLs from a chapter URL.\n",
        "    \"\"\"\n",
        "    audio_urls = []\n",
        "    try:\n",
        "        chrome_options = Options()\n",
        "        chrome_options.add_argument('--headless')  # Run Chrome in headless mode (without GUI)\n",
        "        chrome_options.add_argument('--no-sandbox')  # Disable the sandbox for Chrome\n",
        "        chrome_options.add_argument('--disable-dev-shm-usage')  # Disable shared memory usage for Chrome\n",
        "        chrome_options.add_argument('--enable-javascript')  # Enable JavaScript in Chrome\n",
        "\n",
        "        driver = webdriver.Chrome(options=chrome_options)  # Initialize the Chrome WebDriver with the specified options\n",
        "        driver.set_page_load_timeout(page_load_timeout)  # Set the page load timeout\n",
        "        driver.implicitly_wait(implicit_wait_time)  # Set the implicit wait time\n",
        "\n",
        "        driver.get(chapter_url)  # Navigate to the chapter URL\n",
        "        wait = WebDriverWait(driver, 150)  # Initialize a WebDriverWait with a timeout of 150 seconds\n",
        "        wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"audio-player-background\")))  # Wait until the audio player background is present\n",
        "\n",
        "        soup = BeautifulSoup(driver.page_source, \"html.parser\")  # Parse the page source with BeautifulSoup\n",
        "\n",
        "        audio_players = soup.find_all(\"video\", {\"class\": \"audio-player\"})  # Find all video elements with the class \"audio-player\"\n",
        "        audio_urls = [audio_player.get(\"src\") for audio_player in audio_players if audio_player.has_attr(\"src\")]  # Extract the src attribute of each audio player\n",
        "\n",
        "        driver.quit()  # Quit the WebDriver\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to extract audio from {chapter_url}: {e}\")  # Print error message if extraction fails\n",
        "        if driver:\n",
        "            driver.quit()  # Quit the WebDriver if an exception occurs\n",
        "    return audio_urls  # Return the list of audio URL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JlDZz_w2lRX"
      },
      "outputs": [],
      "source": [
        "def extract_text_and_audio(book_id, chapter):\n",
        "    \"\"\"\n",
        "    Extracts text and audio from a specific chapter of a book.\n",
        "    \"\"\"\n",
        "    chapter_url = f\"{base_url}/{book_id}/{chapter}\"  # Construct the chapter URL\n",
        "\n",
        "    text_content = extract_text(chapter_url)  # Extract text from the chapter URL\n",
        "    text_filename = os.path.join(text_dir, f\"{book_id}_{chapter}.txt\")  # Construct the text filename\n",
        "    with open(text_filename, \"w\", encoding=\"utf-8\") as text_file:  # Open the text file for writing with UTF-8 encoding\n",
        "        text_file.write(text_content)  # Write the extracted text to the file\n",
        "    print(f\"Saved text: {text_filename}\")  # Print success message\n",
        "\n",
        "    audio_urls = extract_audio(chapter_url)  # Extract audio URLs from the chapter URL\n",
        "    for idx, audio_url in enumerate(audio_urls, start=1):  # Iterate over the audio URLs\n",
        "        if audio_url:\n",
        "            audio_filename = os.path.join(audio_dir, f\"{book_id}_{chapter}_{idx}.mp3\")  # Construct the audio filename\n",
        "            download_file(audio_url, audio_filename)  # Download the audio file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4KIEltC2pkW"
      },
      "outputs": [],
      "source": [
        "def extract_all_text_and_audio():\n",
        "    \"\"\"\n",
        "    Extracts text and audio for all chapters of all books.\n",
        "    \"\"\"\n",
        "    os.makedirs(text_dir, exist_ok=True)  # Create the text directory if it doesn't exist\n",
        "    os.makedirs(audio_dir, exist_ok=True)  # Create the audio directory if it doesn't exist\n",
        "\n",
        "    # Process each book in the info dictionary\n",
        "    for book_id, num_chapters in info.items():  # Iterate over the books and their chapter counts\n",
        "        print('Processing book', book_id)  # Print the book ID being processed\n",
        "        for chapter in range(1, num_chapters + 1):  # Iterate over the chapters of the book\n",
        "            extract_text_and_audio(book_id, chapter)  # Extract text and audio for the chapter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPByEw-u2vw-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6130d30-ed71-4aa0-e026-d423de8b7955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing book MAT\n",
            "Saved text: text_files/MAT_1.txt\n",
            "Downloaded: audio_files/MAT_1_1.mp3\n",
            "Failed to extract text from https://live.bible.is/bible/MALNIB//MAT/2: 500 Server Error: Internal Server Error for url: https://live.bible.is/bible/MALNIB/MAT/2\n",
            "Saved text: text_files/MAT_2.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//MAT/2: Message: \n",
            "Stacktrace:\n",
            "#0 0x5b25181936aa <unknown>\n",
            "#1 0x5b2517e760dc <unknown>\n",
            "#2 0x5b2517ec2931 <unknown>\n",
            "#3 0x5b2517ec2a21 <unknown>\n",
            "#4 0x5b2517f07234 <unknown>\n",
            "#5 0x5b2517ee589d <unknown>\n",
            "#6 0x5b2517f045c3 <unknown>\n",
            "#7 0x5b2517ee5613 <unknown>\n",
            "#8 0x5b2517eb54f7 <unknown>\n",
            "#9 0x5b2517eb5e4e <unknown>\n",
            "#10 0x5b251815987b <unknown>\n",
            "#11 0x5b251815d921 <unknown>\n",
            "#12 0x5b251814536e <unknown>\n",
            "#13 0x5b251815e482 <unknown>\n",
            "#14 0x5b2518129ccf <unknown>\n",
            "#15 0x5b25181830a8 <unknown>\n",
            "#16 0x5b2518183280 <unknown>\n",
            "#17 0x5b25181927dc <unknown>\n",
            "#18 0x7ee192b3aac3 <unknown>\n",
            "\n",
            "Saved text: text_files/MAT_3.txt\n",
            "Downloaded: audio_files/MAT_3_1.mp3\n",
            "Saved text: text_files/MAT_4.txt\n",
            "Downloaded: audio_files/MAT_4_1.mp3\n",
            "Saved text: text_files/MAT_5.txt\n",
            "Downloaded: audio_files/MAT_5_1.mp3\n",
            "Saved text: text_files/MAT_6.txt\n",
            "Downloaded: audio_files/MAT_6_1.mp3\n",
            "Saved text: text_files/MAT_7.txt\n",
            "Downloaded: audio_files/MAT_7_1.mp3\n",
            "Saved text: text_files/MAT_8.txt\n",
            "Downloaded: audio_files/MAT_8_1.mp3\n",
            "Saved text: text_files/MAT_9.txt\n",
            "Downloaded: audio_files/MAT_9_1.mp3\n",
            "Saved text: text_files/MAT_10.txt\n",
            "Downloaded: audio_files/MAT_10_1.mp3\n",
            "Saved text: text_files/MAT_11.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/MAT_12.txt\n",
            "Downloaded: audio_files/MAT_12_1.mp3\n",
            "Saved text: text_files/MAT_13.txt\n",
            "Downloaded: audio_files/MAT_13_1.mp3\n",
            "Saved text: text_files/MAT_14.txt\n",
            "Downloaded: audio_files/MAT_14_1.mp3\n",
            "Saved text: text_files/MAT_15.txt\n",
            "Downloaded: audio_files/MAT_15_1.mp3\n",
            "Saved text: text_files/MAT_16.txt\n",
            "Downloaded: audio_files/MAT_16_1.mp3\n",
            "Saved text: text_files/MAT_17.txt\n",
            "Downloaded: audio_files/MAT_17_1.mp3\n",
            "Saved text: text_files/MAT_18.txt\n",
            "Downloaded: audio_files/MAT_18_1.mp3\n",
            "Saved text: text_files/MAT_19.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/MAT_20.txt\n",
            "Downloaded: audio_files/MAT_20_1.mp3\n",
            "Saved text: text_files/MAT_21.txt\n",
            "Downloaded: audio_files/MAT_21_1.mp3\n",
            "Saved text: text_files/MAT_22.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/MAT_23.txt\n",
            "Downloaded: audio_files/MAT_23_1.mp3\n",
            "Saved text: text_files/MAT_24.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/MAT_25.txt\n",
            "Downloaded: audio_files/MAT_25_1.mp3\n",
            "Saved text: text_files/MAT_26.txt\n",
            "Downloaded: audio_files/MAT_26_1.mp3\n",
            "Saved text: text_files/MAT_27.txt\n",
            "Downloaded: audio_files/MAT_27_1.mp3\n",
            "Saved text: text_files/MAT_28.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Processing book MRK\n",
            "Saved text: text_files/MRK_1.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/MRK_2.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/MRK_3.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/MRK_4.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/MRK_5.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//MRK/5: Message: \n",
            "Stacktrace:\n",
            "#0 0x5640434786aa <unknown>\n",
            "#1 0x56404315b0dc <unknown>\n",
            "#2 0x5640431a7931 <unknown>\n",
            "#3 0x5640431a7a21 <unknown>\n",
            "#4 0x5640431ec234 <unknown>\n",
            "#5 0x5640431ca89d <unknown>\n",
            "#6 0x5640431e95c3 <unknown>\n",
            "#7 0x5640431ca613 <unknown>\n",
            "#8 0x56404319a4f7 <unknown>\n",
            "#9 0x56404319ae4e <unknown>\n",
            "#10 0x56404343e87b <unknown>\n",
            "#11 0x564043442921 <unknown>\n",
            "#12 0x56404342a36e <unknown>\n",
            "#13 0x564043443482 <unknown>\n",
            "#14 0x56404340eccf <unknown>\n",
            "#15 0x5640434680a8 <unknown>\n",
            "#16 0x564043468280 <unknown>\n",
            "#17 0x5640434777dc <unknown>\n",
            "#18 0x7c4df6368ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/MRK_6.txt\n",
            "Downloaded: audio_files/MRK_6_1.mp3\n",
            "Saved text: text_files/MRK_7.txt\n",
            "Downloaded: audio_files/MRK_7_1.mp3\n",
            "Saved text: text_files/MRK_8.txt\n",
            "Downloaded: audio_files/MRK_8_1.mp3\n",
            "Saved text: text_files/MRK_9.txt\n",
            "Downloaded: audio_files/MRK_9_1.mp3\n",
            "Saved text: text_files/MRK_10.txt\n",
            "Downloaded: audio_files/MRK_10_1.mp3\n",
            "Saved text: text_files/MRK_11.txt\n",
            "Downloaded: audio_files/MRK_11_1.mp3\n",
            "Saved text: text_files/MRK_12.txt\n",
            "Downloaded: audio_files/MRK_12_1.mp3\n",
            "Saved text: text_files/MRK_13.txt\n",
            "Downloaded: audio_files/MRK_13_1.mp3\n",
            "Saved text: text_files/MRK_14.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/MRK_15.txt\n",
            "Downloaded: audio_files/MRK_15_1.mp3\n",
            "Saved text: text_files/MRK_16.txt\n",
            "Downloaded: audio_files/MRK_16_1.mp3\n",
            "Processing book LUK\n",
            "Saved text: text_files/LUK_1.txt\n",
            "Downloaded: audio_files/LUK_1_1.mp3\n",
            "Saved text: text_files/LUK_2.txt\n",
            "Downloaded: audio_files/LUK_2_1.mp3\n",
            "Saved text: text_files/LUK_3.txt\n",
            "Downloaded: audio_files/LUK_3_1.mp3\n",
            "Saved text: text_files/LUK_4.txt\n",
            "Downloaded: audio_files/LUK_4_1.mp3\n",
            "Saved text: text_files/LUK_5.txt\n",
            "Downloaded: audio_files/LUK_5_1.mp3\n",
            "Saved text: text_files/LUK_6.txt\n",
            "Downloaded: audio_files/LUK_6_1.mp3\n",
            "Saved text: text_files/LUK_7.txt\n",
            "Downloaded: audio_files/LUK_7_1.mp3\n",
            "Saved text: text_files/LUK_8.txt\n",
            "Downloaded: audio_files/LUK_8_1.mp3\n",
            "Saved text: text_files/LUK_9.txt\n",
            "Downloaded: audio_files/LUK_9_1.mp3\n",
            "Saved text: text_files/LUK_10.txt\n",
            "Downloaded: audio_files/LUK_10_1.mp3\n",
            "Saved text: text_files/LUK_11.txt\n",
            "Downloaded: audio_files/LUK_11_1.mp3\n",
            "Saved text: text_files/LUK_12.txt\n",
            "Downloaded: audio_files/LUK_12_1.mp3\n",
            "Saved text: text_files/LUK_13.txt\n",
            "Downloaded: audio_files/LUK_13_1.mp3\n",
            "Saved text: text_files/LUK_14.txt\n",
            "Downloaded: audio_files/LUK_14_1.mp3\n",
            "Saved text: text_files/LUK_15.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/LUK_16.txt\n",
            "Downloaded: audio_files/LUK_16_1.mp3\n",
            "Saved text: text_files/LUK_17.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/LUK_18.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/LUK_19.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/LUK_20.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//LUK/20: Message: \n",
            "Stacktrace:\n",
            "#0 0x579db8c5f6aa <unknown>\n",
            "#1 0x579db89420dc <unknown>\n",
            "#2 0x579db898e931 <unknown>\n",
            "#3 0x579db898ea21 <unknown>\n",
            "#4 0x579db89d3234 <unknown>\n",
            "#5 0x579db89b189d <unknown>\n",
            "#6 0x579db89d05c3 <unknown>\n",
            "#7 0x579db89b1613 <unknown>\n",
            "#8 0x579db89814f7 <unknown>\n",
            "#9 0x579db8981e4e <unknown>\n",
            "#10 0x579db8c2587b <unknown>\n",
            "#11 0x579db8c29921 <unknown>\n",
            "#12 0x579db8c1136e <unknown>\n",
            "#13 0x579db8c2a482 <unknown>\n",
            "#14 0x579db8bf5ccf <unknown>\n",
            "#15 0x579db8c4f0a8 <unknown>\n",
            "#16 0x579db8c4f280 <unknown>\n",
            "#17 0x579db8c5e7dc <unknown>\n",
            "#18 0x7ea62db63ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/LUK_21.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//LUK/21: Message: \n",
            "Stacktrace:\n",
            "#0 0x55a270ecd6aa <unknown>\n",
            "#1 0x55a270bb00dc <unknown>\n",
            "#2 0x55a270bfc931 <unknown>\n",
            "#3 0x55a270bfca21 <unknown>\n",
            "#4 0x55a270c41234 <unknown>\n",
            "#5 0x55a270c1f89d <unknown>\n",
            "#6 0x55a270c3e5c3 <unknown>\n",
            "#7 0x55a270c1f613 <unknown>\n",
            "#8 0x55a270bef4f7 <unknown>\n",
            "#9 0x55a270befe4e <unknown>\n",
            "#10 0x55a270e9387b <unknown>\n",
            "#11 0x55a270e97921 <unknown>\n",
            "#12 0x55a270e7f36e <unknown>\n",
            "#13 0x55a270e98482 <unknown>\n",
            "#14 0x55a270e63ccf <unknown>\n",
            "#15 0x55a270ebd0a8 <unknown>\n",
            "#16 0x55a270ebd280 <unknown>\n",
            "#17 0x55a270ecc7dc <unknown>\n",
            "#18 0x7ad183488ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/LUK_22.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/LUK_23.txt\n",
            "Downloaded: audio_files/LUK_23_1.mp3\n",
            "Saved text: text_files/LUK_24.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Processing book JHN\n",
            "Saved text: text_files/JHN_1.txt\n",
            "Downloaded: audio_files/JHN_1_1.mp3\n",
            "Saved text: text_files/JHN_2.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/JHN_3.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/JHN_4.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//JHN/4: Message: \n",
            "Stacktrace:\n",
            "#0 0x594e65d946aa <unknown>\n",
            "#1 0x594e65a770dc <unknown>\n",
            "#2 0x594e65ac3931 <unknown>\n",
            "#3 0x594e65ac3a21 <unknown>\n",
            "#4 0x594e65b08234 <unknown>\n",
            "#5 0x594e65ae689d <unknown>\n",
            "#6 0x594e65b055c3 <unknown>\n",
            "#7 0x594e65ae6613 <unknown>\n",
            "#8 0x594e65ab64f7 <unknown>\n",
            "#9 0x594e65ab6e4e <unknown>\n",
            "#10 0x594e65d5a87b <unknown>\n",
            "#11 0x594e65d5e921 <unknown>\n",
            "#12 0x594e65d4636e <unknown>\n",
            "#13 0x594e65d5f482 <unknown>\n",
            "#14 0x594e65d2accf <unknown>\n",
            "#15 0x594e65d840a8 <unknown>\n",
            "#16 0x594e65d84280 <unknown>\n",
            "#17 0x594e65d937dc <unknown>\n",
            "#18 0x7ae929f68ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/JHN_5.txt\n",
            "Downloaded: audio_files/JHN_5_1.mp3\n",
            "Saved text: text_files/JHN_6.txt\n",
            "Downloaded: audio_files/JHN_6_1.mp3\n",
            "Saved text: text_files/JHN_7.txt\n",
            "Downloaded: audio_files/JHN_7_1.mp3\n",
            "Saved text: text_files/JHN_8.txt\n",
            "Downloaded: audio_files/JHN_8_1.mp3\n",
            "Saved text: text_files/JHN_9.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/JHN_10.txt\n",
            "Downloaded: audio_files/JHN_10_1.mp3\n",
            "Saved text: text_files/JHN_11.txt\n",
            "Downloaded: audio_files/JHN_11_1.mp3\n",
            "Saved text: text_files/JHN_12.txt\n",
            "Downloaded: audio_files/JHN_12_1.mp3\n",
            "Saved text: text_files/JHN_13.txt\n",
            "Downloaded: audio_files/JHN_13_1.mp3\n",
            "Saved text: text_files/JHN_14.txt\n",
            "Downloaded: audio_files/JHN_14_1.mp3\n",
            "Saved text: text_files/JHN_15.txt\n",
            "Downloaded: audio_files/JHN_15_1.mp3\n",
            "Saved text: text_files/JHN_16.txt\n",
            "Downloaded: audio_files/JHN_16_1.mp3\n",
            "Saved text: text_files/JHN_17.txt\n",
            "Downloaded: audio_files/JHN_17_1.mp3\n",
            "Saved text: text_files/JHN_18.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/JHN_19.txt\n",
            "Downloaded: audio_files/JHN_19_1.mp3\n",
            "Saved text: text_files/JHN_20.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/JHN_21.txt\n",
            "Downloaded: audio_files/JHN_21_1.mp3\n",
            "Processing book ACT\n",
            "Saved text: text_files/ACT_1.txt\n",
            "Downloaded: audio_files/ACT_1_1.mp3\n",
            "Saved text: text_files/ACT_2.txt\n",
            "Downloaded: audio_files/ACT_2_1.mp3\n",
            "Saved text: text_files/ACT_3.txt\n",
            "Downloaded: audio_files/ACT_3_1.mp3\n",
            "Saved text: text_files/ACT_4.txt\n",
            "Downloaded: audio_files/ACT_4_1.mp3\n",
            "Saved text: text_files/ACT_5.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//ACT/5: Message: \n",
            "Stacktrace:\n",
            "#0 0x569f0a6f66aa <unknown>\n",
            "#1 0x569f0a3d90dc <unknown>\n",
            "#2 0x569f0a425931 <unknown>\n",
            "#3 0x569f0a425a21 <unknown>\n",
            "#4 0x569f0a46a234 <unknown>\n",
            "#5 0x569f0a44889d <unknown>\n",
            "#6 0x569f0a4675c3 <unknown>\n",
            "#7 0x569f0a448613 <unknown>\n",
            "#8 0x569f0a4184f7 <unknown>\n",
            "#9 0x569f0a418e4e <unknown>\n",
            "#10 0x569f0a6bc87b <unknown>\n",
            "#11 0x569f0a6c0921 <unknown>\n",
            "#12 0x569f0a6a836e <unknown>\n",
            "#13 0x569f0a6c1482 <unknown>\n",
            "#14 0x569f0a68cccf <unknown>\n",
            "#15 0x569f0a6e60a8 <unknown>\n",
            "#16 0x569f0a6e6280 <unknown>\n",
            "#17 0x569f0a6f57dc <unknown>\n",
            "#18 0x7f30debe1ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/ACT_6.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//ACT/6: Message: \n",
            "Stacktrace:\n",
            "#0 0x5c5661a276aa <unknown>\n",
            "#1 0x5c566170a0dc <unknown>\n",
            "#2 0x5c5661756931 <unknown>\n",
            "#3 0x5c5661756a21 <unknown>\n",
            "#4 0x5c566179b234 <unknown>\n",
            "#5 0x5c566177989d <unknown>\n",
            "#6 0x5c56617985c3 <unknown>\n",
            "#7 0x5c5661779613 <unknown>\n",
            "#8 0x5c56617494f7 <unknown>\n",
            "#9 0x5c5661749e4e <unknown>\n",
            "#10 0x5c56619ed87b <unknown>\n",
            "#11 0x5c56619f1921 <unknown>\n",
            "#12 0x5c56619d936e <unknown>\n",
            "#13 0x5c56619f2482 <unknown>\n",
            "#14 0x5c56619bdccf <unknown>\n",
            "#15 0x5c5661a170a8 <unknown>\n",
            "#16 0x5c5661a17280 <unknown>\n",
            "#17 0x5c5661a267dc <unknown>\n",
            "#18 0x7bef4b26dac3 <unknown>\n",
            "\n",
            "Saved text: text_files/ACT_7.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//ACT/7: Message: \n",
            "Stacktrace:\n",
            "#0 0x57956a84b6aa <unknown>\n",
            "#1 0x57956a52e0dc <unknown>\n",
            "#2 0x57956a57a931 <unknown>\n",
            "#3 0x57956a57aa21 <unknown>\n",
            "#4 0x57956a5bf234 <unknown>\n",
            "#5 0x57956a59d89d <unknown>\n",
            "#6 0x57956a5bc5c3 <unknown>\n",
            "#7 0x57956a59d613 <unknown>\n",
            "#8 0x57956a56d4f7 <unknown>\n",
            "#9 0x57956a56de4e <unknown>\n",
            "#10 0x57956a81187b <unknown>\n",
            "#11 0x57956a815921 <unknown>\n",
            "#12 0x57956a7fd36e <unknown>\n",
            "#13 0x57956a816482 <unknown>\n",
            "#14 0x57956a7e1ccf <unknown>\n",
            "#15 0x57956a83b0a8 <unknown>\n",
            "#16 0x57956a83b280 <unknown>\n",
            "#17 0x57956a84a7dc <unknown>\n",
            "#18 0x7d2be68f3ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/ACT_8.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//ACT/8: Message: \n",
            "Stacktrace:\n",
            "#0 0x55e9f359d6aa <unknown>\n",
            "#1 0x55e9f32800dc <unknown>\n",
            "#2 0x55e9f32cc931 <unknown>\n",
            "#3 0x55e9f32cca21 <unknown>\n",
            "#4 0x55e9f3311234 <unknown>\n",
            "#5 0x55e9f32ef89d <unknown>\n",
            "#6 0x55e9f330e5c3 <unknown>\n",
            "#7 0x55e9f32ef613 <unknown>\n",
            "#8 0x55e9f32bf4f7 <unknown>\n",
            "#9 0x55e9f32bfe4e <unknown>\n",
            "#10 0x55e9f356387b <unknown>\n",
            "#11 0x55e9f3567921 <unknown>\n",
            "#12 0x55e9f354f36e <unknown>\n",
            "#13 0x55e9f3568482 <unknown>\n",
            "#14 0x55e9f3533ccf <unknown>\n",
            "#15 0x55e9f358d0a8 <unknown>\n",
            "#16 0x55e9f358d280 <unknown>\n",
            "#17 0x55e9f359c7dc <unknown>\n",
            "#18 0x7a8c04f09ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/ACT_9.txt\n",
            "Downloaded: audio_files/ACT_9_1.mp3\n",
            "Saved text: text_files/ACT_10.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//ACT/10: Message: \n",
            "Stacktrace:\n",
            "#0 0x58a39ac306aa <unknown>\n",
            "#1 0x58a39a9130dc <unknown>\n",
            "#2 0x58a39a95f931 <unknown>\n",
            "#3 0x58a39a95fa21 <unknown>\n",
            "#4 0x58a39a9a4234 <unknown>\n",
            "#5 0x58a39a98289d <unknown>\n",
            "#6 0x58a39a9a15c3 <unknown>\n",
            "#7 0x58a39a982613 <unknown>\n",
            "#8 0x58a39a9524f7 <unknown>\n",
            "#9 0x58a39a952e4e <unknown>\n",
            "#10 0x58a39abf687b <unknown>\n",
            "#11 0x58a39abfa921 <unknown>\n",
            "#12 0x58a39abe236e <unknown>\n",
            "#13 0x58a39abfb482 <unknown>\n",
            "#14 0x58a39abc6ccf <unknown>\n",
            "#15 0x58a39ac200a8 <unknown>\n",
            "#16 0x58a39ac20280 <unknown>\n",
            "#17 0x58a39ac2f7dc <unknown>\n",
            "#18 0x7a151dfcbac3 <unknown>\n",
            "\n",
            "Saved text: text_files/ACT_11.txt\n",
            "Downloaded: audio_files/ACT_11_1.mp3\n",
            "Saved text: text_files/ACT_12.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/ACT_13.txt\n",
            "Downloaded: audio_files/ACT_13_1.mp3\n",
            "Saved text: text_files/ACT_14.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/ACT_15.txt\n",
            "Downloaded: audio_files/ACT_15_1.mp3\n",
            "Saved text: text_files/ACT_16.txt\n",
            "Downloaded: audio_files/ACT_16_1.mp3\n",
            "Saved text: text_files/ACT_17.txt\n",
            "Downloaded: audio_files/ACT_17_1.mp3\n",
            "Saved text: text_files/ACT_18.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/ACT_19.txt\n",
            "Downloaded: audio_files/ACT_19_1.mp3\n",
            "Saved text: text_files/ACT_20.txt\n",
            "Downloaded: audio_files/ACT_20_1.mp3\n",
            "Saved text: text_files/ACT_21.txt\n",
            "Downloaded: audio_files/ACT_21_1.mp3\n",
            "Processing book ROM\n",
            "Saved text: text_files/ROM_1.txt\n",
            "Downloaded: audio_files/ROM_1_1.mp3\n",
            "Saved text: text_files/ROM_2.txt\n",
            "Downloaded: audio_files/ROM_2_1.mp3\n",
            "Saved text: text_files/ROM_3.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/ROM_4.txt\n",
            "Downloaded: audio_files/ROM_4_1.mp3\n",
            "Saved text: text_files/ROM_5.txt\n",
            "Downloaded: audio_files/ROM_5_1.mp3\n",
            "Saved text: text_files/ROM_6.txt\n",
            "Downloaded: audio_files/ROM_6_1.mp3\n",
            "Saved text: text_files/ROM_7.txt\n",
            "Downloaded: audio_files/ROM_7_1.mp3\n",
            "Saved text: text_files/ROM_8.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/ROM_9.txt\n",
            "Downloaded: audio_files/ROM_9_1.mp3\n",
            "Saved text: text_files/ROM_10.txt\n",
            "Downloaded: audio_files/ROM_10_1.mp3\n",
            "Saved text: text_files/ROM_11.txt\n",
            "Downloaded: audio_files/ROM_11_1.mp3\n",
            "Processing book 1CO\n",
            "Saved text: text_files/1CO_1.txt\n",
            "Downloaded: audio_files/1CO_1_1.mp3\n",
            "Saved text: text_files/1CO_2.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/1CO_3.txt\n",
            "Downloaded: audio_files/1CO_3_1.mp3\n",
            "Saved text: text_files/1CO_4.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/1CO_5.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//1CO/5: Message: \n",
            "Stacktrace:\n",
            "#0 0x583de6f636aa <unknown>\n",
            "#1 0x583de6c460dc <unknown>\n",
            "#2 0x583de6c92931 <unknown>\n",
            "#3 0x583de6c92a21 <unknown>\n",
            "#4 0x583de6cd7234 <unknown>\n",
            "#5 0x583de6cb589d <unknown>\n",
            "#6 0x583de6cd45c3 <unknown>\n",
            "#7 0x583de6cb5613 <unknown>\n",
            "#8 0x583de6c854f7 <unknown>\n",
            "#9 0x583de6c85e4e <unknown>\n",
            "#10 0x583de6f2987b <unknown>\n",
            "#11 0x583de6f2d921 <unknown>\n",
            "#12 0x583de6f1536e <unknown>\n",
            "#13 0x583de6f2e482 <unknown>\n",
            "#14 0x583de6ef9ccf <unknown>\n",
            "#15 0x583de6f530a8 <unknown>\n",
            "#16 0x583de6f53280 <unknown>\n",
            "#17 0x583de6f627dc <unknown>\n",
            "#18 0x7f6fa754bac3 <unknown>\n",
            "\n",
            "Saved text: text_files/1CO_6.txt\n",
            "Downloaded: audio_files/1CO_6_1.mp3\n",
            "Saved text: text_files/1CO_7.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//1CO/7: Message: \n",
            "Stacktrace:\n",
            "#0 0x5b89b91456aa <unknown>\n",
            "#1 0x5b89b8e280dc <unknown>\n",
            "#2 0x5b89b8e74931 <unknown>\n",
            "#3 0x5b89b8e74a21 <unknown>\n",
            "#4 0x5b89b8eb9234 <unknown>\n",
            "#5 0x5b89b8e9789d <unknown>\n",
            "#6 0x5b89b8eb65c3 <unknown>\n",
            "#7 0x5b89b8e97613 <unknown>\n",
            "#8 0x5b89b8e674f7 <unknown>\n",
            "#9 0x5b89b8e67e4e <unknown>\n",
            "#10 0x5b89b910b87b <unknown>\n",
            "#11 0x5b89b910f921 <unknown>\n",
            "#12 0x5b89b90f736e <unknown>\n",
            "#13 0x5b89b9110482 <unknown>\n",
            "#14 0x5b89b90dbccf <unknown>\n",
            "#15 0x5b89b91350a8 <unknown>\n",
            "#16 0x5b89b9135280 <unknown>\n",
            "#17 0x5b89b91447dc <unknown>\n",
            "#18 0x783bdfb5cac3 <unknown>\n",
            "\n",
            "Saved text: text_files/1CO_8.txt\n",
            "Downloaded: audio_files/1CO_8_1.mp3\n",
            "Saved text: text_files/1CO_9.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//1CO/9: Message: \n",
            "Stacktrace:\n",
            "#0 0x5cb696e906aa <unknown>\n",
            "#1 0x5cb696b730dc <unknown>\n",
            "#2 0x5cb696bbf931 <unknown>\n",
            "#3 0x5cb696bbfa21 <unknown>\n",
            "#4 0x5cb696c04234 <unknown>\n",
            "#5 0x5cb696be289d <unknown>\n",
            "#6 0x5cb696c015c3 <unknown>\n",
            "#7 0x5cb696be2613 <unknown>\n",
            "#8 0x5cb696bb24f7 <unknown>\n",
            "#9 0x5cb696bb2e4e <unknown>\n",
            "#10 0x5cb696e5687b <unknown>\n",
            "#11 0x5cb696e5a921 <unknown>\n",
            "#12 0x5cb696e4236e <unknown>\n",
            "#13 0x5cb696e5b482 <unknown>\n",
            "#14 0x5cb696e26ccf <unknown>\n",
            "#15 0x5cb696e800a8 <unknown>\n",
            "#16 0x5cb696e80280 <unknown>\n",
            "#17 0x5cb696e8f7dc <unknown>\n",
            "#18 0x7819fa6a9ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/1CO_10.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/1CO_11.txt\n",
            "Downloaded: audio_files/1CO_11_1.mp3\n",
            "Saved text: text_files/1CO_12.txt\n",
            "Downloaded: audio_files/1CO_12_1.mp3\n",
            "Saved text: text_files/1CO_13.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/1CO_14.txt\n",
            "Downloaded: audio_files/1CO_14_1.mp3\n",
            "Saved text: text_files/1CO_15.txt\n",
            "Downloaded: audio_files/1CO_15_1.mp3\n",
            "Saved text: text_files/1CO_16.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Processing book 2CO\n",
            "Saved text: text_files/2CO_1.txt\n",
            "Downloaded: audio_files/2CO_1_1.mp3\n",
            "Saved text: text_files/2CO_2.txt\n",
            "Downloaded: audio_files/2CO_2_1.mp3\n",
            "Saved text: text_files/2CO_3.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/2CO_4.txt\n",
            "Downloaded: audio_files/2CO_4_1.mp3\n",
            "Saved text: text_files/2CO_5.txt\n",
            "Downloaded: audio_files/2CO_5_1.mp3\n",
            "Saved text: text_files/2CO_6.txt\n",
            "Downloaded: audio_files/2CO_6_1.mp3\n",
            "Saved text: text_files/2CO_7.txt\n",
            "Downloaded: audio_files/2CO_7_1.mp3\n",
            "Saved text: text_files/2CO_8.txt\n",
            "Downloaded: audio_files/2CO_8_1.mp3\n",
            "Saved text: text_files/2CO_9.txt\n",
            "Downloaded: audio_files/2CO_9_1.mp3\n",
            "Saved text: text_files/2CO_10.txt\n",
            "Downloaded: audio_files/2CO_10_1.mp3\n",
            "Saved text: text_files/2CO_11.txt\n",
            "Downloaded: audio_files/2CO_11_1.mp3\n",
            "Saved text: text_files/2CO_12.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/2CO_13.txt\n",
            "Downloaded: audio_files/2CO_13_1.mp3\n",
            "Processing book GAL\n",
            "Saved text: text_files/GAL_1.txt\n",
            "Downloaded: audio_files/GAL_1_1.mp3\n",
            "Saved text: text_files/GAL_2.txt\n",
            "Downloaded: audio_files/GAL_2_1.mp3\n",
            "Saved text: text_files/GAL_3.txt\n",
            "Downloaded: audio_files/GAL_3_1.mp3\n",
            "Saved text: text_files/GAL_4.txt\n",
            "Downloaded: audio_files/GAL_4_1.mp3\n",
            "Saved text: text_files/GAL_5.txt\n",
            "Downloaded: audio_files/GAL_5_1.mp3\n",
            "Saved text: text_files/GAL_6.txt\n",
            "Downloaded: audio_files/GAL_6_1.mp3\n",
            "Processing book EPH\n",
            "Saved text: text_files/EPH_1.txt\n",
            "Downloaded: audio_files/EPH_1_1.mp3\n",
            "Saved text: text_files/EPH_2.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/EPH_3.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/EPH_4.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/EPH_5.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/EPH_6.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//EPH/6: Message: \n",
            "Stacktrace:\n",
            "#0 0x580cbb62e6aa <unknown>\n",
            "#1 0x580cbb3110dc <unknown>\n",
            "#2 0x580cbb35d931 <unknown>\n",
            "#3 0x580cbb35da21 <unknown>\n",
            "#4 0x580cbb3a2234 <unknown>\n",
            "#5 0x580cbb38089d <unknown>\n",
            "#6 0x580cbb39f5c3 <unknown>\n",
            "#7 0x580cbb380613 <unknown>\n",
            "#8 0x580cbb3504f7 <unknown>\n",
            "#9 0x580cbb350e4e <unknown>\n",
            "#10 0x580cbb5f487b <unknown>\n",
            "#11 0x580cbb5f8921 <unknown>\n",
            "#12 0x580cbb5e036e <unknown>\n",
            "#13 0x580cbb5f9482 <unknown>\n",
            "#14 0x580cbb5c4ccf <unknown>\n",
            "#15 0x580cbb61e0a8 <unknown>\n",
            "#16 0x580cbb61e280 <unknown>\n",
            "#17 0x580cbb62d7dc <unknown>\n",
            "#18 0x78f8730a9ac3 <unknown>\n",
            "\n",
            "Processing book PHP\n",
            "Saved text: text_files/PHP_1.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//PHP/1: Message: \n",
            "Stacktrace:\n",
            "#0 0x5af7a997e6aa <unknown>\n",
            "#1 0x5af7a96610dc <unknown>\n",
            "#2 0x5af7a96ad931 <unknown>\n",
            "#3 0x5af7a96ada21 <unknown>\n",
            "#4 0x5af7a96f2234 <unknown>\n",
            "#5 0x5af7a96d089d <unknown>\n",
            "#6 0x5af7a96ef5c3 <unknown>\n",
            "#7 0x5af7a96d0613 <unknown>\n",
            "#8 0x5af7a96a04f7 <unknown>\n",
            "#9 0x5af7a96a0e4e <unknown>\n",
            "#10 0x5af7a994487b <unknown>\n",
            "#11 0x5af7a9948921 <unknown>\n",
            "#12 0x5af7a993036e <unknown>\n",
            "#13 0x5af7a9949482 <unknown>\n",
            "#14 0x5af7a9914ccf <unknown>\n",
            "#15 0x5af7a996e0a8 <unknown>\n",
            "#16 0x5af7a996e280 <unknown>\n",
            "#17 0x5af7a997d7dc <unknown>\n",
            "#18 0x7a85f7c1bac3 <unknown>\n",
            "\n",
            "Saved text: text_files/PHP_2.txt\n",
            "Downloaded: audio_files/PHP_2_1.mp3\n",
            "Saved text: text_files/PHP_3.txt\n",
            "Downloaded: audio_files/PHP_3_1.mp3\n",
            "Saved text: text_files/PHP_4.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//PHP/4: Message: \n",
            "Stacktrace:\n",
            "#0 0x5c716d6b26aa <unknown>\n",
            "#1 0x5c716d3950dc <unknown>\n",
            "#2 0x5c716d3e1931 <unknown>\n",
            "#3 0x5c716d3e1a21 <unknown>\n",
            "#4 0x5c716d426234 <unknown>\n",
            "#5 0x5c716d40489d <unknown>\n",
            "#6 0x5c716d4235c3 <unknown>\n",
            "#7 0x5c716d404613 <unknown>\n",
            "#8 0x5c716d3d44f7 <unknown>\n",
            "#9 0x5c716d3d4e4e <unknown>\n",
            "#10 0x5c716d67887b <unknown>\n",
            "#11 0x5c716d67c921 <unknown>\n",
            "#12 0x5c716d66436e <unknown>\n",
            "#13 0x5c716d67d482 <unknown>\n",
            "#14 0x5c716d648ccf <unknown>\n",
            "#15 0x5c716d6a20a8 <unknown>\n",
            "#16 0x5c716d6a2280 <unknown>\n",
            "#17 0x5c716d6b17dc <unknown>\n",
            "#18 0x7bbf50035ac3 <unknown>\n",
            "\n",
            "Processing book COL\n",
            "Saved text: text_files/COL_1.txt\n",
            "Downloaded: audio_files/COL_1_1.mp3\n",
            "Saved text: text_files/COL_2.txt\n",
            "Downloaded: audio_files/COL_2_1.mp3\n",
            "Saved text: text_files/COL_3.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/COL_4.txt\n",
            "Downloaded: audio_files/COL_4_1.mp3\n",
            "Processing book 1TH\n",
            "Saved text: text_files/1TH_1.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/1TH_2.txt\n",
            "Downloaded: audio_files/1TH_2_1.mp3\n",
            "Saved text: text_files/1TH_3.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//1TH/3: Message: \n",
            "Stacktrace:\n",
            "#0 0x5b545a2f86aa <unknown>\n",
            "#1 0x5b5459fdb0dc <unknown>\n",
            "#2 0x5b545a027931 <unknown>\n",
            "#3 0x5b545a027a21 <unknown>\n",
            "#4 0x5b545a06c234 <unknown>\n",
            "#5 0x5b545a04a89d <unknown>\n",
            "#6 0x5b545a0695c3 <unknown>\n",
            "#7 0x5b545a04a613 <unknown>\n",
            "#8 0x5b545a01a4f7 <unknown>\n",
            "#9 0x5b545a01ae4e <unknown>\n",
            "#10 0x5b545a2be87b <unknown>\n",
            "#11 0x5b545a2c2921 <unknown>\n",
            "#12 0x5b545a2aa36e <unknown>\n",
            "#13 0x5b545a2c3482 <unknown>\n",
            "#14 0x5b545a28eccf <unknown>\n",
            "#15 0x5b545a2e80a8 <unknown>\n",
            "#16 0x5b545a2e8280 <unknown>\n",
            "#17 0x5b545a2f77dc <unknown>\n",
            "#18 0x7a7e7f626ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/1TH_4.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//1TH/4: Message: \n",
            "Stacktrace:\n",
            "#0 0x5c460b0546aa <unknown>\n",
            "#1 0x5c460ad370dc <unknown>\n",
            "#2 0x5c460ad83931 <unknown>\n",
            "#3 0x5c460ad83a21 <unknown>\n",
            "#4 0x5c460adc8234 <unknown>\n",
            "#5 0x5c460ada689d <unknown>\n",
            "#6 0x5c460adc55c3 <unknown>\n",
            "#7 0x5c460ada6613 <unknown>\n",
            "#8 0x5c460ad764f7 <unknown>\n",
            "#9 0x5c460ad76e4e <unknown>\n",
            "#10 0x5c460b01a87b <unknown>\n",
            "#11 0x5c460b01e921 <unknown>\n",
            "#12 0x5c460b00636e <unknown>\n",
            "#13 0x5c460b01f482 <unknown>\n",
            "#14 0x5c460afeaccf <unknown>\n",
            "#15 0x5c460b0440a8 <unknown>\n",
            "#16 0x5c460b044280 <unknown>\n",
            "#17 0x5c460b0537dc <unknown>\n",
            "#18 0x799388a65ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/1TH_5.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//1TH/5: Message: \n",
            "Stacktrace:\n",
            "#0 0x58e6df4bb6aa <unknown>\n",
            "#1 0x58e6df19e0dc <unknown>\n",
            "#2 0x58e6df1ea931 <unknown>\n",
            "#3 0x58e6df1eaa21 <unknown>\n",
            "#4 0x58e6df22f234 <unknown>\n",
            "#5 0x58e6df20d89d <unknown>\n",
            "#6 0x58e6df22c5c3 <unknown>\n",
            "#7 0x58e6df20d613 <unknown>\n",
            "#8 0x58e6df1dd4f7 <unknown>\n",
            "#9 0x58e6df1dde4e <unknown>\n",
            "#10 0x58e6df48187b <unknown>\n",
            "#11 0x58e6df485921 <unknown>\n",
            "#12 0x58e6df46d36e <unknown>\n",
            "#13 0x58e6df486482 <unknown>\n",
            "#14 0x58e6df451ccf <unknown>\n",
            "#15 0x58e6df4ab0a8 <unknown>\n",
            "#16 0x58e6df4ab280 <unknown>\n",
            "#17 0x58e6df4ba7dc <unknown>\n",
            "#18 0x7a1550212ac3 <unknown>\n",
            "\n",
            "Processing book 2TH\n",
            "Saved text: text_files/2TH_1.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//2TH/1: Message: \n",
            "Stacktrace:\n",
            "#0 0x5656fa3566aa <unknown>\n",
            "#1 0x5656fa0390dc <unknown>\n",
            "#2 0x5656fa085931 <unknown>\n",
            "#3 0x5656fa085a21 <unknown>\n",
            "#4 0x5656fa0ca234 <unknown>\n",
            "#5 0x5656fa0a889d <unknown>\n",
            "#6 0x5656fa0c75c3 <unknown>\n",
            "#7 0x5656fa0a8613 <unknown>\n",
            "#8 0x5656fa0784f7 <unknown>\n",
            "#9 0x5656fa078e4e <unknown>\n",
            "#10 0x5656fa31c87b <unknown>\n",
            "#11 0x5656fa320921 <unknown>\n",
            "#12 0x5656fa30836e <unknown>\n",
            "#13 0x5656fa321482 <unknown>\n",
            "#14 0x5656fa2ecccf <unknown>\n",
            "#15 0x5656fa3460a8 <unknown>\n",
            "#16 0x5656fa346280 <unknown>\n",
            "#17 0x5656fa3557dc <unknown>\n",
            "#18 0x7c398b0cfac3 <unknown>\n",
            "\n",
            "Saved text: text_files/2TH_2.txt\n",
            "Downloaded: audio_files/2TH_2_1.mp3\n",
            "Saved text: text_files/2TH_3.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//2TH/3: Message: \n",
            "Stacktrace:\n",
            "#0 0x5a24b76d06aa <unknown>\n",
            "#1 0x5a24b73b30dc <unknown>\n",
            "#2 0x5a24b73ff931 <unknown>\n",
            "#3 0x5a24b73ffa21 <unknown>\n",
            "#4 0x5a24b7444234 <unknown>\n",
            "#5 0x5a24b742289d <unknown>\n",
            "#6 0x5a24b74415c3 <unknown>\n",
            "#7 0x5a24b7422613 <unknown>\n",
            "#8 0x5a24b73f24f7 <unknown>\n",
            "#9 0x5a24b73f2e4e <unknown>\n",
            "#10 0x5a24b769687b <unknown>\n",
            "#11 0x5a24b769a921 <unknown>\n",
            "#12 0x5a24b768236e <unknown>\n",
            "#13 0x5a24b769b482 <unknown>\n",
            "#14 0x5a24b7666ccf <unknown>\n",
            "#15 0x5a24b76c00a8 <unknown>\n",
            "#16 0x5a24b76c0280 <unknown>\n",
            "#17 0x5a24b76cf7dc <unknown>\n",
            "#18 0x79b89372dac3 <unknown>\n",
            "\n",
            "Processing book 1TI\n",
            "Saved text: text_files/1TI_1.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//1TI/1: Message: \n",
            "Stacktrace:\n",
            "#0 0x5b680ac026aa <unknown>\n",
            "#1 0x5b680a8e50dc <unknown>\n",
            "#2 0x5b680a931931 <unknown>\n",
            "#3 0x5b680a931a21 <unknown>\n",
            "#4 0x5b680a976234 <unknown>\n",
            "#5 0x5b680a95489d <unknown>\n",
            "#6 0x5b680a9735c3 <unknown>\n",
            "#7 0x5b680a954613 <unknown>\n",
            "#8 0x5b680a9244f7 <unknown>\n",
            "#9 0x5b680a924e4e <unknown>\n",
            "#10 0x5b680abc887b <unknown>\n",
            "#11 0x5b680abcc921 <unknown>\n",
            "#12 0x5b680abb436e <unknown>\n",
            "#13 0x5b680abcd482 <unknown>\n",
            "#14 0x5b680ab98ccf <unknown>\n",
            "#15 0x5b680abf20a8 <unknown>\n",
            "#16 0x5b680abf2280 <unknown>\n",
            "#17 0x5b680ac017dc <unknown>\n",
            "#18 0x7bccf4c15ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/1TI_2.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//1TI/2: Message: \n",
            "Stacktrace:\n",
            "#0 0x55898f17c6aa <unknown>\n",
            "#1 0x55898ee5f0dc <unknown>\n",
            "#2 0x55898eeab931 <unknown>\n",
            "#3 0x55898eeaba21 <unknown>\n",
            "#4 0x55898eef0234 <unknown>\n",
            "#5 0x55898eece89d <unknown>\n",
            "#6 0x55898eeed5c3 <unknown>\n",
            "#7 0x55898eece613 <unknown>\n",
            "#8 0x55898ee9e4f7 <unknown>\n",
            "#9 0x55898ee9ee4e <unknown>\n",
            "#10 0x55898f14287b <unknown>\n",
            "#11 0x55898f146921 <unknown>\n",
            "#12 0x55898f12e36e <unknown>\n",
            "#13 0x55898f147482 <unknown>\n",
            "#14 0x55898f112ccf <unknown>\n",
            "#15 0x55898f16c0a8 <unknown>\n",
            "#16 0x55898f16c280 <unknown>\n",
            "#17 0x55898f17b7dc <unknown>\n",
            "#18 0x7d383c8ceac3 <unknown>\n",
            "\n",
            "Saved text: text_files/1TI_3.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//1TI/3: Message: \n",
            "Stacktrace:\n",
            "#0 0x5787270e16aa <unknown>\n",
            "#1 0x578726dc40dc <unknown>\n",
            "#2 0x578726e10931 <unknown>\n",
            "#3 0x578726e10a21 <unknown>\n",
            "#4 0x578726e55234 <unknown>\n",
            "#5 0x578726e3389d <unknown>\n",
            "#6 0x578726e525c3 <unknown>\n",
            "#7 0x578726e33613 <unknown>\n",
            "#8 0x578726e034f7 <unknown>\n",
            "#9 0x578726e03e4e <unknown>\n",
            "#10 0x5787270a787b <unknown>\n",
            "#11 0x5787270ab921 <unknown>\n",
            "#12 0x57872709336e <unknown>\n",
            "#13 0x5787270ac482 <unknown>\n",
            "#14 0x578727077ccf <unknown>\n",
            "#15 0x5787270d10a8 <unknown>\n",
            "#16 0x5787270d1280 <unknown>\n",
            "#17 0x5787270e07dc <unknown>\n",
            "#18 0x7f47c0018ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/1TI_4.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//1TI/4: Message: \n",
            "Stacktrace:\n",
            "#0 0x58f46e3be6aa <unknown>\n",
            "#1 0x58f46e0a10dc <unknown>\n",
            "#2 0x58f46e0ed931 <unknown>\n",
            "#3 0x58f46e0eda21 <unknown>\n",
            "#4 0x58f46e132234 <unknown>\n",
            "#5 0x58f46e11089d <unknown>\n",
            "#6 0x58f46e12f5c3 <unknown>\n",
            "#7 0x58f46e110613 <unknown>\n",
            "#8 0x58f46e0e04f7 <unknown>\n",
            "#9 0x58f46e0e0e4e <unknown>\n",
            "#10 0x58f46e38487b <unknown>\n",
            "#11 0x58f46e388921 <unknown>\n",
            "#12 0x58f46e37036e <unknown>\n",
            "#13 0x58f46e389482 <unknown>\n",
            "#14 0x58f46e354ccf <unknown>\n",
            "#15 0x58f46e3ae0a8 <unknown>\n",
            "#16 0x58f46e3ae280 <unknown>\n",
            "#17 0x58f46e3bd7dc <unknown>\n",
            "#18 0x7e1d022c9ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/1TI_5.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/1TI_6.txt\n",
            "Downloaded: audio_files/1TI_6_1.mp3\n",
            "Processing book 2TI\n",
            "Saved text: text_files/2TI_1.txt\n",
            "Downloaded: audio_files/2TI_1_1.mp3\n",
            "Saved text: text_files/2TI_2.txt\n",
            "Downloaded: audio_files/2TI_2_1.mp3\n",
            "Saved text: text_files/2TI_3.txt\n",
            "Downloaded: audio_files/2TI_3_1.mp3\n",
            "Saved text: text_files/2TI_4.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Processing book TIT\n",
            "Saved text: text_files/TIT_1.txt\n",
            "Downloaded: audio_files/TIT_1_1.mp3\n",
            "Saved text: text_files/TIT_2.txt\n",
            "Downloaded: audio_files/TIT_2_1.mp3\n",
            "Saved text: text_files/TIT_3.txt\n",
            "Downloaded: audio_files/TIT_3_1.mp3\n",
            "Processing book PHM\n",
            "Saved text: text_files/PHM_1.txt\n",
            "Downloaded: audio_files/PHM_1_1.mp3\n",
            "Processing book HEB\n",
            "Saved text: text_files/HEB_1.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/HEB_2.txt\n",
            "Downloaded: audio_files/HEB_2_1.mp3\n",
            "Saved text: text_files/HEB_3.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//HEB/3: Message: \n",
            "Stacktrace:\n",
            "#0 0x573fbda136aa <unknown>\n",
            "#1 0x573fbd6f60dc <unknown>\n",
            "#2 0x573fbd742931 <unknown>\n",
            "#3 0x573fbd742a21 <unknown>\n",
            "#4 0x573fbd787234 <unknown>\n",
            "#5 0x573fbd76589d <unknown>\n",
            "#6 0x573fbd7845c3 <unknown>\n",
            "#7 0x573fbd765613 <unknown>\n",
            "#8 0x573fbd7354f7 <unknown>\n",
            "#9 0x573fbd735e4e <unknown>\n",
            "#10 0x573fbd9d987b <unknown>\n",
            "#11 0x573fbd9dd921 <unknown>\n",
            "#12 0x573fbd9c536e <unknown>\n",
            "#13 0x573fbd9de482 <unknown>\n",
            "#14 0x573fbd9a9ccf <unknown>\n",
            "#15 0x573fbda030a8 <unknown>\n",
            "#16 0x573fbda03280 <unknown>\n",
            "#17 0x573fbda127dc <unknown>\n",
            "#18 0x788e1a070ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/HEB_4.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//HEB/4: Message: \n",
            "Stacktrace:\n",
            "#0 0x56ffbfef66aa <unknown>\n",
            "#1 0x56ffbfbd90dc <unknown>\n",
            "#2 0x56ffbfc25931 <unknown>\n",
            "#3 0x56ffbfc25a21 <unknown>\n",
            "#4 0x56ffbfc6a234 <unknown>\n",
            "#5 0x56ffbfc4889d <unknown>\n",
            "#6 0x56ffbfc675c3 <unknown>\n",
            "#7 0x56ffbfc48613 <unknown>\n",
            "#8 0x56ffbfc184f7 <unknown>\n",
            "#9 0x56ffbfc18e4e <unknown>\n",
            "#10 0x56ffbfebc87b <unknown>\n",
            "#11 0x56ffbfec0921 <unknown>\n",
            "#12 0x56ffbfea836e <unknown>\n",
            "#13 0x56ffbfec1482 <unknown>\n",
            "#14 0x56ffbfe8cccf <unknown>\n",
            "#15 0x56ffbfee60a8 <unknown>\n",
            "#16 0x56ffbfee6280 <unknown>\n",
            "#17 0x56ffbfef57dc <unknown>\n",
            "#18 0x780d99fc7ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/HEB_5.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//HEB/5: Message: \n",
            "Stacktrace:\n",
            "#0 0x5add0e7296aa <unknown>\n",
            "#1 0x5add0e40c0dc <unknown>\n",
            "#2 0x5add0e458931 <unknown>\n",
            "#3 0x5add0e458a21 <unknown>\n",
            "#4 0x5add0e49d234 <unknown>\n",
            "#5 0x5add0e47b89d <unknown>\n",
            "#6 0x5add0e49a5c3 <unknown>\n",
            "#7 0x5add0e47b613 <unknown>\n",
            "#8 0x5add0e44b4f7 <unknown>\n",
            "#9 0x5add0e44be4e <unknown>\n",
            "#10 0x5add0e6ef87b <unknown>\n",
            "#11 0x5add0e6f3921 <unknown>\n",
            "#12 0x5add0e6db36e <unknown>\n",
            "#13 0x5add0e6f4482 <unknown>\n",
            "#14 0x5add0e6bfccf <unknown>\n",
            "#15 0x5add0e7190a8 <unknown>\n",
            "#16 0x5add0e719280 <unknown>\n",
            "#17 0x5add0e7287dc <unknown>\n",
            "#18 0x7e6faad23ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/HEB_6.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//HEB/6: Message: \n",
            "Stacktrace:\n",
            "#0 0x5c7851ca86aa <unknown>\n",
            "#1 0x5c785198b0dc <unknown>\n",
            "#2 0x5c78519d7931 <unknown>\n",
            "#3 0x5c78519d7a21 <unknown>\n",
            "#4 0x5c7851a1c234 <unknown>\n",
            "#5 0x5c78519fa89d <unknown>\n",
            "#6 0x5c7851a195c3 <unknown>\n",
            "#7 0x5c78519fa613 <unknown>\n",
            "#8 0x5c78519ca4f7 <unknown>\n",
            "#9 0x5c78519cae4e <unknown>\n",
            "#10 0x5c7851c6e87b <unknown>\n",
            "#11 0x5c7851c72921 <unknown>\n",
            "#12 0x5c7851c5a36e <unknown>\n",
            "#13 0x5c7851c73482 <unknown>\n",
            "#14 0x5c7851c3eccf <unknown>\n",
            "#15 0x5c7851c980a8 <unknown>\n",
            "#16 0x5c7851c98280 <unknown>\n",
            "#17 0x5c7851ca77dc <unknown>\n",
            "#18 0x7bdb5e6d7ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/HEB_7.txt\n",
            "Downloaded: audio_files/HEB_7_1.mp3\n",
            "Saved text: text_files/HEB_8.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//HEB/8: Message: \n",
            "Stacktrace:\n",
            "#0 0x5a5f7509d6aa <unknown>\n",
            "#1 0x5a5f74d800dc <unknown>\n",
            "#2 0x5a5f74dcc931 <unknown>\n",
            "#3 0x5a5f74dcca21 <unknown>\n",
            "#4 0x5a5f74e11234 <unknown>\n",
            "#5 0x5a5f74def89d <unknown>\n",
            "#6 0x5a5f74e0e5c3 <unknown>\n",
            "#7 0x5a5f74def613 <unknown>\n",
            "#8 0x5a5f74dbf4f7 <unknown>\n",
            "#9 0x5a5f74dbfe4e <unknown>\n",
            "#10 0x5a5f7506387b <unknown>\n",
            "#11 0x5a5f75067921 <unknown>\n",
            "#12 0x5a5f7504f36e <unknown>\n",
            "#13 0x5a5f75068482 <unknown>\n",
            "#14 0x5a5f75033ccf <unknown>\n",
            "#15 0x5a5f7508d0a8 <unknown>\n",
            "#16 0x5a5f7508d280 <unknown>\n",
            "#17 0x5a5f7509c7dc <unknown>\n",
            "#18 0x7c99c63b3ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/HEB_9.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//HEB/9: Message: \n",
            "Stacktrace:\n",
            "#0 0x5d0581b766aa <unknown>\n",
            "#1 0x5d05818590dc <unknown>\n",
            "#2 0x5d05818a5931 <unknown>\n",
            "#3 0x5d05818a5a21 <unknown>\n",
            "#4 0x5d05818ea234 <unknown>\n",
            "#5 0x5d05818c889d <unknown>\n",
            "#6 0x5d05818e75c3 <unknown>\n",
            "#7 0x5d05818c8613 <unknown>\n",
            "#8 0x5d05818984f7 <unknown>\n",
            "#9 0x5d0581898e4e <unknown>\n",
            "#10 0x5d0581b3c87b <unknown>\n",
            "#11 0x5d0581b40921 <unknown>\n",
            "#12 0x5d0581b2836e <unknown>\n",
            "#13 0x5d0581b41482 <unknown>\n",
            "#14 0x5d0581b0cccf <unknown>\n",
            "#15 0x5d0581b660a8 <unknown>\n",
            "#16 0x5d0581b66280 <unknown>\n",
            "#17 0x5d0581b757dc <unknown>\n",
            "#18 0x7d9412450ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/HEB_10.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//HEB/10: Message: \n",
            "Stacktrace:\n",
            "#0 0x5aa358ff16aa <unknown>\n",
            "#1 0x5aa358cd40dc <unknown>\n",
            "#2 0x5aa358d20931 <unknown>\n",
            "#3 0x5aa358d20a21 <unknown>\n",
            "#4 0x5aa358d65234 <unknown>\n",
            "#5 0x5aa358d4389d <unknown>\n",
            "#6 0x5aa358d625c3 <unknown>\n",
            "#7 0x5aa358d43613 <unknown>\n",
            "#8 0x5aa358d134f7 <unknown>\n",
            "#9 0x5aa358d13e4e <unknown>\n",
            "#10 0x5aa358fb787b <unknown>\n",
            "#11 0x5aa358fbb921 <unknown>\n",
            "#12 0x5aa358fa336e <unknown>\n",
            "#13 0x5aa358fbc482 <unknown>\n",
            "#14 0x5aa358f87ccf <unknown>\n",
            "#15 0x5aa358fe10a8 <unknown>\n",
            "#16 0x5aa358fe1280 <unknown>\n",
            "#17 0x5aa358ff07dc <unknown>\n",
            "#18 0x79051891eac3 <unknown>\n",
            "\n",
            "Saved text: text_files/HEB_11.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//HEB/11: Message: \n",
            "Stacktrace:\n",
            "#0 0x57f0b2d6b6aa <unknown>\n",
            "#1 0x57f0b2a4e0dc <unknown>\n",
            "#2 0x57f0b2a9a931 <unknown>\n",
            "#3 0x57f0b2a9aa21 <unknown>\n",
            "#4 0x57f0b2adf234 <unknown>\n",
            "#5 0x57f0b2abd89d <unknown>\n",
            "#6 0x57f0b2adc5c3 <unknown>\n",
            "#7 0x57f0b2abd613 <unknown>\n",
            "#8 0x57f0b2a8d4f7 <unknown>\n",
            "#9 0x57f0b2a8de4e <unknown>\n",
            "#10 0x57f0b2d3187b <unknown>\n",
            "#11 0x57f0b2d35921 <unknown>\n",
            "#12 0x57f0b2d1d36e <unknown>\n",
            "#13 0x57f0b2d36482 <unknown>\n",
            "#14 0x57f0b2d01ccf <unknown>\n",
            "#15 0x57f0b2d5b0a8 <unknown>\n",
            "#16 0x57f0b2d5b280 <unknown>\n",
            "#17 0x57f0b2d6a7dc <unknown>\n",
            "#18 0x7e6876cdbac3 <unknown>\n",
            "\n",
            "Saved text: text_files/HEB_12.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//HEB/12: Message: \n",
            "Stacktrace:\n",
            "#0 0x566e55af56aa <unknown>\n",
            "#1 0x566e557d80dc <unknown>\n",
            "#2 0x566e55824931 <unknown>\n",
            "#3 0x566e55824a21 <unknown>\n",
            "#4 0x566e55869234 <unknown>\n",
            "#5 0x566e5584789d <unknown>\n",
            "#6 0x566e558665c3 <unknown>\n",
            "#7 0x566e55847613 <unknown>\n",
            "#8 0x566e558174f7 <unknown>\n",
            "#9 0x566e55817e4e <unknown>\n",
            "#10 0x566e55abb87b <unknown>\n",
            "#11 0x566e55abf921 <unknown>\n",
            "#12 0x566e55aa736e <unknown>\n",
            "#13 0x566e55ac0482 <unknown>\n",
            "#14 0x566e55a8bccf <unknown>\n",
            "#15 0x566e55ae50a8 <unknown>\n",
            "#16 0x566e55ae5280 <unknown>\n",
            "#17 0x566e55af47dc <unknown>\n",
            "#18 0x78ffcd060ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/HEB_13.txt\n",
            "Downloaded: audio_files/HEB_13_1.mp3\n",
            "Processing book JAS\n",
            "Saved text: text_files/JAS_1.txt\n",
            "Downloaded: audio_files/JAS_1_1.mp3\n",
            "Saved text: text_files/JAS_2.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/JAS_3.txt\n",
            "Downloaded: audio_files/JAS_3_1.mp3\n",
            "Saved text: text_files/JAS_4.txt\n",
            "Downloaded: audio_files/JAS_4_1.mp3\n",
            "Saved text: text_files/JAS_5.txt\n",
            "Downloaded: audio_files/JAS_5_1.mp3\n",
            "Processing book 1PE\n",
            "Saved text: text_files/1PE_1.txt\n",
            "Downloaded: audio_files/1PE_1_1.mp3\n",
            "Saved text: text_files/1PE_2.txt\n",
            "Downloaded: audio_files/1PE_2_1.mp3\n",
            "Saved text: text_files/1PE_3.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/1PE_4.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//1PE/4: Message: \n",
            "Stacktrace:\n",
            "#0 0x57bf285546aa <unknown>\n",
            "#1 0x57bf282370dc <unknown>\n",
            "#2 0x57bf28283931 <unknown>\n",
            "#3 0x57bf28283a21 <unknown>\n",
            "#4 0x57bf282c8234 <unknown>\n",
            "#5 0x57bf282a689d <unknown>\n",
            "#6 0x57bf282c55c3 <unknown>\n",
            "#7 0x57bf282a6613 <unknown>\n",
            "#8 0x57bf282764f7 <unknown>\n",
            "#9 0x57bf28276e4e <unknown>\n",
            "#10 0x57bf2851a87b <unknown>\n",
            "#11 0x57bf2851e921 <unknown>\n",
            "#12 0x57bf2850636e <unknown>\n",
            "#13 0x57bf2851f482 <unknown>\n",
            "#14 0x57bf284eaccf <unknown>\n",
            "#15 0x57bf285440a8 <unknown>\n",
            "#16 0x57bf28544280 <unknown>\n",
            "#17 0x57bf285537dc <unknown>\n",
            "#18 0x7a36cc199ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/1PE_5.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//1PE/5: Message: \n",
            "Stacktrace:\n",
            "#0 0x5a31615bb6aa <unknown>\n",
            "#1 0x5a316129e0dc <unknown>\n",
            "#2 0x5a31612ea931 <unknown>\n",
            "#3 0x5a31612eaa21 <unknown>\n",
            "#4 0x5a316132f234 <unknown>\n",
            "#5 0x5a316130d89d <unknown>\n",
            "#6 0x5a316132c5c3 <unknown>\n",
            "#7 0x5a316130d613 <unknown>\n",
            "#8 0x5a31612dd4f7 <unknown>\n",
            "#9 0x5a31612dde4e <unknown>\n",
            "#10 0x5a316158187b <unknown>\n",
            "#11 0x5a3161585921 <unknown>\n",
            "#12 0x5a316156d36e <unknown>\n",
            "#13 0x5a3161586482 <unknown>\n",
            "#14 0x5a3161551ccf <unknown>\n",
            "#15 0x5a31615ab0a8 <unknown>\n",
            "#16 0x5a31615ab280 <unknown>\n",
            "#17 0x5a31615ba7dc <unknown>\n",
            "#18 0x7ebe7e898ac3 <unknown>\n",
            "\n",
            "Processing book 2PE\n",
            "Saved text: text_files/2PE_1.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//2PE/1: Message: \n",
            "Stacktrace:\n",
            "#0 0x5a0d7ee1a6aa <unknown>\n",
            "#1 0x5a0d7eafd0dc <unknown>\n",
            "#2 0x5a0d7eb49931 <unknown>\n",
            "#3 0x5a0d7eb49a21 <unknown>\n",
            "#4 0x5a0d7eb8e234 <unknown>\n",
            "#5 0x5a0d7eb6c89d <unknown>\n",
            "#6 0x5a0d7eb8b5c3 <unknown>\n",
            "#7 0x5a0d7eb6c613 <unknown>\n",
            "#8 0x5a0d7eb3c4f7 <unknown>\n",
            "#9 0x5a0d7eb3ce4e <unknown>\n",
            "#10 0x5a0d7ede087b <unknown>\n",
            "#11 0x5a0d7ede4921 <unknown>\n",
            "#12 0x5a0d7edcc36e <unknown>\n",
            "#13 0x5a0d7ede5482 <unknown>\n",
            "#14 0x5a0d7edb0ccf <unknown>\n",
            "#15 0x5a0d7ee0a0a8 <unknown>\n",
            "#16 0x5a0d7ee0a280 <unknown>\n",
            "#17 0x5a0d7ee197dc <unknown>\n",
            "#18 0x78132a285ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/2PE_2.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//2PE/2: Message: \n",
            "Stacktrace:\n",
            "#0 0x5c555ba3d6aa <unknown>\n",
            "#1 0x5c555b7200dc <unknown>\n",
            "#2 0x5c555b76c931 <unknown>\n",
            "#3 0x5c555b76ca21 <unknown>\n",
            "#4 0x5c555b7b1234 <unknown>\n",
            "#5 0x5c555b78f89d <unknown>\n",
            "#6 0x5c555b7ae5c3 <unknown>\n",
            "#7 0x5c555b78f613 <unknown>\n",
            "#8 0x5c555b75f4f7 <unknown>\n",
            "#9 0x5c555b75fe4e <unknown>\n",
            "#10 0x5c555ba0387b <unknown>\n",
            "#11 0x5c555ba07921 <unknown>\n",
            "#12 0x5c555b9ef36e <unknown>\n",
            "#13 0x5c555ba08482 <unknown>\n",
            "#14 0x5c555b9d3ccf <unknown>\n",
            "#15 0x5c555ba2d0a8 <unknown>\n",
            "#16 0x5c555ba2d280 <unknown>\n",
            "#17 0x5c555ba3c7dc <unknown>\n",
            "#18 0x7c37bcc61ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/2PE_3.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//2PE/3: Message: \n",
            "Stacktrace:\n",
            "#0 0x5a59f03866aa <unknown>\n",
            "#1 0x5a59f00690dc <unknown>\n",
            "#2 0x5a59f00b5931 <unknown>\n",
            "#3 0x5a59f00b5a21 <unknown>\n",
            "#4 0x5a59f00fa234 <unknown>\n",
            "#5 0x5a59f00d889d <unknown>\n",
            "#6 0x5a59f00f75c3 <unknown>\n",
            "#7 0x5a59f00d8613 <unknown>\n",
            "#8 0x5a59f00a84f7 <unknown>\n",
            "#9 0x5a59f00a8e4e <unknown>\n",
            "#10 0x5a59f034c87b <unknown>\n",
            "#11 0x5a59f0350921 <unknown>\n",
            "#12 0x5a59f033836e <unknown>\n",
            "#13 0x5a59f0351482 <unknown>\n",
            "#14 0x5a59f031cccf <unknown>\n",
            "#15 0x5a59f03760a8 <unknown>\n",
            "#16 0x5a59f0376280 <unknown>\n",
            "#17 0x5a59f03857dc <unknown>\n",
            "#18 0x7b0322c5cac3 <unknown>\n",
            "\n",
            "Processing book 1JN\n",
            "Saved text: text_files/1JN_1.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/1JN_2.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//1JN/2: Message: \n",
            "Stacktrace:\n",
            "#0 0x56649aa0b6aa <unknown>\n",
            "#1 0x56649a6ee0dc <unknown>\n",
            "#2 0x56649a73a931 <unknown>\n",
            "#3 0x56649a73aa21 <unknown>\n",
            "#4 0x56649a77f234 <unknown>\n",
            "#5 0x56649a75d89d <unknown>\n",
            "#6 0x56649a77c5c3 <unknown>\n",
            "#7 0x56649a75d613 <unknown>\n",
            "#8 0x56649a72d4f7 <unknown>\n",
            "#9 0x56649a72de4e <unknown>\n",
            "#10 0x56649a9d187b <unknown>\n",
            "#11 0x56649a9d5921 <unknown>\n",
            "#12 0x56649a9bd36e <unknown>\n",
            "#13 0x56649a9d6482 <unknown>\n",
            "#14 0x56649a9a1ccf <unknown>\n",
            "#15 0x56649a9fb0a8 <unknown>\n",
            "#16 0x56649a9fb280 <unknown>\n",
            "#17 0x56649aa0a7dc <unknown>\n",
            "#18 0x7b054b83aac3 <unknown>\n",
            "\n",
            "Saved text: text_files/1JN_3.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//1JN/3: Message: \n",
            "Stacktrace:\n",
            "#0 0x5ad5ba6886aa <unknown>\n",
            "#1 0x5ad5ba36b0dc <unknown>\n",
            "#2 0x5ad5ba3b7931 <unknown>\n",
            "#3 0x5ad5ba3b7a21 <unknown>\n",
            "#4 0x5ad5ba3fc234 <unknown>\n",
            "#5 0x5ad5ba3da89d <unknown>\n",
            "#6 0x5ad5ba3f95c3 <unknown>\n",
            "#7 0x5ad5ba3da613 <unknown>\n",
            "#8 0x5ad5ba3aa4f7 <unknown>\n",
            "#9 0x5ad5ba3aae4e <unknown>\n",
            "#10 0x5ad5ba64e87b <unknown>\n",
            "#11 0x5ad5ba652921 <unknown>\n",
            "#12 0x5ad5ba63a36e <unknown>\n",
            "#13 0x5ad5ba653482 <unknown>\n",
            "#14 0x5ad5ba61eccf <unknown>\n",
            "#15 0x5ad5ba6780a8 <unknown>\n",
            "#16 0x5ad5ba678280 <unknown>\n",
            "#17 0x5ad5ba6877dc <unknown>\n",
            "#18 0x7e2a4aff5ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/1JN_4.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/1JN_5.txt\n",
            "Downloaded: audio_files/1JN_5_1.mp3\n",
            "Processing book 2JN\n",
            "Saved text: text_files/2JN_1.txt\n",
            "Downloaded: audio_files/2JN_1_1.mp3\n",
            "Processing book 3JN\n",
            "Saved text: text_files/3JN_1.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Processing book JUD\n",
            "Saved text: text_files/JUD_1.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Processing book REV\n",
            "Saved text: text_files/REV_1.txt\n",
            "Downloaded: audio_files/REV_1_1.mp3\n",
            "Saved text: text_files/REV_2.txt\n",
            "Downloaded: audio_files/REV_2_1.mp3\n",
            "Saved text: text_files/REV_3.txt\n",
            "Downloaded: audio_files/REV_3_1.mp3\n",
            "Saved text: text_files/REV_4.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/REV_5.txt\n",
            "Downloaded: audio_files/REV_5_1.mp3\n",
            "Saved text: text_files/REV_6.txt\n",
            "Downloaded: audio_files/REV_6_1.mp3\n",
            "Saved text: text_files/REV_7.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/REV_8.txt\n",
            "Downloaded: audio_files/REV_8_1.mp3\n",
            "Saved text: text_files/REV_9.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//REV/9: Message: \n",
            "Stacktrace:\n",
            "#0 0x5d35e38b26aa <unknown>\n",
            "#1 0x5d35e35950dc <unknown>\n",
            "#2 0x5d35e35e1931 <unknown>\n",
            "#3 0x5d35e35e1a21 <unknown>\n",
            "#4 0x5d35e3626234 <unknown>\n",
            "#5 0x5d35e360489d <unknown>\n",
            "#6 0x5d35e36235c3 <unknown>\n",
            "#7 0x5d35e3604613 <unknown>\n",
            "#8 0x5d35e35d44f7 <unknown>\n",
            "#9 0x5d35e35d4e4e <unknown>\n",
            "#10 0x5d35e387887b <unknown>\n",
            "#11 0x5d35e387c921 <unknown>\n",
            "#12 0x5d35e386436e <unknown>\n",
            "#13 0x5d35e387d482 <unknown>\n",
            "#14 0x5d35e3848ccf <unknown>\n",
            "#15 0x5d35e38a20a8 <unknown>\n",
            "#16 0x5d35e38a2280 <unknown>\n",
            "#17 0x5d35e38b17dc <unknown>\n",
            "#18 0x78f822b84ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/REV_10.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//REV/10: Message: \n",
            "Stacktrace:\n",
            "#0 0x596d868bb6aa <unknown>\n",
            "#1 0x596d8659e0dc <unknown>\n",
            "#2 0x596d865ea931 <unknown>\n",
            "#3 0x596d865eaa21 <unknown>\n",
            "#4 0x596d8662f234 <unknown>\n",
            "#5 0x596d8660d89d <unknown>\n",
            "#6 0x596d8662c5c3 <unknown>\n",
            "#7 0x596d8660d613 <unknown>\n",
            "#8 0x596d865dd4f7 <unknown>\n",
            "#9 0x596d865dde4e <unknown>\n",
            "#10 0x596d8688187b <unknown>\n",
            "#11 0x596d86885921 <unknown>\n",
            "#12 0x596d8686d36e <unknown>\n",
            "#13 0x596d86886482 <unknown>\n",
            "#14 0x596d86851ccf <unknown>\n",
            "#15 0x596d868ab0a8 <unknown>\n",
            "#16 0x596d868ab280 <unknown>\n",
            "#17 0x596d868ba7dc <unknown>\n",
            "#18 0x7a93422d8ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/REV_11.txt\n",
            "Downloaded: audio_files/REV_11_1.mp3\n",
            "Saved text: text_files/REV_12.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//REV/12: Message: \n",
            "Stacktrace:\n",
            "#0 0x55d1f46cf6aa <unknown>\n",
            "#1 0x55d1f43b20dc <unknown>\n",
            "#2 0x55d1f43fe931 <unknown>\n",
            "#3 0x55d1f43fea21 <unknown>\n",
            "#4 0x55d1f4443234 <unknown>\n",
            "#5 0x55d1f442189d <unknown>\n",
            "#6 0x55d1f44405c3 <unknown>\n",
            "#7 0x55d1f4421613 <unknown>\n",
            "#8 0x55d1f43f14f7 <unknown>\n",
            "#9 0x55d1f43f1e4e <unknown>\n",
            "#10 0x55d1f469587b <unknown>\n",
            "#11 0x55d1f4699921 <unknown>\n",
            "#12 0x55d1f468136e <unknown>\n",
            "#13 0x55d1f469a482 <unknown>\n",
            "#14 0x55d1f4665ccf <unknown>\n",
            "#15 0x55d1f46bf0a8 <unknown>\n",
            "#16 0x55d1f46bf280 <unknown>\n",
            "#17 0x55d1f46ce7dc <unknown>\n",
            "#18 0x7f81311b6ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/REV_13.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//REV/13: Message: \n",
            "Stacktrace:\n",
            "#0 0x5862ce61c6aa <unknown>\n",
            "#1 0x5862ce2ff0dc <unknown>\n",
            "#2 0x5862ce34b931 <unknown>\n",
            "#3 0x5862ce34ba21 <unknown>\n",
            "#4 0x5862ce390234 <unknown>\n",
            "#5 0x5862ce36e89d <unknown>\n",
            "#6 0x5862ce38d5c3 <unknown>\n",
            "#7 0x5862ce36e613 <unknown>\n",
            "#8 0x5862ce33e4f7 <unknown>\n",
            "#9 0x5862ce33ee4e <unknown>\n",
            "#10 0x5862ce5e287b <unknown>\n",
            "#11 0x5862ce5e6921 <unknown>\n",
            "#12 0x5862ce5ce36e <unknown>\n",
            "#13 0x5862ce5e7482 <unknown>\n",
            "#14 0x5862ce5b2ccf <unknown>\n",
            "#15 0x5862ce60c0a8 <unknown>\n",
            "#16 0x5862ce60c280 <unknown>\n",
            "#17 0x5862ce61b7dc <unknown>\n",
            "#18 0x7be1ac29eac3 <unknown>\n",
            "\n",
            "Saved text: text_files/REV_14.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//REV/14: Message: \n",
            "Stacktrace:\n",
            "#0 0x55aec09d86aa <unknown>\n",
            "#1 0x55aec06bb0dc <unknown>\n",
            "#2 0x55aec0707931 <unknown>\n",
            "#3 0x55aec0707a21 <unknown>\n",
            "#4 0x55aec074c234 <unknown>\n",
            "#5 0x55aec072a89d <unknown>\n",
            "#6 0x55aec07495c3 <unknown>\n",
            "#7 0x55aec072a613 <unknown>\n",
            "#8 0x55aec06fa4f7 <unknown>\n",
            "#9 0x55aec06fae4e <unknown>\n",
            "#10 0x55aec099e87b <unknown>\n",
            "#11 0x55aec09a2921 <unknown>\n",
            "#12 0x55aec098a36e <unknown>\n",
            "#13 0x55aec09a3482 <unknown>\n",
            "#14 0x55aec096eccf <unknown>\n",
            "#15 0x55aec09c80a8 <unknown>\n",
            "#16 0x55aec09c8280 <unknown>\n",
            "#17 0x55aec09d77dc <unknown>\n",
            "#18 0x78ff9a348ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/REV_15.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//REV/15: Message: \n",
            "Stacktrace:\n",
            "#0 0x5b81ea1956aa <unknown>\n",
            "#1 0x5b81e9e780dc <unknown>\n",
            "#2 0x5b81e9ec4931 <unknown>\n",
            "#3 0x5b81e9ec4a21 <unknown>\n",
            "#4 0x5b81e9f09234 <unknown>\n",
            "#5 0x5b81e9ee789d <unknown>\n",
            "#6 0x5b81e9f065c3 <unknown>\n",
            "#7 0x5b81e9ee7613 <unknown>\n",
            "#8 0x5b81e9eb74f7 <unknown>\n",
            "#9 0x5b81e9eb7e4e <unknown>\n",
            "#10 0x5b81ea15b87b <unknown>\n",
            "#11 0x5b81ea15f921 <unknown>\n",
            "#12 0x5b81ea14736e <unknown>\n",
            "#13 0x5b81ea160482 <unknown>\n",
            "#14 0x5b81ea12bccf <unknown>\n",
            "#15 0x5b81ea1850a8 <unknown>\n",
            "#16 0x5b81ea185280 <unknown>\n",
            "#17 0x5b81ea1947dc <unknown>\n",
            "#18 0x7c7c9318dac3 <unknown>\n",
            "\n",
            "Saved text: text_files/REV_16.txt\n",
            "Failed to extract audio from https://live.bible.is/bible/MALNIB//REV/16: Message: \n",
            "Stacktrace:\n",
            "#0 0x5683d93996aa <unknown>\n",
            "#1 0x5683d907c0dc <unknown>\n",
            "#2 0x5683d90c8931 <unknown>\n",
            "#3 0x5683d90c8a21 <unknown>\n",
            "#4 0x5683d910d234 <unknown>\n",
            "#5 0x5683d90eb89d <unknown>\n",
            "#6 0x5683d910a5c3 <unknown>\n",
            "#7 0x5683d90eb613 <unknown>\n",
            "#8 0x5683d90bb4f7 <unknown>\n",
            "#9 0x5683d90bbe4e <unknown>\n",
            "#10 0x5683d935f87b <unknown>\n",
            "#11 0x5683d9363921 <unknown>\n",
            "#12 0x5683d934b36e <unknown>\n",
            "#13 0x5683d9364482 <unknown>\n",
            "#14 0x5683d932fccf <unknown>\n",
            "#15 0x5683d93890a8 <unknown>\n",
            "#16 0x5683d9389280 <unknown>\n",
            "#17 0x5683d93987dc <unknown>\n",
            "#18 0x7a85579c7ac3 <unknown>\n",
            "\n",
            "Saved text: text_files/REV_17.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/REV_18.txt\n",
            "Downloaded: audio_files/REV_18_1.mp3\n",
            "Saved text: text_files/REV_19.txt\n",
            "Downloaded: audio_files/REV_19_1.mp3\n",
            "Saved text: text_files/REV_20.txt\n",
            "Downloaded: audio_files/REV_20_1.mp3\n",
            "Saved text: text_files/REV_21.txt\n",
            "Failed to download _: Invalid URL '_': No scheme supplied. Perhaps you meant https://_?\n",
            "Saved text: text_files/REV_22.txt\n",
            "Downloaded: audio_files/REV_22_1.mp3\n"
          ]
        }
      ],
      "source": [
        "# Extract text and audio for all chapters of all books\n",
        "extract_all_text_and_audio()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhTQCYOH3MsE"
      },
      "source": [
        "Organizing the Data by Chapters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSbZ-ize3NnB"
      },
      "outputs": [],
      "source": [
        "import os # Import the os module for interacting with the operating system\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63-JNv6r3Vj4"
      },
      "outputs": [],
      "source": [
        "# Directories for storing organized data\n",
        "organized_dir = '/content/organized data'\n",
        "text_dir = '/content/text_files'\n",
        "audio_dir = '/content/audio_files'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUSaANHL3iMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f300ab3-542d-4e86-dcd5-2447349e3cd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data organized successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a directory to organize the data by chapters\n",
        "os.makedirs(organized_dir, exist_ok=True)  # Create the organized directory if it doesn't exist\n",
        "\n",
        "# Organize the data by chapters\n",
        "for book_id in info:  # Iterate over each book in the info dictionary\n",
        "    book_dir = os.path.join(organized_dir, book_id)  # Create a directory for the book\n",
        "    os.makedirs(book_dir, exist_ok=True)  # Create the book directory if it doesn't exist\n",
        "\n",
        "    num_chapters = info[book_id]  # Get the number of chapters for the current book\n",
        "    for chapter in range(1, num_chapters + 1):  # Iterate over each chapter\n",
        "        chapter_dir = os.path.join(book_dir, f'Chapter_{chapter}')  # Create a directory for the chapter\n",
        "        os.makedirs(chapter_dir, exist_ok=True)  # Create the chapter directory if it doesn't exist\n",
        "\n",
        "        # Move the text file\n",
        "        text_filename = f\"{book_id}_{chapter}.txt\"  # Construct the text file name\n",
        "        src_text_path = os.path.join(text_dir, text_filename)  # Construct the source path for the text file\n",
        "        dest_text_path = os.path.join(chapter_dir, text_filename)  # Construct the destination path for the text file\n",
        "        if os.path.exists(src_text_path):  # Check if the source text file exists\n",
        "            shutil.move(src_text_path, dest_text_path)  # Move the text file to the destination\n",
        "\n",
        "        # Move the audio files\n",
        "        audio_filenames = [f for f in os.listdir(audio_dir) if f.startswith(f\"{book_id}_{chapter}_\")]  # Get all audio files for the current chapter\n",
        "        for audio_filename in audio_filenames:  # Iterate over each audio file\n",
        "            src_audio_path = os.path.join(audio_dir, audio_filename)  # Construct the source path for the audio file\n",
        "            dest_audio_path = os.path.join(chapter_dir, audio_filename)  # Construct the destination path for the audio file\n",
        "            if os.path.exists(src_audio_path):  # Check if the source audio file exists\n",
        "                shutil.move(src_audio_path, dest_audio_path)  # Move the audio file to the destination\n",
        "\n",
        "print(\"Data organized successfully.\")  # Print a success message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRRa73jL3mce"
      },
      "source": [
        "Analysis of Audio Duration and Text Length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuODB9lx3nIN"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDGOilv_3sd2"
      },
      "outputs": [],
      "source": [
        "# Function to get the duration of an audio file\n",
        "def get_audio_duration(file_path):\n",
        "    y, sr = librosa.load(file_path)\n",
        "    return librosa.get_duration(y=y, sr=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtxPo4sU31SN"
      },
      "outputs": [],
      "source": [
        "# Initialize empty lists to store audio durations and text lengths\n",
        "audio_durations = []\n",
        "text_lengths = []\n",
        "\n",
        "# Iterate over each book in the 'info' dictionary\n",
        "for book_id in info:\n",
        "    # Construct the path to the directory containing chapters for the current book\n",
        "    book_dir = os.path.join(organized_dir, book_id)\n",
        "\n",
        "    # Get the number of chapters for the current book from the 'info' dictionary\n",
        "    num_chapters = info[book_id]\n",
        "\n",
        "    # Iterate over each chapter of the current book\n",
        "    for chapter in range(1, num_chapters + 1):\n",
        "        # Construct the path to the directory of the current chapter\n",
        "        chapter_dir = os.path.join(book_dir, f'Chapter_{chapter}')\n",
        "\n",
        "        # Get the text length for the current chapter\n",
        "        text_filename = f\"{book_id}_{chapter}.txt\"\n",
        "        text_path = os.path.join(chapter_dir, text_filename)\n",
        "\n",
        "        # Check if the text file exists for the current chapter\n",
        "        if os.path.exists(text_path):\n",
        "            # Open the text file and read its content\n",
        "            with open(text_path, 'r', encoding='utf-8') as file:\n",
        "                text_content = file.read()\n",
        "                # Append the length of the text content to the 'text_lengths' list\n",
        "                text_lengths.append(len(text_content))\n",
        "\n",
        "        # Get the audio duration for the current chapter\n",
        "        audio_filenames = [f for f in os.listdir(chapter_dir) if f.endswith('.mp3')]\n",
        "        for audio_filename in audio_filenames:\n",
        "            audio_path = os.path.join(chapter_dir, audio_filename)\n",
        "            # Check if the audio file exists for the current chapter\n",
        "            if os.path.exists(audio_path):\n",
        "                # Calculate the duration of the audio file and append it to the 'audio_durations' list\n",
        "                audio_duration = get_audio_duration(audio_path)\n",
        "                audio_durations.append(audio_duration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNGlionM4A_n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "outputId": "b64317fe-0fce-4eff-8c8c-57917eee4809"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plotting the results\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(audio_durations, bins=20, color='blue', edgecolor='black')\n",
        "plt.title('Distribution of Audio Durations')\n",
        "plt.xlabel('Duration (seconds)')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(text_lengths, bins=20, color='green', edgecolor='black')\n",
        "plt.title('Distribution of Text Lengths')\n",
        "plt.xlabel('Text Length (characters)')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwx1YYNp4JVR"
      },
      "source": [
        "Transcripting the Audio into Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETlQapxA4Klp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ab7c0b8-62f9-4b15-a1f2-d00bef24f78b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faster_whisper\n",
            "  Downloading faster_whisper-1.0.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting av<13,>=11.0 (from faster_whisper)\n",
            "  Downloading av-12.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ctranslate2<5,>=4.0 (from faster_whisper)\n",
            "  Downloading ctranslate2-4.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (192.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.3/192.3 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster_whisper) (0.23.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster_whisper) (0.19.1)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster_whisper)\n",
            "  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster_whisper) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster_whisper) (1.25.2)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster_whisper) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster_whisper) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster_whisper) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster_whisper) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster_whisper) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster_whisper) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster_whisper) (4.12.2)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster_whisper)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster_whisper) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster_whisper) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster_whisper) (1.12.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster_whisper)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster_whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster_whisper) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster_whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster_whisper) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2,>=1.14->faster_whisper) (1.3.0)\n",
            "Installing collected packages: humanfriendly, ctranslate2, av, coloredlogs, onnxruntime, faster_whisper\n",
            "Successfully installed av-12.1.0 coloredlogs-15.0.1 ctranslate2-4.3.1 faster_whisper-1.0.2 humanfriendly-10.0 onnxruntime-1.18.0\n"
          ]
        }
      ],
      "source": [
        "pip install faster_whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfsstidO4P45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbae58d2-f6c7-40bb-bfb8-c1afcd7fd224"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWQQSkK-4Th9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f8e042e-523f-4e5a-a695-014517abe3d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0->torchaudio)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0->torchaudio)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0->torchaudio)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0->torchaudio)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0->torchaudio)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0->torchaudio)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0->torchaudio)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0->torchaudio)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0->torchaudio)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0->torchaudio)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0->torchaudio)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->torchaudio)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0->torchaudio) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0->torchaudio) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "pip install torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqFI5Pj34ZL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9140a70-67ef-4e67-e90b-b48d9bb25a98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "transcribe = pipeline(task=\"automatic-speech-recognition\", model=\"vasista22/whisper-telugu-Medium\", chunk_length_s=30, device=device)\n",
        "transcribe.model.config.forced_decoder_ids = transcribe.tokenizer.get_decoder_prompt_ids(language=\"te\", task=\"transcribe\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator = pipeline(\"translation_en_to_te\", model=\"vasista22/whisper-telugu-Medium\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRjZqa473oo4",
        "outputId": "1a2b9990-d76f-44e6-d512-027847ae69a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "The model 'WhisperForConditionalGeneration' is not supported for translation_en_to_te. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os  # Import the os module for interacting with the operating system\n",
        "\n",
        "exceptaudios = []  # Initialize a list to keep track of audio files that could not be processed\n",
        "maindirectory = \"/content/organized data\"  # Set the main directory path\n",
        "\n",
        "# Ensure model and translator are defined\n",
        "from transformers import pipeline\n",
        "\n",
        "# Define your model and translator (ensure you have loaded them correctly)\n",
        "# Example: Replace 'your_model' and 'your_translator' with actual model and translator instances\n",
        "# Assuming you have the `model` for transcription and `translator` for translation\n",
        "model = \"vasista22/whisper-telugu-Medium\"  # Your transcription model here\n",
        "translator = pipeline(\"translation\", model=\"vasista22/whisper-telugu-Medium\")  # Example translator\n",
        "\n",
        "info = {\n",
        "    \"2CO\": 13,  # Example data: book 2CO has 13 chapters\n",
        "    \"GAL\": 6,   # Example data: book GAL has 6 chapters\n",
        "    \"EPH\": 6,   # Example data: book EPH has 6 chapters\n",
        "    \"2TH\": 3,   # Example data: book 2TH has 3 chapters\n",
        "    \"1TI\": 6,   # Example data: book 1TI has 6 chapters\n",
        "    \"2TI\": 4,   # Example data: book 2TI has 4 chapters\n",
        "    \"TIT\": 3,   # Example data: book TIT has 3 chapters\n",
        "    \"PHM\": 1,   # Example data: book PHM has 1 chapter\n",
        "    \"HEB\": 13,  # Example data: book HEB has 13 chapters\n",
        "    \"JAS\": 5,   # Example data: book JAS has 5 chapters\n",
        "    \"1PE\": 5,   # Example data: book 1PE has 5 chapters\n",
        "    \"2PE\": 3,   # Example data: book 2PE has 3 chapters\n",
        "    \"1JN\": 5,   # Example data: book 1JN has 5 chapters\n",
        "    \"3JN\": 1,   # Example data: book 3JN has 1 chapter\n",
        "    \"JUD\": 1,   # Example data: book JUD has 1 chapter\n",
        "    \"REV\": 22,  # Example data: book REV has 22 chapters\n",
        "}\n",
        "\n",
        "def split_text(text, max_length):\n",
        "    \"\"\"\n",
        "    Split text into chunks with a maximum length.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): The input text to be split.\n",
        "    max_length (int): The maximum length of each chunk.\n",
        "\n",
        "    Returns:\n",
        "    List[str]: A list of text chunks.\n",
        "    \"\"\"\n",
        "    words = text.split()  # Split the text into words\n",
        "    chunks = []  # Initialize a list to store text chunks\n",
        "    current_chunk = []  # Initialize a list to store the current chunk\n",
        "    current_length = 0  # Initialize the current length of the chunk\n",
        "\n",
        "    for word in words:  # Iterate over each word in the text\n",
        "        word_length = len(word)  # Get the length of the word\n",
        "        if current_length + word_length <= max_length:  # Check if the word can be added to the current chunk\n",
        "            current_chunk.append(word)  # Add the word to the current chunk\n",
        "            current_length += word_length + 1  # Update the current length (+1 for the space)\n",
        "        else:  # If the word cannot be added to the current chunk\n",
        "            chunks.append(\" \".join(current_chunk))  # Add the current chunk to the list of chunks\n",
        "            current_chunk = [word]  # Start a new chunk with the current word\n",
        "            current_length = word_length + 1  # Update the current length\n",
        "\n",
        "    if current_chunk:  # If there are words left in the current chunk\n",
        "        chunks.append(\" \".join(current_chunk))  # Add the last chunk to the list of chunks\n",
        "\n",
        "    return chunks  # Return the list of text chunks\n",
        "\n",
        "def transcription():\n",
        "    \"\"\"\n",
        "    Transcribe audio files and translate the text to Telugu.\n",
        "    \"\"\"\n",
        "    for k in info.keys():  # Iterate over each book in the info dictionary\n",
        "        for chap in range(1, info[k] + 1):  # Iterate over each chapter in the book\n",
        "            try:\n",
        "                transcribed_text = \"\"  # Initialize the transcribed text\n",
        "                audiopath = f\"{maindirectory}/{k}/Chapter_{chap}/{k}_{chap}_1.mp3\"  # Construct the audio file path\n",
        "                if not os.path.exists(audiopath):  # Check if the audio file exists\n",
        "                    continue  # Skip to the next chapter if the audio file does not exist\n",
        "\n",
        "                # Transcribe the audio to English text\n",
        "                segments, _ = model.transcribe(audiopath, beam_size=5, language=\"en\")  # Transcribe the audio file\n",
        "                english_text = \" \".join([segment.text for segment in segments])  # Combine the transcribed segments into a single string\n",
        "\n",
        "                # Split the text into chunks to fit within the model's token limit\n",
        "                max_length = 512  # Set the maximum length of each chunk\n",
        "                chunks = split_text(english_text, max_length)  # Split the text into chunks\n",
        "\n",
        "                # Translate each chunk and combine the results\n",
        "                telugu_translation = \"\"  # Initialize the telugu translation\n",
        "                for chunk in chunks:  # Iterate over each chunk\n",
        "                    translation = translator(chunk, target_lang=\"ml\")[0]['translation_text']  # Translate the chunk\n",
        "                    malayalam_translation += translation + \" \"  # Add the translation to the combined result\n",
        "\n",
        "                # Save the Malayalam text\n",
        "                output_path = f\"{maindirectory}/{k}/Chapter_{chap}/{k}_{chap}_transcribed_te.txt\"\n",
        "                os.makedirs(os.path.dirname(output_path), exist_ok=True)  # Ensure the directory exists\n",
        "                with open(output_path, \"w\", encoding=\"utf-8\") as f:  # Open the file for writing\n",
        "                    f.write(malayalam_translation.strip())  # Write the translated text to the file\n",
        "\n",
        "                print(f\"Processed {audiopath}\")  # Print a message indicating the file was processed\n",
        "            except Exception as e:  # If an exception occurs\n",
        "                exceptaudios.append(audiopath)  # Add the audio file to the list of exceptions\n",
        "                print(f\"Error processing {audiopath}: {e}\")  # Print the error message\n",
        "\n",
        "# Call the transcription function\n",
        "transcription()  # Start the transcription process\n",
        "\n",
        "# Print any audio files that couldn't be processed\n",
        "if exceptaudios:  # If there are audio files that couldn't be processed\n",
        "    print(\"The following audio files could not be processed:\")  # Print a message\n",
        "    for audio in exceptaudios:  # Iterate over each audio file\n",
        "        print(audio)  # Print the audio file path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zuDmKsl0nbq",
        "outputId": "8cb73cd6-f318-4ad0-9b08-a89be803933b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "The model 'WhisperForConditionalGeneration' is not supported for translation. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing /content/organized data/2CO/Chapter_1/2CO_1_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2CO/Chapter_2/2CO_2_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2CO/Chapter_4/2CO_4_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2CO/Chapter_5/2CO_5_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2CO/Chapter_6/2CO_6_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2CO/Chapter_7/2CO_7_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2CO/Chapter_8/2CO_8_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2CO/Chapter_9/2CO_9_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2CO/Chapter_10/2CO_10_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2CO/Chapter_11/2CO_11_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2CO/Chapter_13/2CO_13_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/GAL/Chapter_1/GAL_1_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/GAL/Chapter_2/GAL_2_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/GAL/Chapter_3/GAL_3_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/GAL/Chapter_4/GAL_4_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/GAL/Chapter_5/GAL_5_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/GAL/Chapter_6/GAL_6_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/EPH/Chapter_1/EPH_1_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2TH/Chapter_2/2TH_2_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/1TI/Chapter_6/1TI_6_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2TI/Chapter_1/2TI_1_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2TI/Chapter_2/2TI_2_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2TI/Chapter_3/2TI_3_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/TIT/Chapter_1/TIT_1_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/TIT/Chapter_2/TIT_2_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/TIT/Chapter_3/TIT_3_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/PHM/Chapter_1/PHM_1_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/HEB/Chapter_2/HEB_2_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/HEB/Chapter_7/HEB_7_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/HEB/Chapter_13/HEB_13_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/JAS/Chapter_1/JAS_1_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/JAS/Chapter_3/JAS_3_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/JAS/Chapter_4/JAS_4_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/JAS/Chapter_5/JAS_5_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/1PE/Chapter_1/1PE_1_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/1PE/Chapter_2/1PE_2_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/1JN/Chapter_5/1JN_5_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_1/REV_1_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_2/REV_2_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_3/REV_3_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_5/REV_5_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_6/REV_6_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_8/REV_8_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_11/REV_11_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_18/REV_18_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_19/REV_19_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_20/REV_20_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_22/REV_22_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "The following audio files could not be processed:\n",
            "/content/organized data/2CO/Chapter_1/2CO_1_1.mp3\n",
            "/content/organized data/2CO/Chapter_2/2CO_2_1.mp3\n",
            "/content/organized data/2CO/Chapter_4/2CO_4_1.mp3\n",
            "/content/organized data/2CO/Chapter_5/2CO_5_1.mp3\n",
            "/content/organized data/2CO/Chapter_6/2CO_6_1.mp3\n",
            "/content/organized data/2CO/Chapter_7/2CO_7_1.mp3\n",
            "/content/organized data/2CO/Chapter_8/2CO_8_1.mp3\n",
            "/content/organized data/2CO/Chapter_9/2CO_9_1.mp3\n",
            "/content/organized data/2CO/Chapter_10/2CO_10_1.mp3\n",
            "/content/organized data/2CO/Chapter_11/2CO_11_1.mp3\n",
            "/content/organized data/2CO/Chapter_13/2CO_13_1.mp3\n",
            "/content/organized data/GAL/Chapter_1/GAL_1_1.mp3\n",
            "/content/organized data/GAL/Chapter_2/GAL_2_1.mp3\n",
            "/content/organized data/GAL/Chapter_3/GAL_3_1.mp3\n",
            "/content/organized data/GAL/Chapter_4/GAL_4_1.mp3\n",
            "/content/organized data/GAL/Chapter_5/GAL_5_1.mp3\n",
            "/content/organized data/GAL/Chapter_6/GAL_6_1.mp3\n",
            "/content/organized data/EPH/Chapter_1/EPH_1_1.mp3\n",
            "/content/organized data/2TH/Chapter_2/2TH_2_1.mp3\n",
            "/content/organized data/1TI/Chapter_6/1TI_6_1.mp3\n",
            "/content/organized data/2TI/Chapter_1/2TI_1_1.mp3\n",
            "/content/organized data/2TI/Chapter_2/2TI_2_1.mp3\n",
            "/content/organized data/2TI/Chapter_3/2TI_3_1.mp3\n",
            "/content/organized data/TIT/Chapter_1/TIT_1_1.mp3\n",
            "/content/organized data/TIT/Chapter_2/TIT_2_1.mp3\n",
            "/content/organized data/TIT/Chapter_3/TIT_3_1.mp3\n",
            "/content/organized data/PHM/Chapter_1/PHM_1_1.mp3\n",
            "/content/organized data/HEB/Chapter_2/HEB_2_1.mp3\n",
            "/content/organized data/HEB/Chapter_7/HEB_7_1.mp3\n",
            "/content/organized data/HEB/Chapter_13/HEB_13_1.mp3\n",
            "/content/organized data/JAS/Chapter_1/JAS_1_1.mp3\n",
            "/content/organized data/JAS/Chapter_3/JAS_3_1.mp3\n",
            "/content/organized data/JAS/Chapter_4/JAS_4_1.mp3\n",
            "/content/organized data/JAS/Chapter_5/JAS_5_1.mp3\n",
            "/content/organized data/1PE/Chapter_1/1PE_1_1.mp3\n",
            "/content/organized data/1PE/Chapter_2/1PE_2_1.mp3\n",
            "/content/organized data/1JN/Chapter_5/1JN_5_1.mp3\n",
            "/content/organized data/REV/Chapter_1/REV_1_1.mp3\n",
            "/content/organized data/REV/Chapter_2/REV_2_1.mp3\n",
            "/content/organized data/REV/Chapter_3/REV_3_1.mp3\n",
            "/content/organized data/REV/Chapter_5/REV_5_1.mp3\n",
            "/content/organized data/REV/Chapter_6/REV_6_1.mp3\n",
            "/content/organized data/REV/Chapter_8/REV_8_1.mp3\n",
            "/content/organized data/REV/Chapter_11/REV_11_1.mp3\n",
            "/content/organized data/REV/Chapter_18/REV_18_1.mp3\n",
            "/content/organized data/REV/Chapter_19/REV_19_1.mp3\n",
            "/content/organized data/REV/Chapter_20/REV_20_1.mp3\n",
            "/content/organized data/REV/Chapter_22/REV_22_1.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os  # Import the os module for interacting with the operating system\n",
        "\n",
        "exceptaudios = []  # Initialize a list to keep track of audio files that could not be processed\n",
        "maindirectory = \"/content/organized data\"  # Set the main directory path\n",
        "\n",
        "def split_text(text, max_length):\n",
        "    \"\"\"\n",
        "    Split text into chunks with a maximum length.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): The input text to be split.\n",
        "    max_length (int): The maximum length of each chunk.\n",
        "\n",
        "    Returns:\n",
        "    List[str]: A list of text chunks.\n",
        "    \"\"\"\n",
        "    words = text.split()  # Split the text into words\n",
        "    chunks = []  # Initialize a list to store text chunks\n",
        "    current_chunk = []  # Initialize a list to store the current chunk\n",
        "    current_length = 0  # Initialize the current length of the chunk\n",
        "\n",
        "    for word in words:  # Iterate over each word in the text\n",
        "        word_length = len(word)  # Get the length of the word\n",
        "        if current_length + word_length <= max_length:  # Check if the word can be added to the current chunk\n",
        "            current_chunk.append(word)  # Add the word to the current chunk\n",
        "            current_length += word_length + 1  # Update the current length (+1 for the space)\n",
        "        else:  # If the word cannot be added to the current chunk\n",
        "            chunks.append(\" \".join(current_chunk))  # Add the current chunk to the list of chunks\n",
        "            current_chunk = [word]  # Start a new chunk with the current word\n",
        "            current_length = word_length + 1  # Update the current length\n",
        "\n",
        "    if current_chunk:  # If there are words left in the current chunk\n",
        "        chunks.append(\" \".join(current_chunk))  # Add the last chunk to the list of chunks\n",
        "\n",
        "    return chunks  # Return the list of text chunks\n",
        "\n",
        "def transcription():\n",
        "    \"\"\"\n",
        "    Transcribe audio files and translate the text to telugu.\n",
        "    \"\"\"\n",
        "    for k in info.keys():  # Iterate over each book in the info dictionary\n",
        "        for chap in range(1, info[k] + 1):  # Iterate over each chapter in the book\n",
        "            try:\n",
        "                transcribed_text = \"\"  # Initialize the transcribed text\n",
        "                audiopath = f\"{maindirectory}/{k}/Chapter_{chap}/{k}_{chap}_1.mp3\"  # Construct the audio file path\n",
        "                if not os.path.exists(audiopath):  # Check if the audio file exists\n",
        "                    continue  # Skip to the next chapter if the audio file does not exist\n",
        "\n",
        "                # Transcribe the audio to English text\n",
        "                segments, _ = model.transcribe(audiopath, beam_size=5, language=\"en\")  # Transcribe the audio file\n",
        "                english_text = \" \".join([segment.text for segment in segments])  # Combine the transcribed segments into a single string\n",
        "\n",
        "                # Split the text into chunks to fit within the model's token limit\n",
        "                max_length = 512  # Set the maximum length of each chunk\n",
        "                chunks = split_text(english_text, max_length)  # Split the text into chunks\n",
        "\n",
        "                # Translate each chunk and combine the results\n",
        "                telugu_translation = \"\"  # Initialize the telugu translation\n",
        "                for chunk in chunks:  # Iterate over each chunk\n",
        "                    translation = translator(chunk)[0]['translation_text']  # Translate the chunk\n",
        "                    telugu_translation += translation + \" \"  # Add the translation to the combined result\n",
        "\n",
        "                # Save the Malayalam text\n",
        "                with open(f\"{maindirectory}/{k}/Chapter_{chap}/{k}_{chap}_transcribed_ml.txt\", \"w\", encoding=\"utf-8\") as f:  # Open the file for writing\n",
        "                    f.write(telugu_translation.strip())  # Write the translated text to the file\n",
        "\n",
        "                print(f\"Processed {audiopath}\")  # Print a message indicating the file was processed\n",
        "            except Exception as e:  # If an exception occurs\n",
        "                exceptaudios.append(audiopath)  # Add the audio file to the list of exceptions\n",
        "                print(f\"Error processing {audiopath}: {e}\")  # Print the error message\n",
        "\n",
        "# Call the transcription function\n",
        "transcription()  # Start the transcription process\n",
        "\n",
        "# Print any audio files that couldn't be processed\n",
        "if exceptaudios:  # If there are audio files that couldn't be processed\n",
        "    print(\"The following audio files could not be processed:\")  # Print a message\n",
        "    for audio in exceptaudios:  # Iterate over each audio file\n",
        "        print(audio)  # Print the audio file path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otHYkvE8EHTy",
        "outputId": "6f1e7df4-0566-4220-b82c-b70469006778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing /content/organized data/2CO/Chapter_1/2CO_1_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2CO/Chapter_2/2CO_2_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2CO/Chapter_4/2CO_4_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2CO/Chapter_5/2CO_5_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2CO/Chapter_6/2CO_6_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2CO/Chapter_7/2CO_7_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2CO/Chapter_8/2CO_8_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2CO/Chapter_9/2CO_9_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2CO/Chapter_10/2CO_10_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2CO/Chapter_11/2CO_11_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2CO/Chapter_13/2CO_13_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/GAL/Chapter_1/GAL_1_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/GAL/Chapter_2/GAL_2_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/GAL/Chapter_3/GAL_3_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/GAL/Chapter_4/GAL_4_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/GAL/Chapter_5/GAL_5_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/GAL/Chapter_6/GAL_6_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/EPH/Chapter_1/EPH_1_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2TH/Chapter_2/2TH_2_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/1TI/Chapter_6/1TI_6_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2TI/Chapter_1/2TI_1_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2TI/Chapter_2/2TI_2_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/2TI/Chapter_3/2TI_3_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/TIT/Chapter_1/TIT_1_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/TIT/Chapter_2/TIT_2_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/TIT/Chapter_3/TIT_3_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/PHM/Chapter_1/PHM_1_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/HEB/Chapter_2/HEB_2_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/HEB/Chapter_7/HEB_7_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/HEB/Chapter_13/HEB_13_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/JAS/Chapter_1/JAS_1_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/JAS/Chapter_3/JAS_3_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/JAS/Chapter_4/JAS_4_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/JAS/Chapter_5/JAS_5_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/1PE/Chapter_1/1PE_1_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/1PE/Chapter_2/1PE_2_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/1JN/Chapter_5/1JN_5_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_1/REV_1_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_2/REV_2_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_3/REV_3_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_5/REV_5_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_6/REV_6_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_8/REV_8_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_11/REV_11_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_18/REV_18_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_19/REV_19_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_20/REV_20_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "Error processing /content/organized data/REV/Chapter_22/REV_22_1.mp3: 'str' object has no attribute 'transcribe'\n",
            "The following audio files could not be processed:\n",
            "/content/organized data/2CO/Chapter_1/2CO_1_1.mp3\n",
            "/content/organized data/2CO/Chapter_2/2CO_2_1.mp3\n",
            "/content/organized data/2CO/Chapter_4/2CO_4_1.mp3\n",
            "/content/organized data/2CO/Chapter_5/2CO_5_1.mp3\n",
            "/content/organized data/2CO/Chapter_6/2CO_6_1.mp3\n",
            "/content/organized data/2CO/Chapter_7/2CO_7_1.mp3\n",
            "/content/organized data/2CO/Chapter_8/2CO_8_1.mp3\n",
            "/content/organized data/2CO/Chapter_9/2CO_9_1.mp3\n",
            "/content/organized data/2CO/Chapter_10/2CO_10_1.mp3\n",
            "/content/organized data/2CO/Chapter_11/2CO_11_1.mp3\n",
            "/content/organized data/2CO/Chapter_13/2CO_13_1.mp3\n",
            "/content/organized data/GAL/Chapter_1/GAL_1_1.mp3\n",
            "/content/organized data/GAL/Chapter_2/GAL_2_1.mp3\n",
            "/content/organized data/GAL/Chapter_3/GAL_3_1.mp3\n",
            "/content/organized data/GAL/Chapter_4/GAL_4_1.mp3\n",
            "/content/organized data/GAL/Chapter_5/GAL_5_1.mp3\n",
            "/content/organized data/GAL/Chapter_6/GAL_6_1.mp3\n",
            "/content/organized data/EPH/Chapter_1/EPH_1_1.mp3\n",
            "/content/organized data/2TH/Chapter_2/2TH_2_1.mp3\n",
            "/content/organized data/1TI/Chapter_6/1TI_6_1.mp3\n",
            "/content/organized data/2TI/Chapter_1/2TI_1_1.mp3\n",
            "/content/organized data/2TI/Chapter_2/2TI_2_1.mp3\n",
            "/content/organized data/2TI/Chapter_3/2TI_3_1.mp3\n",
            "/content/organized data/TIT/Chapter_1/TIT_1_1.mp3\n",
            "/content/organized data/TIT/Chapter_2/TIT_2_1.mp3\n",
            "/content/organized data/TIT/Chapter_3/TIT_3_1.mp3\n",
            "/content/organized data/PHM/Chapter_1/PHM_1_1.mp3\n",
            "/content/organized data/HEB/Chapter_2/HEB_2_1.mp3\n",
            "/content/organized data/HEB/Chapter_7/HEB_7_1.mp3\n",
            "/content/organized data/HEB/Chapter_13/HEB_13_1.mp3\n",
            "/content/organized data/JAS/Chapter_1/JAS_1_1.mp3\n",
            "/content/organized data/JAS/Chapter_3/JAS_3_1.mp3\n",
            "/content/organized data/JAS/Chapter_4/JAS_4_1.mp3\n",
            "/content/organized data/JAS/Chapter_5/JAS_5_1.mp3\n",
            "/content/organized data/1PE/Chapter_1/1PE_1_1.mp3\n",
            "/content/organized data/1PE/Chapter_2/1PE_2_1.mp3\n",
            "/content/organized data/1JN/Chapter_5/1JN_5_1.mp3\n",
            "/content/organized data/REV/Chapter_1/REV_1_1.mp3\n",
            "/content/organized data/REV/Chapter_2/REV_2_1.mp3\n",
            "/content/organized data/REV/Chapter_3/REV_3_1.mp3\n",
            "/content/organized data/REV/Chapter_5/REV_5_1.mp3\n",
            "/content/organized data/REV/Chapter_6/REV_6_1.mp3\n",
            "/content/organized data/REV/Chapter_8/REV_8_1.mp3\n",
            "/content/organized data/REV/Chapter_11/REV_11_1.mp3\n",
            "/content/organized data/REV/Chapter_18/REV_18_1.mp3\n",
            "/content/organized data/REV/Chapter_19/REV_19_1.mp3\n",
            "/content/organized data/REV/Chapter_20/REV_20_1.mp3\n",
            "/content/organized data/REV/Chapter_22/REV_22_1.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a DataFrame"
      ],
      "metadata": {
        "id": "wyV3CRFd0oX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import pandas as pd\n",
        "\n",
        "organized_dir = \"/content/organized data\"  # Set the directory containing organized data\n",
        "\n",
        "data = []\n",
        "non_audio_data = []\n",
        "\n",
        "# Iterate over each book in the organized directory\n",
        "for book in os.listdir(organized_dir):\n",
        "    book_path = os.path.join(organized_dir, book)  # Get the path of the book directory\n",
        "    if os.path.isdir(book_path):  # Check if the item is a directory\n",
        "        for chapter in os.listdir(book_path):  # Iterate over each chapter in the book\n",
        "            _, chapter_id = chapter.split(\"_\")  # Extract the chapter ID from the filename\n",
        "            chapter_path = os.path.join(book_path, chapter)  # Get the path of the chapter directory\n",
        "            if os.path.isdir(chapter_path):  # Check if the item is a directory\n",
        "                audio_path = os.path.join(chapter_path, f'{book}_{chapter_id}_1.mp3')  # Get the path of the audio file\n",
        "                text_path = os.path.join(chapter_path, f'{book}_{chapter_id}.txt')  # Get the path of the text file\n",
        "                transcript_path = os.path.join(chapter_path, f'{book}_{chapter_id}_transcribed_te.txt')  # Get the path of the transcript file\n",
        "\n",
        "                # Read text file\n",
        "                with open(text_path, 'r', encoding='utf-8') as file:\n",
        "                    text = file.read()  # Read the content of the text file\n",
        "\n",
        "                transcript = None\n",
        "                # Check if transcript file exists\n",
        "                if os.path.exists(transcript_path):\n",
        "                    with open(transcript_path, 'r', encoding='utf-8') as file:\n",
        "                        transcript = file.read()  # Read the content of the transcript file\n",
        "                else:\n",
        "                    print(f\"{transcript_path} does not exist\")\n",
        "                    non_audio_data.append(transcript_path)  # Add the missing transcript file path to the list\n",
        "\n",
        "                try:\n",
        "                    # Load audio file\n",
        "                    y, sr = librosa.load(audio_path, sr=None)  # Load the audio file and its sampling rate\n",
        "\n",
        "                    # Store data\n",
        "                    data.append({\n",
        "                        'book': book,\n",
        "                        'chapter': chapter,\n",
        "                        'audio': y,\n",
        "                        'text': text,\n",
        "                        'transcript': transcript,\n",
        "                        'sampling_rate': sr\n",
        "                    })\n",
        "                except Exception as e:\n",
        "                    # Store data with empty sampling rate if audio file loading fails\n",
        "                    print(f\"Error loading audio {audio_path}: {e}\")\n",
        "                    data.append({\n",
        "                        'book': book,\n",
        "                        'chapter': chapter,\n",
        "                        'audio': None,\n",
        "                        'text': text,\n",
        "                        'transcript': transcript,\n",
        "                        'sampling_rate': \"\"\n",
        "                    })\n",
        "\n",
        "# Convert data to a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Output DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Output any non-audio data\n",
        "if non_audio_data:\n",
        "    print(\"The following transcript files could not be found:\")\n",
        "    for item in non_audio_data:\n",
        "        print(item)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74kD2Vdt1VX3",
        "outputId": "46c35210-81aa-49c7-8daa-d49a7a6fd78c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/organized data/PHP/Chapter_4/PHP_4_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/PHP/Chapter_4/PHP_4_1.mp3: [Errno 2] No such file or directory: '/content/organized data/PHP/Chapter_4/PHP_4_1.mp3'\n",
            "/content/organized data/PHP/Chapter_1/PHP_1_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/PHP/Chapter_1/PHP_1_1.mp3: [Errno 2] No such file or directory: '/content/organized data/PHP/Chapter_1/PHP_1_1.mp3'\n",
            "/content/organized data/PHP/Chapter_2/PHP_2_transcribed_te.txt does not exist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-5aa7a5ed62ac>:37: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  y, sr = librosa.load(audio_path, sr=None)  # Load the audio file and its sampling rate\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/organized data/PHP/Chapter_3/PHP_3_transcribed_te.txt does not exist\n",
            "/content/organized data/HEB/Chapter_11/HEB_11_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/HEB/Chapter_11/HEB_11_1.mp3: [Errno 2] No such file or directory: '/content/organized data/HEB/Chapter_11/HEB_11_1.mp3'\n",
            "/content/organized data/HEB/Chapter_4/HEB_4_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/HEB/Chapter_4/HEB_4_1.mp3: [Errno 2] No such file or directory: '/content/organized data/HEB/Chapter_4/HEB_4_1.mp3'\n",
            "/content/organized data/HEB/Chapter_8/HEB_8_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/HEB/Chapter_8/HEB_8_1.mp3: [Errno 2] No such file or directory: '/content/organized data/HEB/Chapter_8/HEB_8_1.mp3'\n",
            "/content/organized data/HEB/Chapter_5/HEB_5_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/HEB/Chapter_5/HEB_5_1.mp3: [Errno 2] No such file or directory: '/content/organized data/HEB/Chapter_5/HEB_5_1.mp3'\n",
            "/content/organized data/HEB/Chapter_9/HEB_9_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/HEB/Chapter_9/HEB_9_1.mp3: [Errno 2] No such file or directory: '/content/organized data/HEB/Chapter_9/HEB_9_1.mp3'\n",
            "/content/organized data/HEB/Chapter_13/HEB_13_transcribed_te.txt does not exist\n",
            "/content/organized data/HEB/Chapter_7/HEB_7_transcribed_te.txt does not exist\n",
            "/content/organized data/HEB/Chapter_1/HEB_1_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/HEB/Chapter_1/HEB_1_1.mp3: [Errno 2] No such file or directory: '/content/organized data/HEB/Chapter_1/HEB_1_1.mp3'\n",
            "/content/organized data/HEB/Chapter_10/HEB_10_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/HEB/Chapter_10/HEB_10_1.mp3: [Errno 2] No such file or directory: '/content/organized data/HEB/Chapter_10/HEB_10_1.mp3'\n",
            "/content/organized data/HEB/Chapter_2/HEB_2_transcribed_te.txt does not exist\n",
            "/content/organized data/HEB/Chapter_6/HEB_6_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/HEB/Chapter_6/HEB_6_1.mp3: [Errno 2] No such file or directory: '/content/organized data/HEB/Chapter_6/HEB_6_1.mp3'\n",
            "/content/organized data/HEB/Chapter_12/HEB_12_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/HEB/Chapter_12/HEB_12_1.mp3: [Errno 2] No such file or directory: '/content/organized data/HEB/Chapter_12/HEB_12_1.mp3'\n",
            "/content/organized data/HEB/Chapter_3/HEB_3_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/HEB/Chapter_3/HEB_3_1.mp3: [Errno 2] No such file or directory: '/content/organized data/HEB/Chapter_3/HEB_3_1.mp3'\n",
            "/content/organized data/MRK/Chapter_11/MRK_11_transcribed_te.txt does not exist\n",
            "/content/organized data/MRK/Chapter_15/MRK_15_transcribed_te.txt does not exist\n",
            "/content/organized data/MRK/Chapter_4/MRK_4_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/MRK/Chapter_4/MRK_4_1.mp3: [Errno 2] No such file or directory: '/content/organized data/MRK/Chapter_4/MRK_4_1.mp3'\n",
            "/content/organized data/MRK/Chapter_8/MRK_8_transcribed_te.txt does not exist\n",
            "/content/organized data/MRK/Chapter_5/MRK_5_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/MRK/Chapter_5/MRK_5_1.mp3: [Errno 2] No such file or directory: '/content/organized data/MRK/Chapter_5/MRK_5_1.mp3'\n",
            "/content/organized data/MRK/Chapter_9/MRK_9_transcribed_te.txt does not exist\n",
            "/content/organized data/MRK/Chapter_13/MRK_13_transcribed_te.txt does not exist\n",
            "/content/organized data/MRK/Chapter_7/MRK_7_transcribed_te.txt does not exist\n",
            "/content/organized data/MRK/Chapter_1/MRK_1_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/MRK/Chapter_1/MRK_1_1.mp3: [Errno 2] No such file or directory: '/content/organized data/MRK/Chapter_1/MRK_1_1.mp3'\n",
            "/content/organized data/MRK/Chapter_10/MRK_10_transcribed_te.txt does not exist\n",
            "/content/organized data/MRK/Chapter_2/MRK_2_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/MRK/Chapter_2/MRK_2_1.mp3: [Errno 2] No such file or directory: '/content/organized data/MRK/Chapter_2/MRK_2_1.mp3'\n",
            "/content/organized data/MRK/Chapter_16/MRK_16_transcribed_te.txt does not exist\n",
            "/content/organized data/MRK/Chapter_6/MRK_6_transcribed_te.txt does not exist\n",
            "/content/organized data/MRK/Chapter_12/MRK_12_transcribed_te.txt does not exist\n",
            "/content/organized data/MRK/Chapter_3/MRK_3_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/MRK/Chapter_3/MRK_3_1.mp3: [Errno 2] No such file or directory: '/content/organized data/MRK/Chapter_3/MRK_3_1.mp3'\n",
            "/content/organized data/MRK/Chapter_14/MRK_14_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/MRK/Chapter_14/MRK_14_1.mp3: [Errno 2] No such file or directory: '/content/organized data/MRK/Chapter_14/MRK_14_1.mp3'\n",
            "/content/organized data/JAS/Chapter_4/JAS_4_transcribed_te.txt does not exist\n",
            "/content/organized data/JAS/Chapter_5/JAS_5_transcribed_te.txt does not exist\n",
            "/content/organized data/JAS/Chapter_1/JAS_1_transcribed_te.txt does not exist\n",
            "/content/organized data/JAS/Chapter_2/JAS_2_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/JAS/Chapter_2/JAS_2_1.mp3: [Errno 2] No such file or directory: '/content/organized data/JAS/Chapter_2/JAS_2_1.mp3'\n",
            "/content/organized data/JAS/Chapter_3/JAS_3_transcribed_te.txt does not exist\n",
            "/content/organized data/GAL/Chapter_4/GAL_4_transcribed_te.txt does not exist\n",
            "/content/organized data/GAL/Chapter_5/GAL_5_transcribed_te.txt does not exist\n",
            "/content/organized data/GAL/Chapter_1/GAL_1_transcribed_te.txt does not exist\n",
            "/content/organized data/GAL/Chapter_2/GAL_2_transcribed_te.txt does not exist\n",
            "/content/organized data/GAL/Chapter_6/GAL_6_transcribed_te.txt does not exist\n",
            "/content/organized data/GAL/Chapter_3/GAL_3_transcribed_te.txt does not exist\n",
            "/content/organized data/JHN/Chapter_11/JHN_11_transcribed_te.txt does not exist\n",
            "/content/organized data/JHN/Chapter_15/JHN_15_transcribed_te.txt does not exist\n",
            "/content/organized data/JHN/Chapter_4/JHN_4_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/JHN/Chapter_4/JHN_4_1.mp3: [Errno 2] No such file or directory: '/content/organized data/JHN/Chapter_4/JHN_4_1.mp3'\n",
            "/content/organized data/JHN/Chapter_8/JHN_8_transcribed_te.txt does not exist\n",
            "/content/organized data/JHN/Chapter_19/JHN_19_transcribed_te.txt does not exist\n",
            "/content/organized data/JHN/Chapter_5/JHN_5_transcribed_te.txt does not exist\n",
            "/content/organized data/JHN/Chapter_9/JHN_9_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/JHN/Chapter_9/JHN_9_1.mp3: [Errno 2] No such file or directory: '/content/organized data/JHN/Chapter_9/JHN_9_1.mp3'\n",
            "/content/organized data/JHN/Chapter_21/JHN_21_transcribed_te.txt does not exist\n",
            "/content/organized data/JHN/Chapter_17/JHN_17_transcribed_te.txt does not exist\n",
            "/content/organized data/JHN/Chapter_13/JHN_13_transcribed_te.txt does not exist\n",
            "/content/organized data/JHN/Chapter_7/JHN_7_transcribed_te.txt does not exist\n",
            "/content/organized data/JHN/Chapter_1/JHN_1_transcribed_te.txt does not exist\n",
            "/content/organized data/JHN/Chapter_10/JHN_10_transcribed_te.txt does not exist\n",
            "/content/organized data/JHN/Chapter_2/JHN_2_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/JHN/Chapter_2/JHN_2_1.mp3: [Errno 2] No such file or directory: '/content/organized data/JHN/Chapter_2/JHN_2_1.mp3'\n",
            "/content/organized data/JHN/Chapter_18/JHN_18_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/JHN/Chapter_18/JHN_18_1.mp3: [Errno 2] No such file or directory: '/content/organized data/JHN/Chapter_18/JHN_18_1.mp3'\n",
            "/content/organized data/JHN/Chapter_16/JHN_16_transcribed_te.txt does not exist\n",
            "/content/organized data/JHN/Chapter_20/JHN_20_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/JHN/Chapter_20/JHN_20_1.mp3: [Errno 2] No such file or directory: '/content/organized data/JHN/Chapter_20/JHN_20_1.mp3'\n",
            "/content/organized data/JHN/Chapter_6/JHN_6_transcribed_te.txt does not exist\n",
            "/content/organized data/JHN/Chapter_12/JHN_12_transcribed_te.txt does not exist\n",
            "/content/organized data/JHN/Chapter_3/JHN_3_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/JHN/Chapter_3/JHN_3_1.mp3: [Errno 2] No such file or directory: '/content/organized data/JHN/Chapter_3/JHN_3_1.mp3'\n",
            "/content/organized data/JHN/Chapter_14/JHN_14_transcribed_te.txt does not exist\n",
            "/content/organized data/TIT/Chapter_1/TIT_1_transcribed_te.txt does not exist\n",
            "/content/organized data/TIT/Chapter_2/TIT_2_transcribed_te.txt does not exist\n",
            "/content/organized data/TIT/Chapter_3/TIT_3_transcribed_te.txt does not exist\n",
            "/content/organized data/1JN/Chapter_4/1JN_4_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1JN/Chapter_4/1JN_4_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1JN/Chapter_4/1JN_4_1.mp3'\n",
            "/content/organized data/1JN/Chapter_5/1JN_5_transcribed_te.txt does not exist\n",
            "/content/organized data/1JN/Chapter_1/1JN_1_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1JN/Chapter_1/1JN_1_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1JN/Chapter_1/1JN_1_1.mp3'\n",
            "/content/organized data/1JN/Chapter_2/1JN_2_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1JN/Chapter_2/1JN_2_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1JN/Chapter_2/1JN_2_1.mp3'\n",
            "/content/organized data/1JN/Chapter_3/1JN_3_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1JN/Chapter_3/1JN_3_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1JN/Chapter_3/1JN_3_1.mp3'\n",
            "/content/organized data/2CO/Chapter_11/2CO_11_transcribed_te.txt does not exist\n",
            "/content/organized data/2CO/Chapter_4/2CO_4_transcribed_te.txt does not exist\n",
            "/content/organized data/2CO/Chapter_8/2CO_8_transcribed_te.txt does not exist\n",
            "/content/organized data/2CO/Chapter_5/2CO_5_transcribed_te.txt does not exist\n",
            "/content/organized data/2CO/Chapter_9/2CO_9_transcribed_te.txt does not exist\n",
            "/content/organized data/2CO/Chapter_13/2CO_13_transcribed_te.txt does not exist\n",
            "/content/organized data/2CO/Chapter_7/2CO_7_transcribed_te.txt does not exist\n",
            "/content/organized data/2CO/Chapter_1/2CO_1_transcribed_te.txt does not exist\n",
            "/content/organized data/2CO/Chapter_10/2CO_10_transcribed_te.txt does not exist\n",
            "/content/organized data/2CO/Chapter_2/2CO_2_transcribed_te.txt does not exist\n",
            "/content/organized data/2CO/Chapter_6/2CO_6_transcribed_te.txt does not exist\n",
            "/content/organized data/2CO/Chapter_12/2CO_12_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/2CO/Chapter_12/2CO_12_1.mp3: [Errno 2] No such file or directory: '/content/organized data/2CO/Chapter_12/2CO_12_1.mp3'\n",
            "/content/organized data/2CO/Chapter_3/2CO_3_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/2CO/Chapter_3/2CO_3_1.mp3: [Errno 2] No such file or directory: '/content/organized data/2CO/Chapter_3/2CO_3_1.mp3'\n",
            "/content/organized data/JUD/Chapter_1/JUD_1_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/JUD/Chapter_1/JUD_1_1.mp3: [Errno 2] No such file or directory: '/content/organized data/JUD/Chapter_1/JUD_1_1.mp3'\n",
            "/content/organized data/REV/Chapter_11/REV_11_transcribed_te.txt does not exist\n",
            "/content/organized data/REV/Chapter_15/REV_15_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/REV/Chapter_15/REV_15_1.mp3: [Errno 2] No such file or directory: '/content/organized data/REV/Chapter_15/REV_15_1.mp3'\n",
            "/content/organized data/REV/Chapter_4/REV_4_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/REV/Chapter_4/REV_4_1.mp3: [Errno 2] No such file or directory: '/content/organized data/REV/Chapter_4/REV_4_1.mp3'\n",
            "/content/organized data/REV/Chapter_8/REV_8_transcribed_te.txt does not exist\n",
            "/content/organized data/REV/Chapter_19/REV_19_transcribed_te.txt does not exist\n",
            "/content/organized data/REV/Chapter_5/REV_5_transcribed_te.txt does not exist\n",
            "/content/organized data/REV/Chapter_9/REV_9_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/REV/Chapter_9/REV_9_1.mp3: [Errno 2] No such file or directory: '/content/organized data/REV/Chapter_9/REV_9_1.mp3'\n",
            "/content/organized data/REV/Chapter_21/REV_21_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/REV/Chapter_21/REV_21_1.mp3: [Errno 2] No such file or directory: '/content/organized data/REV/Chapter_21/REV_21_1.mp3'\n",
            "/content/organized data/REV/Chapter_17/REV_17_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/REV/Chapter_17/REV_17_1.mp3: [Errno 2] No such file or directory: '/content/organized data/REV/Chapter_17/REV_17_1.mp3'\n",
            "/content/organized data/REV/Chapter_13/REV_13_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/REV/Chapter_13/REV_13_1.mp3: [Errno 2] No such file or directory: '/content/organized data/REV/Chapter_13/REV_13_1.mp3'\n",
            "/content/organized data/REV/Chapter_7/REV_7_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/REV/Chapter_7/REV_7_1.mp3: [Errno 2] No such file or directory: '/content/organized data/REV/Chapter_7/REV_7_1.mp3'\n",
            "/content/organized data/REV/Chapter_1/REV_1_transcribed_te.txt does not exist\n",
            "/content/organized data/REV/Chapter_10/REV_10_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/REV/Chapter_10/REV_10_1.mp3: [Errno 2] No such file or directory: '/content/organized data/REV/Chapter_10/REV_10_1.mp3'\n",
            "/content/organized data/REV/Chapter_2/REV_2_transcribed_te.txt does not exist\n",
            "/content/organized data/REV/Chapter_22/REV_22_transcribed_te.txt does not exist\n",
            "/content/organized data/REV/Chapter_18/REV_18_transcribed_te.txt does not exist\n",
            "/content/organized data/REV/Chapter_16/REV_16_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/REV/Chapter_16/REV_16_1.mp3: [Errno 2] No such file or directory: '/content/organized data/REV/Chapter_16/REV_16_1.mp3'\n",
            "/content/organized data/REV/Chapter_20/REV_20_transcribed_te.txt does not exist\n",
            "/content/organized data/REV/Chapter_6/REV_6_transcribed_te.txt does not exist\n",
            "/content/organized data/REV/Chapter_12/REV_12_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/REV/Chapter_12/REV_12_1.mp3: [Errno 2] No such file or directory: '/content/organized data/REV/Chapter_12/REV_12_1.mp3'\n",
            "/content/organized data/REV/Chapter_3/REV_3_transcribed_te.txt does not exist\n",
            "/content/organized data/REV/Chapter_14/REV_14_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/REV/Chapter_14/REV_14_1.mp3: [Errno 2] No such file or directory: '/content/organized data/REV/Chapter_14/REV_14_1.mp3'\n",
            "/content/organized data/1PE/Chapter_4/1PE_4_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1PE/Chapter_4/1PE_4_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1PE/Chapter_4/1PE_4_1.mp3'\n",
            "/content/organized data/1PE/Chapter_5/1PE_5_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1PE/Chapter_5/1PE_5_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1PE/Chapter_5/1PE_5_1.mp3'\n",
            "/content/organized data/1PE/Chapter_1/1PE_1_transcribed_te.txt does not exist\n",
            "/content/organized data/1PE/Chapter_2/1PE_2_transcribed_te.txt does not exist\n",
            "/content/organized data/1PE/Chapter_3/1PE_3_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1PE/Chapter_3/1PE_3_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1PE/Chapter_3/1PE_3_1.mp3'\n",
            "/content/organized data/LUK/Chapter_24/LUK_24_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/LUK/Chapter_24/LUK_24_1.mp3: [Errno 2] No such file or directory: '/content/organized data/LUK/Chapter_24/LUK_24_1.mp3'\n",
            "/content/organized data/LUK/Chapter_11/LUK_11_transcribed_te.txt does not exist\n",
            "/content/organized data/LUK/Chapter_15/LUK_15_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/LUK/Chapter_15/LUK_15_1.mp3: [Errno 2] No such file or directory: '/content/organized data/LUK/Chapter_15/LUK_15_1.mp3'\n",
            "/content/organized data/LUK/Chapter_4/LUK_4_transcribed_te.txt does not exist\n",
            "/content/organized data/LUK/Chapter_8/LUK_8_transcribed_te.txt does not exist\n",
            "/content/organized data/LUK/Chapter_19/LUK_19_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/LUK/Chapter_19/LUK_19_1.mp3: [Errno 2] No such file or directory: '/content/organized data/LUK/Chapter_19/LUK_19_1.mp3'\n",
            "/content/organized data/LUK/Chapter_5/LUK_5_transcribed_te.txt does not exist\n",
            "/content/organized data/LUK/Chapter_9/LUK_9_transcribed_te.txt does not exist\n",
            "/content/organized data/LUK/Chapter_21/LUK_21_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/LUK/Chapter_21/LUK_21_1.mp3: [Errno 2] No such file or directory: '/content/organized data/LUK/Chapter_21/LUK_21_1.mp3'\n",
            "/content/organized data/LUK/Chapter_17/LUK_17_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/LUK/Chapter_17/LUK_17_1.mp3: [Errno 2] No such file or directory: '/content/organized data/LUK/Chapter_17/LUK_17_1.mp3'\n",
            "/content/organized data/LUK/Chapter_13/LUK_13_transcribed_te.txt does not exist\n",
            "/content/organized data/LUK/Chapter_7/LUK_7_transcribed_te.txt does not exist\n",
            "/content/organized data/LUK/Chapter_1/LUK_1_transcribed_te.txt does not exist\n",
            "/content/organized data/LUK/Chapter_23/LUK_23_transcribed_te.txt does not exist\n",
            "/content/organized data/LUK/Chapter_10/LUK_10_transcribed_te.txt does not exist\n",
            "/content/organized data/LUK/Chapter_2/LUK_2_transcribed_te.txt does not exist\n",
            "/content/organized data/LUK/Chapter_22/LUK_22_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/LUK/Chapter_22/LUK_22_1.mp3: [Errno 2] No such file or directory: '/content/organized data/LUK/Chapter_22/LUK_22_1.mp3'\n",
            "/content/organized data/LUK/Chapter_18/LUK_18_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/LUK/Chapter_18/LUK_18_1.mp3: [Errno 2] No such file or directory: '/content/organized data/LUK/Chapter_18/LUK_18_1.mp3'\n",
            "/content/organized data/LUK/Chapter_16/LUK_16_transcribed_te.txt does not exist\n",
            "/content/organized data/LUK/Chapter_20/LUK_20_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/LUK/Chapter_20/LUK_20_1.mp3: [Errno 2] No such file or directory: '/content/organized data/LUK/Chapter_20/LUK_20_1.mp3'\n",
            "/content/organized data/LUK/Chapter_6/LUK_6_transcribed_te.txt does not exist\n",
            "/content/organized data/LUK/Chapter_12/LUK_12_transcribed_te.txt does not exist\n",
            "/content/organized data/LUK/Chapter_3/LUK_3_transcribed_te.txt does not exist\n",
            "/content/organized data/LUK/Chapter_14/LUK_14_transcribed_te.txt does not exist\n",
            "/content/organized data/ROM/Chapter_11/ROM_11_transcribed_te.txt does not exist\n",
            "/content/organized data/ROM/Chapter_4/ROM_4_transcribed_te.txt does not exist\n",
            "/content/organized data/ROM/Chapter_8/ROM_8_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/ROM/Chapter_8/ROM_8_1.mp3: [Errno 2] No such file or directory: '/content/organized data/ROM/Chapter_8/ROM_8_1.mp3'\n",
            "/content/organized data/ROM/Chapter_5/ROM_5_transcribed_te.txt does not exist\n",
            "/content/organized data/ROM/Chapter_9/ROM_9_transcribed_te.txt does not exist\n",
            "/content/organized data/ROM/Chapter_7/ROM_7_transcribed_te.txt does not exist\n",
            "/content/organized data/ROM/Chapter_1/ROM_1_transcribed_te.txt does not exist\n",
            "/content/organized data/ROM/Chapter_10/ROM_10_transcribed_te.txt does not exist\n",
            "/content/organized data/ROM/Chapter_2/ROM_2_transcribed_te.txt does not exist\n",
            "/content/organized data/ROM/Chapter_6/ROM_6_transcribed_te.txt does not exist\n",
            "/content/organized data/ROM/Chapter_3/ROM_3_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/ROM/Chapter_3/ROM_3_1.mp3: [Errno 2] No such file or directory: '/content/organized data/ROM/Chapter_3/ROM_3_1.mp3'\n",
            "/content/organized data/ACT/Chapter_11/ACT_11_transcribed_te.txt does not exist\n",
            "/content/organized data/ACT/Chapter_15/ACT_15_transcribed_te.txt does not exist\n",
            "/content/organized data/ACT/Chapter_4/ACT_4_transcribed_te.txt does not exist\n",
            "/content/organized data/ACT/Chapter_8/ACT_8_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/ACT/Chapter_8/ACT_8_1.mp3: [Errno 2] No such file or directory: '/content/organized data/ACT/Chapter_8/ACT_8_1.mp3'\n",
            "/content/organized data/ACT/Chapter_19/ACT_19_transcribed_te.txt does not exist\n",
            "/content/organized data/ACT/Chapter_5/ACT_5_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/ACT/Chapter_5/ACT_5_1.mp3: [Errno 2] No such file or directory: '/content/organized data/ACT/Chapter_5/ACT_5_1.mp3'\n",
            "/content/organized data/ACT/Chapter_9/ACT_9_transcribed_te.txt does not exist\n",
            "/content/organized data/ACT/Chapter_21/ACT_21_transcribed_te.txt does not exist\n",
            "/content/organized data/ACT/Chapter_17/ACT_17_transcribed_te.txt does not exist\n",
            "/content/organized data/ACT/Chapter_13/ACT_13_transcribed_te.txt does not exist\n",
            "/content/organized data/ACT/Chapter_7/ACT_7_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/ACT/Chapter_7/ACT_7_1.mp3: [Errno 2] No such file or directory: '/content/organized data/ACT/Chapter_7/ACT_7_1.mp3'\n",
            "/content/organized data/ACT/Chapter_1/ACT_1_transcribed_te.txt does not exist\n",
            "/content/organized data/ACT/Chapter_10/ACT_10_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/ACT/Chapter_10/ACT_10_1.mp3: [Errno 2] No such file or directory: '/content/organized data/ACT/Chapter_10/ACT_10_1.mp3'\n",
            "/content/organized data/ACT/Chapter_2/ACT_2_transcribed_te.txt does not exist\n",
            "/content/organized data/ACT/Chapter_18/ACT_18_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/ACT/Chapter_18/ACT_18_1.mp3: [Errno 2] No such file or directory: '/content/organized data/ACT/Chapter_18/ACT_18_1.mp3'\n",
            "/content/organized data/ACT/Chapter_16/ACT_16_transcribed_te.txt does not exist\n",
            "/content/organized data/ACT/Chapter_20/ACT_20_transcribed_te.txt does not exist\n",
            "/content/organized data/ACT/Chapter_6/ACT_6_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/ACT/Chapter_6/ACT_6_1.mp3: [Errno 2] No such file or directory: '/content/organized data/ACT/Chapter_6/ACT_6_1.mp3'\n",
            "/content/organized data/ACT/Chapter_12/ACT_12_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/ACT/Chapter_12/ACT_12_1.mp3: [Errno 2] No such file or directory: '/content/organized data/ACT/Chapter_12/ACT_12_1.mp3'\n",
            "/content/organized data/ACT/Chapter_3/ACT_3_transcribed_te.txt does not exist\n",
            "/content/organized data/ACT/Chapter_14/ACT_14_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/ACT/Chapter_14/ACT_14_1.mp3: [Errno 2] No such file or directory: '/content/organized data/ACT/Chapter_14/ACT_14_1.mp3'\n",
            "/content/organized data/1TH/Chapter_4/1TH_4_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1TH/Chapter_4/1TH_4_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1TH/Chapter_4/1TH_4_1.mp3'\n",
            "/content/organized data/1TH/Chapter_5/1TH_5_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1TH/Chapter_5/1TH_5_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1TH/Chapter_5/1TH_5_1.mp3'\n",
            "/content/organized data/1TH/Chapter_1/1TH_1_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1TH/Chapter_1/1TH_1_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1TH/Chapter_1/1TH_1_1.mp3'\n",
            "/content/organized data/1TH/Chapter_2/1TH_2_transcribed_te.txt does not exist\n",
            "/content/organized data/1TH/Chapter_3/1TH_3_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1TH/Chapter_3/1TH_3_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1TH/Chapter_3/1TH_3_1.mp3'\n",
            "/content/organized data/2JN/Chapter_1/2JN_1_transcribed_te.txt does not exist\n",
            "/content/organized data/2PE/Chapter_1/2PE_1_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/2PE/Chapter_1/2PE_1_1.mp3: [Errno 2] No such file or directory: '/content/organized data/2PE/Chapter_1/2PE_1_1.mp3'\n",
            "/content/organized data/2PE/Chapter_2/2PE_2_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/2PE/Chapter_2/2PE_2_1.mp3: [Errno 2] No such file or directory: '/content/organized data/2PE/Chapter_2/2PE_2_1.mp3'\n",
            "/content/organized data/2PE/Chapter_3/2PE_3_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/2PE/Chapter_3/2PE_3_1.mp3: [Errno 2] No such file or directory: '/content/organized data/2PE/Chapter_3/2PE_3_1.mp3'\n",
            "/content/organized data/MAT/Chapter_24/MAT_24_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/MAT/Chapter_24/MAT_24_1.mp3: [Errno 2] No such file or directory: '/content/organized data/MAT/Chapter_24/MAT_24_1.mp3'\n",
            "/content/organized data/MAT/Chapter_11/MAT_11_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/MAT/Chapter_11/MAT_11_1.mp3: [Errno 2] No such file or directory: '/content/organized data/MAT/Chapter_11/MAT_11_1.mp3'\n",
            "/content/organized data/MAT/Chapter_15/MAT_15_transcribed_te.txt does not exist\n",
            "/content/organized data/MAT/Chapter_4/MAT_4_transcribed_te.txt does not exist\n",
            "/content/organized data/MAT/Chapter_8/MAT_8_transcribed_te.txt does not exist\n",
            "/content/organized data/MAT/Chapter_19/MAT_19_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/MAT/Chapter_19/MAT_19_1.mp3: [Errno 2] No such file or directory: '/content/organized data/MAT/Chapter_19/MAT_19_1.mp3'\n",
            "/content/organized data/MAT/Chapter_5/MAT_5_transcribed_te.txt does not exist\n",
            "/content/organized data/MAT/Chapter_27/MAT_27_transcribed_te.txt does not exist\n",
            "/content/organized data/MAT/Chapter_9/MAT_9_transcribed_te.txt does not exist\n",
            "/content/organized data/MAT/Chapter_21/MAT_21_transcribed_te.txt does not exist\n",
            "/content/organized data/MAT/Chapter_17/MAT_17_transcribed_te.txt does not exist\n",
            "/content/organized data/MAT/Chapter_13/MAT_13_transcribed_te.txt does not exist\n",
            "/content/organized data/MAT/Chapter_7/MAT_7_transcribed_te.txt does not exist\n",
            "/content/organized data/MAT/Chapter_1/MAT_1_transcribed_te.txt does not exist\n",
            "/content/organized data/MAT/Chapter_23/MAT_23_transcribed_te.txt does not exist\n",
            "/content/organized data/MAT/Chapter_10/MAT_10_transcribed_te.txt does not exist\n",
            "/content/organized data/MAT/Chapter_2/MAT_2_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/MAT/Chapter_2/MAT_2_1.mp3: [Errno 2] No such file or directory: '/content/organized data/MAT/Chapter_2/MAT_2_1.mp3'\n",
            "/content/organized data/MAT/Chapter_22/MAT_22_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/MAT/Chapter_22/MAT_22_1.mp3: [Errno 2] No such file or directory: '/content/organized data/MAT/Chapter_22/MAT_22_1.mp3'\n",
            "/content/organized data/MAT/Chapter_18/MAT_18_transcribed_te.txt does not exist\n",
            "/content/organized data/MAT/Chapter_25/MAT_25_transcribed_te.txt does not exist\n",
            "/content/organized data/MAT/Chapter_16/MAT_16_transcribed_te.txt does not exist\n",
            "/content/organized data/MAT/Chapter_20/MAT_20_transcribed_te.txt does not exist\n",
            "/content/organized data/MAT/Chapter_6/MAT_6_transcribed_te.txt does not exist\n",
            "/content/organized data/MAT/Chapter_28/MAT_28_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/MAT/Chapter_28/MAT_28_1.mp3: [Errno 2] No such file or directory: '/content/organized data/MAT/Chapter_28/MAT_28_1.mp3'\n",
            "/content/organized data/MAT/Chapter_12/MAT_12_transcribed_te.txt does not exist\n",
            "/content/organized data/MAT/Chapter_26/MAT_26_transcribed_te.txt does not exist\n",
            "/content/organized data/MAT/Chapter_3/MAT_3_transcribed_te.txt does not exist\n",
            "/content/organized data/MAT/Chapter_14/MAT_14_transcribed_te.txt does not exist\n",
            "/content/organized data/1TI/Chapter_4/1TI_4_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1TI/Chapter_4/1TI_4_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1TI/Chapter_4/1TI_4_1.mp3'\n",
            "/content/organized data/1TI/Chapter_5/1TI_5_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1TI/Chapter_5/1TI_5_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1TI/Chapter_5/1TI_5_1.mp3'\n",
            "/content/organized data/1TI/Chapter_1/1TI_1_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1TI/Chapter_1/1TI_1_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1TI/Chapter_1/1TI_1_1.mp3'\n",
            "/content/organized data/1TI/Chapter_2/1TI_2_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1TI/Chapter_2/1TI_2_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1TI/Chapter_2/1TI_2_1.mp3'\n",
            "/content/organized data/1TI/Chapter_6/1TI_6_transcribed_te.txt does not exist\n",
            "/content/organized data/1TI/Chapter_3/1TI_3_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1TI/Chapter_3/1TI_3_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1TI/Chapter_3/1TI_3_1.mp3'\n",
            "/content/organized data/3JN/Chapter_1/3JN_1_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/3JN/Chapter_1/3JN_1_1.mp3: [Errno 2] No such file or directory: '/content/organized data/3JN/Chapter_1/3JN_1_1.mp3'\n",
            "/content/organized data/1CO/Chapter_11/1CO_11_transcribed_te.txt does not exist\n",
            "/content/organized data/1CO/Chapter_15/1CO_15_transcribed_te.txt does not exist\n",
            "/content/organized data/1CO/Chapter_4/1CO_4_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1CO/Chapter_4/1CO_4_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1CO/Chapter_4/1CO_4_1.mp3'\n",
            "/content/organized data/1CO/Chapter_8/1CO_8_transcribed_te.txt does not exist\n",
            "/content/organized data/1CO/Chapter_5/1CO_5_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1CO/Chapter_5/1CO_5_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1CO/Chapter_5/1CO_5_1.mp3'\n",
            "/content/organized data/1CO/Chapter_9/1CO_9_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1CO/Chapter_9/1CO_9_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1CO/Chapter_9/1CO_9_1.mp3'\n",
            "/content/organized data/1CO/Chapter_13/1CO_13_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1CO/Chapter_13/1CO_13_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1CO/Chapter_13/1CO_13_1.mp3'\n",
            "/content/organized data/1CO/Chapter_7/1CO_7_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1CO/Chapter_7/1CO_7_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1CO/Chapter_7/1CO_7_1.mp3'\n",
            "/content/organized data/1CO/Chapter_1/1CO_1_transcribed_te.txt does not exist\n",
            "/content/organized data/1CO/Chapter_10/1CO_10_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1CO/Chapter_10/1CO_10_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1CO/Chapter_10/1CO_10_1.mp3'\n",
            "/content/organized data/1CO/Chapter_2/1CO_2_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1CO/Chapter_2/1CO_2_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1CO/Chapter_2/1CO_2_1.mp3'\n",
            "/content/organized data/1CO/Chapter_16/1CO_16_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/1CO/Chapter_16/1CO_16_1.mp3: [Errno 2] No such file or directory: '/content/organized data/1CO/Chapter_16/1CO_16_1.mp3'\n",
            "/content/organized data/1CO/Chapter_6/1CO_6_transcribed_te.txt does not exist\n",
            "/content/organized data/1CO/Chapter_12/1CO_12_transcribed_te.txt does not exist\n",
            "/content/organized data/1CO/Chapter_3/1CO_3_transcribed_te.txt does not exist\n",
            "/content/organized data/1CO/Chapter_14/1CO_14_transcribed_te.txt does not exist\n",
            "/content/organized data/2TI/Chapter_4/2TI_4_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/2TI/Chapter_4/2TI_4_1.mp3: [Errno 2] No such file or directory: '/content/organized data/2TI/Chapter_4/2TI_4_1.mp3'\n",
            "/content/organized data/2TI/Chapter_1/2TI_1_transcribed_te.txt does not exist\n",
            "/content/organized data/2TI/Chapter_2/2TI_2_transcribed_te.txt does not exist\n",
            "/content/organized data/2TI/Chapter_3/2TI_3_transcribed_te.txt does not exist\n",
            "/content/organized data/PHM/Chapter_1/PHM_1_transcribed_te.txt does not exist\n",
            "/content/organized data/2TH/Chapter_1/2TH_1_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/2TH/Chapter_1/2TH_1_1.mp3: [Errno 2] No such file or directory: '/content/organized data/2TH/Chapter_1/2TH_1_1.mp3'\n",
            "/content/organized data/2TH/Chapter_2/2TH_2_transcribed_te.txt does not exist\n",
            "/content/organized data/2TH/Chapter_3/2TH_3_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/2TH/Chapter_3/2TH_3_1.mp3: [Errno 2] No such file or directory: '/content/organized data/2TH/Chapter_3/2TH_3_1.mp3'\n",
            "/content/organized data/EPH/Chapter_4/EPH_4_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/EPH/Chapter_4/EPH_4_1.mp3: [Errno 2] No such file or directory: '/content/organized data/EPH/Chapter_4/EPH_4_1.mp3'\n",
            "/content/organized data/EPH/Chapter_5/EPH_5_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/EPH/Chapter_5/EPH_5_1.mp3: [Errno 2] No such file or directory: '/content/organized data/EPH/Chapter_5/EPH_5_1.mp3'\n",
            "/content/organized data/EPH/Chapter_1/EPH_1_transcribed_te.txt does not exist\n",
            "/content/organized data/EPH/Chapter_2/EPH_2_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/EPH/Chapter_2/EPH_2_1.mp3: [Errno 2] No such file or directory: '/content/organized data/EPH/Chapter_2/EPH_2_1.mp3'\n",
            "/content/organized data/EPH/Chapter_6/EPH_6_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/EPH/Chapter_6/EPH_6_1.mp3: [Errno 2] No such file or directory: '/content/organized data/EPH/Chapter_6/EPH_6_1.mp3'\n",
            "/content/organized data/EPH/Chapter_3/EPH_3_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/EPH/Chapter_3/EPH_3_1.mp3: [Errno 2] No such file or directory: '/content/organized data/EPH/Chapter_3/EPH_3_1.mp3'\n",
            "/content/organized data/COL/Chapter_4/COL_4_transcribed_te.txt does not exist\n",
            "/content/organized data/COL/Chapter_1/COL_1_transcribed_te.txt does not exist\n",
            "/content/organized data/COL/Chapter_2/COL_2_transcribed_te.txt does not exist\n",
            "/content/organized data/COL/Chapter_3/COL_3_transcribed_te.txt does not exist\n",
            "Error loading audio /content/organized data/COL/Chapter_3/COL_3_1.mp3: [Errno 2] No such file or directory: '/content/organized data/COL/Chapter_3/COL_3_1.mp3'\n",
            "  book     chapter                                              audio  \\\n",
            "0  PHP   Chapter_4                                               None   \n",
            "1  PHP   Chapter_1                                               None   \n",
            "2  PHP   Chapter_2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
            "3  PHP   Chapter_3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
            "4  HEB  Chapter_11                                               None   \n",
            "\n",
            "                                                text transcript sampling_rate  \n",
            "0                                                          None                \n",
            "1                                                          None                \n",
            "2                                                          None         22050  \n",
            "3  1സഹോദരരേ, ക്രിസ്തുവില്‍ സന്തുഷ്ടരാകുവിന്‍. എഴു...       None         22050  \n",
            "4                                                          None                \n",
            "The following transcript files could not be found:\n",
            "/content/organized data/PHP/Chapter_4/PHP_4_transcribed_te.txt\n",
            "/content/organized data/PHP/Chapter_1/PHP_1_transcribed_te.txt\n",
            "/content/organized data/PHP/Chapter_2/PHP_2_transcribed_te.txt\n",
            "/content/organized data/PHP/Chapter_3/PHP_3_transcribed_te.txt\n",
            "/content/organized data/HEB/Chapter_11/HEB_11_transcribed_te.txt\n",
            "/content/organized data/HEB/Chapter_4/HEB_4_transcribed_te.txt\n",
            "/content/organized data/HEB/Chapter_8/HEB_8_transcribed_te.txt\n",
            "/content/organized data/HEB/Chapter_5/HEB_5_transcribed_te.txt\n",
            "/content/organized data/HEB/Chapter_9/HEB_9_transcribed_te.txt\n",
            "/content/organized data/HEB/Chapter_13/HEB_13_transcribed_te.txt\n",
            "/content/organized data/HEB/Chapter_7/HEB_7_transcribed_te.txt\n",
            "/content/organized data/HEB/Chapter_1/HEB_1_transcribed_te.txt\n",
            "/content/organized data/HEB/Chapter_10/HEB_10_transcribed_te.txt\n",
            "/content/organized data/HEB/Chapter_2/HEB_2_transcribed_te.txt\n",
            "/content/organized data/HEB/Chapter_6/HEB_6_transcribed_te.txt\n",
            "/content/organized data/HEB/Chapter_12/HEB_12_transcribed_te.txt\n",
            "/content/organized data/HEB/Chapter_3/HEB_3_transcribed_te.txt\n",
            "/content/organized data/MRK/Chapter_11/MRK_11_transcribed_te.txt\n",
            "/content/organized data/MRK/Chapter_15/MRK_15_transcribed_te.txt\n",
            "/content/organized data/MRK/Chapter_4/MRK_4_transcribed_te.txt\n",
            "/content/organized data/MRK/Chapter_8/MRK_8_transcribed_te.txt\n",
            "/content/organized data/MRK/Chapter_5/MRK_5_transcribed_te.txt\n",
            "/content/organized data/MRK/Chapter_9/MRK_9_transcribed_te.txt\n",
            "/content/organized data/MRK/Chapter_13/MRK_13_transcribed_te.txt\n",
            "/content/organized data/MRK/Chapter_7/MRK_7_transcribed_te.txt\n",
            "/content/organized data/MRK/Chapter_1/MRK_1_transcribed_te.txt\n",
            "/content/organized data/MRK/Chapter_10/MRK_10_transcribed_te.txt\n",
            "/content/organized data/MRK/Chapter_2/MRK_2_transcribed_te.txt\n",
            "/content/organized data/MRK/Chapter_16/MRK_16_transcribed_te.txt\n",
            "/content/organized data/MRK/Chapter_6/MRK_6_transcribed_te.txt\n",
            "/content/organized data/MRK/Chapter_12/MRK_12_transcribed_te.txt\n",
            "/content/organized data/MRK/Chapter_3/MRK_3_transcribed_te.txt\n",
            "/content/organized data/MRK/Chapter_14/MRK_14_transcribed_te.txt\n",
            "/content/organized data/JAS/Chapter_4/JAS_4_transcribed_te.txt\n",
            "/content/organized data/JAS/Chapter_5/JAS_5_transcribed_te.txt\n",
            "/content/organized data/JAS/Chapter_1/JAS_1_transcribed_te.txt\n",
            "/content/organized data/JAS/Chapter_2/JAS_2_transcribed_te.txt\n",
            "/content/organized data/JAS/Chapter_3/JAS_3_transcribed_te.txt\n",
            "/content/organized data/GAL/Chapter_4/GAL_4_transcribed_te.txt\n",
            "/content/organized data/GAL/Chapter_5/GAL_5_transcribed_te.txt\n",
            "/content/organized data/GAL/Chapter_1/GAL_1_transcribed_te.txt\n",
            "/content/organized data/GAL/Chapter_2/GAL_2_transcribed_te.txt\n",
            "/content/organized data/GAL/Chapter_6/GAL_6_transcribed_te.txt\n",
            "/content/organized data/GAL/Chapter_3/GAL_3_transcribed_te.txt\n",
            "/content/organized data/JHN/Chapter_11/JHN_11_transcribed_te.txt\n",
            "/content/organized data/JHN/Chapter_15/JHN_15_transcribed_te.txt\n",
            "/content/organized data/JHN/Chapter_4/JHN_4_transcribed_te.txt\n",
            "/content/organized data/JHN/Chapter_8/JHN_8_transcribed_te.txt\n",
            "/content/organized data/JHN/Chapter_19/JHN_19_transcribed_te.txt\n",
            "/content/organized data/JHN/Chapter_5/JHN_5_transcribed_te.txt\n",
            "/content/organized data/JHN/Chapter_9/JHN_9_transcribed_te.txt\n",
            "/content/organized data/JHN/Chapter_21/JHN_21_transcribed_te.txt\n",
            "/content/organized data/JHN/Chapter_17/JHN_17_transcribed_te.txt\n",
            "/content/organized data/JHN/Chapter_13/JHN_13_transcribed_te.txt\n",
            "/content/organized data/JHN/Chapter_7/JHN_7_transcribed_te.txt\n",
            "/content/organized data/JHN/Chapter_1/JHN_1_transcribed_te.txt\n",
            "/content/organized data/JHN/Chapter_10/JHN_10_transcribed_te.txt\n",
            "/content/organized data/JHN/Chapter_2/JHN_2_transcribed_te.txt\n",
            "/content/organized data/JHN/Chapter_18/JHN_18_transcribed_te.txt\n",
            "/content/organized data/JHN/Chapter_16/JHN_16_transcribed_te.txt\n",
            "/content/organized data/JHN/Chapter_20/JHN_20_transcribed_te.txt\n",
            "/content/organized data/JHN/Chapter_6/JHN_6_transcribed_te.txt\n",
            "/content/organized data/JHN/Chapter_12/JHN_12_transcribed_te.txt\n",
            "/content/organized data/JHN/Chapter_3/JHN_3_transcribed_te.txt\n",
            "/content/organized data/JHN/Chapter_14/JHN_14_transcribed_te.txt\n",
            "/content/organized data/TIT/Chapter_1/TIT_1_transcribed_te.txt\n",
            "/content/organized data/TIT/Chapter_2/TIT_2_transcribed_te.txt\n",
            "/content/organized data/TIT/Chapter_3/TIT_3_transcribed_te.txt\n",
            "/content/organized data/1JN/Chapter_4/1JN_4_transcribed_te.txt\n",
            "/content/organized data/1JN/Chapter_5/1JN_5_transcribed_te.txt\n",
            "/content/organized data/1JN/Chapter_1/1JN_1_transcribed_te.txt\n",
            "/content/organized data/1JN/Chapter_2/1JN_2_transcribed_te.txt\n",
            "/content/organized data/1JN/Chapter_3/1JN_3_transcribed_te.txt\n",
            "/content/organized data/2CO/Chapter_11/2CO_11_transcribed_te.txt\n",
            "/content/organized data/2CO/Chapter_4/2CO_4_transcribed_te.txt\n",
            "/content/organized data/2CO/Chapter_8/2CO_8_transcribed_te.txt\n",
            "/content/organized data/2CO/Chapter_5/2CO_5_transcribed_te.txt\n",
            "/content/organized data/2CO/Chapter_9/2CO_9_transcribed_te.txt\n",
            "/content/organized data/2CO/Chapter_13/2CO_13_transcribed_te.txt\n",
            "/content/organized data/2CO/Chapter_7/2CO_7_transcribed_te.txt\n",
            "/content/organized data/2CO/Chapter_1/2CO_1_transcribed_te.txt\n",
            "/content/organized data/2CO/Chapter_10/2CO_10_transcribed_te.txt\n",
            "/content/organized data/2CO/Chapter_2/2CO_2_transcribed_te.txt\n",
            "/content/organized data/2CO/Chapter_6/2CO_6_transcribed_te.txt\n",
            "/content/organized data/2CO/Chapter_12/2CO_12_transcribed_te.txt\n",
            "/content/organized data/2CO/Chapter_3/2CO_3_transcribed_te.txt\n",
            "/content/organized data/JUD/Chapter_1/JUD_1_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_11/REV_11_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_15/REV_15_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_4/REV_4_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_8/REV_8_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_19/REV_19_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_5/REV_5_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_9/REV_9_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_21/REV_21_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_17/REV_17_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_13/REV_13_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_7/REV_7_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_1/REV_1_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_10/REV_10_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_2/REV_2_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_22/REV_22_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_18/REV_18_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_16/REV_16_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_20/REV_20_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_6/REV_6_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_12/REV_12_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_3/REV_3_transcribed_te.txt\n",
            "/content/organized data/REV/Chapter_14/REV_14_transcribed_te.txt\n",
            "/content/organized data/1PE/Chapter_4/1PE_4_transcribed_te.txt\n",
            "/content/organized data/1PE/Chapter_5/1PE_5_transcribed_te.txt\n",
            "/content/organized data/1PE/Chapter_1/1PE_1_transcribed_te.txt\n",
            "/content/organized data/1PE/Chapter_2/1PE_2_transcribed_te.txt\n",
            "/content/organized data/1PE/Chapter_3/1PE_3_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_24/LUK_24_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_11/LUK_11_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_15/LUK_15_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_4/LUK_4_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_8/LUK_8_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_19/LUK_19_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_5/LUK_5_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_9/LUK_9_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_21/LUK_21_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_17/LUK_17_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_13/LUK_13_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_7/LUK_7_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_1/LUK_1_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_23/LUK_23_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_10/LUK_10_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_2/LUK_2_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_22/LUK_22_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_18/LUK_18_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_16/LUK_16_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_20/LUK_20_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_6/LUK_6_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_12/LUK_12_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_3/LUK_3_transcribed_te.txt\n",
            "/content/organized data/LUK/Chapter_14/LUK_14_transcribed_te.txt\n",
            "/content/organized data/ROM/Chapter_11/ROM_11_transcribed_te.txt\n",
            "/content/organized data/ROM/Chapter_4/ROM_4_transcribed_te.txt\n",
            "/content/organized data/ROM/Chapter_8/ROM_8_transcribed_te.txt\n",
            "/content/organized data/ROM/Chapter_5/ROM_5_transcribed_te.txt\n",
            "/content/organized data/ROM/Chapter_9/ROM_9_transcribed_te.txt\n",
            "/content/organized data/ROM/Chapter_7/ROM_7_transcribed_te.txt\n",
            "/content/organized data/ROM/Chapter_1/ROM_1_transcribed_te.txt\n",
            "/content/organized data/ROM/Chapter_10/ROM_10_transcribed_te.txt\n",
            "/content/organized data/ROM/Chapter_2/ROM_2_transcribed_te.txt\n",
            "/content/organized data/ROM/Chapter_6/ROM_6_transcribed_te.txt\n",
            "/content/organized data/ROM/Chapter_3/ROM_3_transcribed_te.txt\n",
            "/content/organized data/ACT/Chapter_11/ACT_11_transcribed_te.txt\n",
            "/content/organized data/ACT/Chapter_15/ACT_15_transcribed_te.txt\n",
            "/content/organized data/ACT/Chapter_4/ACT_4_transcribed_te.txt\n",
            "/content/organized data/ACT/Chapter_8/ACT_8_transcribed_te.txt\n",
            "/content/organized data/ACT/Chapter_19/ACT_19_transcribed_te.txt\n",
            "/content/organized data/ACT/Chapter_5/ACT_5_transcribed_te.txt\n",
            "/content/organized data/ACT/Chapter_9/ACT_9_transcribed_te.txt\n",
            "/content/organized data/ACT/Chapter_21/ACT_21_transcribed_te.txt\n",
            "/content/organized data/ACT/Chapter_17/ACT_17_transcribed_te.txt\n",
            "/content/organized data/ACT/Chapter_13/ACT_13_transcribed_te.txt\n",
            "/content/organized data/ACT/Chapter_7/ACT_7_transcribed_te.txt\n",
            "/content/organized data/ACT/Chapter_1/ACT_1_transcribed_te.txt\n",
            "/content/organized data/ACT/Chapter_10/ACT_10_transcribed_te.txt\n",
            "/content/organized data/ACT/Chapter_2/ACT_2_transcribed_te.txt\n",
            "/content/organized data/ACT/Chapter_18/ACT_18_transcribed_te.txt\n",
            "/content/organized data/ACT/Chapter_16/ACT_16_transcribed_te.txt\n",
            "/content/organized data/ACT/Chapter_20/ACT_20_transcribed_te.txt\n",
            "/content/organized data/ACT/Chapter_6/ACT_6_transcribed_te.txt\n",
            "/content/organized data/ACT/Chapter_12/ACT_12_transcribed_te.txt\n",
            "/content/organized data/ACT/Chapter_3/ACT_3_transcribed_te.txt\n",
            "/content/organized data/ACT/Chapter_14/ACT_14_transcribed_te.txt\n",
            "/content/organized data/1TH/Chapter_4/1TH_4_transcribed_te.txt\n",
            "/content/organized data/1TH/Chapter_5/1TH_5_transcribed_te.txt\n",
            "/content/organized data/1TH/Chapter_1/1TH_1_transcribed_te.txt\n",
            "/content/organized data/1TH/Chapter_2/1TH_2_transcribed_te.txt\n",
            "/content/organized data/1TH/Chapter_3/1TH_3_transcribed_te.txt\n",
            "/content/organized data/2JN/Chapter_1/2JN_1_transcribed_te.txt\n",
            "/content/organized data/2PE/Chapter_1/2PE_1_transcribed_te.txt\n",
            "/content/organized data/2PE/Chapter_2/2PE_2_transcribed_te.txt\n",
            "/content/organized data/2PE/Chapter_3/2PE_3_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_24/MAT_24_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_11/MAT_11_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_15/MAT_15_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_4/MAT_4_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_8/MAT_8_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_19/MAT_19_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_5/MAT_5_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_27/MAT_27_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_9/MAT_9_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_21/MAT_21_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_17/MAT_17_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_13/MAT_13_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_7/MAT_7_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_1/MAT_1_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_23/MAT_23_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_10/MAT_10_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_2/MAT_2_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_22/MAT_22_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_18/MAT_18_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_25/MAT_25_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_16/MAT_16_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_20/MAT_20_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_6/MAT_6_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_28/MAT_28_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_12/MAT_12_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_26/MAT_26_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_3/MAT_3_transcribed_te.txt\n",
            "/content/organized data/MAT/Chapter_14/MAT_14_transcribed_te.txt\n",
            "/content/organized data/1TI/Chapter_4/1TI_4_transcribed_te.txt\n",
            "/content/organized data/1TI/Chapter_5/1TI_5_transcribed_te.txt\n",
            "/content/organized data/1TI/Chapter_1/1TI_1_transcribed_te.txt\n",
            "/content/organized data/1TI/Chapter_2/1TI_2_transcribed_te.txt\n",
            "/content/organized data/1TI/Chapter_6/1TI_6_transcribed_te.txt\n",
            "/content/organized data/1TI/Chapter_3/1TI_3_transcribed_te.txt\n",
            "/content/organized data/3JN/Chapter_1/3JN_1_transcribed_te.txt\n",
            "/content/organized data/1CO/Chapter_11/1CO_11_transcribed_te.txt\n",
            "/content/organized data/1CO/Chapter_15/1CO_15_transcribed_te.txt\n",
            "/content/organized data/1CO/Chapter_4/1CO_4_transcribed_te.txt\n",
            "/content/organized data/1CO/Chapter_8/1CO_8_transcribed_te.txt\n",
            "/content/organized data/1CO/Chapter_5/1CO_5_transcribed_te.txt\n",
            "/content/organized data/1CO/Chapter_9/1CO_9_transcribed_te.txt\n",
            "/content/organized data/1CO/Chapter_13/1CO_13_transcribed_te.txt\n",
            "/content/organized data/1CO/Chapter_7/1CO_7_transcribed_te.txt\n",
            "/content/organized data/1CO/Chapter_1/1CO_1_transcribed_te.txt\n",
            "/content/organized data/1CO/Chapter_10/1CO_10_transcribed_te.txt\n",
            "/content/organized data/1CO/Chapter_2/1CO_2_transcribed_te.txt\n",
            "/content/organized data/1CO/Chapter_16/1CO_16_transcribed_te.txt\n",
            "/content/organized data/1CO/Chapter_6/1CO_6_transcribed_te.txt\n",
            "/content/organized data/1CO/Chapter_12/1CO_12_transcribed_te.txt\n",
            "/content/organized data/1CO/Chapter_3/1CO_3_transcribed_te.txt\n",
            "/content/organized data/1CO/Chapter_14/1CO_14_transcribed_te.txt\n",
            "/content/organized data/2TI/Chapter_4/2TI_4_transcribed_te.txt\n",
            "/content/organized data/2TI/Chapter_1/2TI_1_transcribed_te.txt\n",
            "/content/organized data/2TI/Chapter_2/2TI_2_transcribed_te.txt\n",
            "/content/organized data/2TI/Chapter_3/2TI_3_transcribed_te.txt\n",
            "/content/organized data/PHM/Chapter_1/PHM_1_transcribed_te.txt\n",
            "/content/organized data/2TH/Chapter_1/2TH_1_transcribed_te.txt\n",
            "/content/organized data/2TH/Chapter_2/2TH_2_transcribed_te.txt\n",
            "/content/organized data/2TH/Chapter_3/2TH_3_transcribed_te.txt\n",
            "/content/organized data/EPH/Chapter_4/EPH_4_transcribed_te.txt\n",
            "/content/organized data/EPH/Chapter_5/EPH_5_transcribed_te.txt\n",
            "/content/organized data/EPH/Chapter_1/EPH_1_transcribed_te.txt\n",
            "/content/organized data/EPH/Chapter_2/EPH_2_transcribed_te.txt\n",
            "/content/organized data/EPH/Chapter_6/EPH_6_transcribed_te.txt\n",
            "/content/organized data/EPH/Chapter_3/EPH_3_transcribed_te.txt\n",
            "/content/organized data/COL/Chapter_4/COL_4_transcribed_te.txt\n",
            "/content/organized data/COL/Chapter_1/COL_1_transcribed_te.txt\n",
            "/content/organized data/COL/Chapter_2/COL_2_transcribed_te.txt\n",
            "/content/organized data/COL/Chapter_3/COL_3_transcribed_te.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting the dictionary into a dataframe\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Displaying the first 5 rows from the dataset/dataframe\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "am8D-wLP4571",
        "outputId": "dc2c575b-08ce-46f1-ca0e-51754baf3c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  book     chapter                                              audio  \\\n",
              "0  PHP   Chapter_4                                               None   \n",
              "1  PHP   Chapter_1                                               None   \n",
              "2  PHP   Chapter_2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "3  PHP   Chapter_3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "4  HEB  Chapter_11                                               None   \n",
              "\n",
              "                                                text transcript sampling_rate  \n",
              "0                                                          None                \n",
              "1                                                          None                \n",
              "2                                                          None         22050  \n",
              "3  1സഹോദരരേ, ക്രിസ്തുവില്‍ സന്തുഷ്ടരാകുവിന്‍. എഴു...       None         22050  \n",
              "4                                                          None                "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5ea5a46-c0ef-4c9f-8c8e-daee06657b27\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book</th>\n",
              "      <th>chapter</th>\n",
              "      <th>audio</th>\n",
              "      <th>text</th>\n",
              "      <th>transcript</th>\n",
              "      <th>sampling_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PHP</td>\n",
              "      <td>Chapter_4</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PHP</td>\n",
              "      <td>Chapter_1</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PHP</td>\n",
              "      <td>Chapter_2</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>22050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PHP</td>\n",
              "      <td>Chapter_3</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>1സഹോദരരേ, ക്രിസ്തുവില്‍ സന്തുഷ്ടരാകുവിന്‍. എഴു...</td>\n",
              "      <td>None</td>\n",
              "      <td>22050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HEB</td>\n",
              "      <td>Chapter_11</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5ea5a46-c0ef-4c9f-8c8e-daee06657b27')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d5ea5a46-c0ef-4c9f-8c8e-daee06657b27 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d5ea5a46-c0ef-4c9f-8c8e-daee06657b27');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6b0fded5-08ba-4289-ac49-fe6c48f5048a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6b0fded5-08ba-4289-ac49-fe6c48f5048a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6b0fded5-08ba-4289-ac49-fe6c48f5048a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECKING TO SEE IF EVERY BOOK EXISTS\n",
        "df[\"book\"].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVaNjvLd56gc",
        "outputId": "a3e87909-99be-4bc4-de6f-32c03cbd1d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['PHP', 'HEB', 'MRK', 'JAS', 'GAL', 'JHN', 'TIT', '1JN', '2CO',\n",
              "       'JUD', 'REV', '1PE', 'LUK', 'ROM', 'ACT', '1TH', '2JN', '2PE',\n",
              "       'MAT', '1TI', '3JN', '1CO', '2TI', 'PHM', '2TH', 'EPH', 'COL'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOMiUsMM6HRY",
        "outputId": "abc65ef9-3f72-4aef-af13-4b852e8b28ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "248"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import librosa\n",
        "\n",
        "# Function to convert audio column from string to numpy array\n",
        "def parse_audio_array(audio_str):\n",
        "    try:\n",
        "        return np.array(ast.literal_eval(audio_str))\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing audio array: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to calculate duration and SNR for each row\n",
        "def calculate_duration_and_snr(row):\n",
        "    try:\n",
        "        audio_array = row['audio']  # Get the audio array from the row\n",
        "        sr = row['sampling_rate']  # Get the sampling rate from the row\n",
        "\n",
        "        if audio_array is not None and isinstance(sr, (int, float)):\n",
        "            # Calculate duration\n",
        "            duration = librosa.get_duration(y=audio_array, sr=sr)  # Calculate the duration of the audio\n",
        "\n",
        "            # Calculate SNR (Signal-to-Noise Ratio)\n",
        "            mean_signal = np.mean(audio_array)  # Calculate the mean of the audio signal\n",
        "            std_signal = np.std(audio_array)  # Calculate the standard deviation of the audio signal\n",
        "            snr = mean_signal / std_signal if std_signal != 0 else np.nan  # Calculate the SNR\n",
        "\n",
        "            return duration, snr  # Return the duration and SNR\n",
        "        else:\n",
        "            raise ValueError(\"Invalid data in row: audio_array or sampling_rate\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing row: {e}\")  # Print error message if an exception occurs\n",
        "        return np.nan, np.nan  # Return NaN for duration and SNR in case of error\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'audio': ['[1, 2, 3, 4, 5]', '[2, 3, 4, 5, 6]'],  # Example audio data as strings\n",
        "    'sampling_rate': [22050, 22050]  # Example sampling rates\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert the 'audio' column to numpy arrays\n",
        "df['audio'] = df['audio'].apply(parse_audio_array)\n",
        "\n",
        "# Verify that the audio arrays and sampling rates are correctly parsed\n",
        "print(df)\n",
        "\n",
        "# Apply the calculate_duration_and_snr function to each row of the DataFrame\n",
        "df['duration'], df['snr'] = zip(*df.apply(calculate_duration_and_snr, axis=1))\n",
        "\n",
        "# Display the resulting DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6txN4CnjGdxB",
        "outputId": "38690c01-b77d-4fba-b1ea-0f914df7179b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             audio  sampling_rate\n",
            "0  [1, 2, 3, 4, 5]          22050\n",
            "1  [2, 3, 4, 5, 6]          22050\n",
            "             audio  sampling_rate  duration       snr\n",
            "0  [1, 2, 3, 4, 5]          22050  0.000227  2.121320\n",
            "1  [2, 3, 4, 5, 6]          22050  0.000227  2.828427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['snr'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gg0XU2D2IuaU",
        "outputId": "e6b5985b-992b-4916-8f50-ae24eee13648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    2.000000\n",
              "mean     2.474874\n",
              "std      0.500000\n",
              "min      2.121320\n",
              "25%      2.298097\n",
              "50%      2.474874\n",
              "75%      2.651650\n",
              "max      2.828427\n",
              "Name: snr, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLORATORY DATA ANALYSIS"
      ],
      "metadata": {
        "id": "sEGDPUNd1Pb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Signal-to-Noise Ratio (SNR) Distribution"
      ],
      "metadata": {
        "id": "JZGbfumMIED1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt  # Import the matplotlib library for plotting\n",
        "\n",
        "# Create a line plot of the SNR values\n",
        "plt.plot(df['snr'], color=\"lightgreen\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "b3kM_n9oIFUY",
        "outputId": "3aa63ae6-7a06-489e-c27f-883ba7e66467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ffa007163b0>]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['duration'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwIgOGJLI7NF",
        "outputId": "2cac9162-3ea9-4a6e-e580-7660ae19b5f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    2.000000\n",
              "mean     0.000227\n",
              "std      0.000000\n",
              "min      0.000227\n",
              "25%      0.000227\n",
              "50%      0.000227\n",
              "75%      0.000227\n",
              "max      0.000227\n",
              "Name: duration, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ya-5qyNI9wJ",
        "outputId": "ef6361b6-03e9-4df5-f3b8-fe646e5896f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2 entries, 0 to 1\n",
            "Data columns (total 4 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   audio          2 non-null      object \n",
            " 1   sampling_rate  2 non-null      int64  \n",
            " 2   duration       2 non-null      float64\n",
            " 3   snr            2 non-null      float64\n",
            "dtypes: float64(2), int64(1), object(1)\n",
            "memory usage: 192.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Signal-to-Noise Ratio Distribution**"
      ],
      "metadata": {
        "id": "diIahmepJJwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "cyy9kGwiJJHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df, x='snr', color=\"lightgreen\")\n",
        "plt.title('Signal-to-Noise Ratio Distribution')\n",
        "plt.xlabel('SNR')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "gBlEsRmjJRDa",
        "outputId": "ba3eba54-9626-45ed-e70b-7b2ed410c6c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis of Audio Duration**"
      ],
      "metadata": {
        "id": "UXNRQo7vJhZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(df['duration'], color = \"lightgreen\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "E-Nj32LVJg6P",
        "outputId": "e01a29e3-a1cb-4db3-8250-5ae7845d41d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff9fd994ee0>]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distribution of Audio Durations**"
      ],
      "metadata": {
        "id": "ErrOJzAOJtfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the distribution of audio durations\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['duration'], bins=20, kde=True)\n",
        "plt.title('Distribution of Audio Durations')\n",
        "plt.xlabel('Duration (seconds)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "4L3gdfA-Jva5",
        "outputId": "04e7ff33-aa33-4aa5-eed1-bc11ef8d19b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distribution of SNR**"
      ],
      "metadata": {
        "id": "R5fTzn1_J-rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the distribution of SNR\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['snr'], bins=20, kde=True)\n",
        "plt.title('Distribution of SNR')\n",
        "plt.xlabel('SNR')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "7iFZ1FmpJ-Bc",
        "outputId": "670ddd40-97df-4d38-8484-ebcb136aab8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "TEnkAjSgCSH2",
        "outputId": "16e8bc44-2bff-4a71-e55d-6830761a875b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             audio  sampling_rate  duration       snr\n",
              "0  [1, 2, 3, 4, 5]          22050  0.000227  2.121320\n",
              "1  [2, 3, 4, 5, 6]          22050  0.000227  2.828427"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-967bf40b-6fc7-4c69-b62b-366422ae41c8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>audio</th>\n",
              "      <th>sampling_rate</th>\n",
              "      <th>duration</th>\n",
              "      <th>snr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[1, 2, 3, 4, 5]</td>\n",
              "      <td>22050</td>\n",
              "      <td>0.000227</td>\n",
              "      <td>2.121320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[2, 3, 4, 5, 6]</td>\n",
              "      <td>22050</td>\n",
              "      <td>0.000227</td>\n",
              "      <td>2.828427</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-967bf40b-6fc7-4c69-b62b-366422ae41c8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-967bf40b-6fc7-4c69-b62b-366422ae41c8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-967bf40b-6fc7-4c69-b62b-366422ae41c8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9e118c88-ee39-4558-9fbd-431019dbe027\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9e118c88-ee39-4558-9fbd-431019dbe027')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9e118c88-ee39-4558-9fbd-431019dbe027 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"audio\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sampling_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 22050,\n        \"max\": 22050,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          22050\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.00022675736961451248,\n        \"max\": 0.00022675736961451248,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.00022675736961451248\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"snr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49999999999999994,\n        \"min\": 2.1213203435596424,\n        \"max\": 2.82842712474619,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2.82842712474619\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy**"
      ],
      "metadata": {
        "id": "ydwDEzwpLRuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BLEU Score: Measures precision of n-grams in the candidate translation against reference translations. Higher BLEU score indicates better translation quality."
      ],
      "metadata": {
        "id": "LWdn8MSUN4aL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueCattsbLVF_",
        "outputId": "c8908b7a-876c-421c-d2a8-41d4765d9735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
        "\n",
        "# Sample translations\n",
        "reference = [\n",
        "    ['this', 'is', 'a', 'test'],\n",
        "    ['this', 'is', 'another', 'test']\n",
        "]\n",
        "candidate = ['this', 'is', 'a', 'test']\n",
        "\n",
        "# Calculate BLEU score for a single sentence\n",
        "score = sentence_bleu(reference, candidate)\n",
        "print(f'BLEU score: {score}')\n",
        "\n",
        "# For corpus BLEU score\n",
        "references = [\n",
        "    [['this', 'is', 'a', 'test'], ['this', 'is', 'another', 'test']],\n",
        "    [['another', 'sentence']]\n",
        "]\n",
        "candidates = [\n",
        "    ['this', 'is', 'a', 'test'],\n",
        "    ['another', 'sentence']\n",
        "]\n",
        "corpus_score = corpus_bleu(references, candidates)\n",
        "print(f'Corpus BLEU score: {corpus_score}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEG5DiRHMJP9",
        "outputId": "0fdf2ee6-f2fd-4737-cdd1-b2c2fae0867c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score: 1.0\n",
            "Corpus BLEU score: 0.7598356856515925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate ROUGE Score:**"
      ],
      "metadata": {
        "id": "fSg2PciVMmry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROUGE Score: Measures recall of n-grams. Useful for tasks like summarization"
      ],
      "metadata": {
        "id": "QB6e8q9PN6zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmmwmk_WNGpT",
        "outputId": "1ee28957-cb02-4ef7-a7a7-428fe1455de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "# Sample translations\n",
        "audio = \" \"\n",
        "duration = \" \"\n",
        "\n",
        "# Initialize ROUGE scorer\n",
        "rouge = Rouge()\n",
        "scores = rouge.get_scores(audio, duration)\n",
        "\n",
        "print(f'ROUGE scores: {scores}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qnIYmQRMpJT",
        "outputId": "829e3b20-81e2-44a9-fd3c-18af2908b1c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE scores: [{'rouge-1': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TER (Translation Edit Rate): Measures the number of edits required to change the candidate translation into one of the references. Lower TER indicates better translation quality."
      ],
      "metadata": {
        "id": "H6Dcz_b5PmdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY8xctwdPoDe",
        "outputId": "6b669cef-2b68-4fdb-a980-712cacfb5353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.5.15)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.25.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.8.2 sacrebleu-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu\n",
        "\n",
        "# Sample translations\n",
        "audio = [\" \"]\n",
        "snr = [\" \"]\n",
        "\n",
        "# Calculate TER\n",
        "ter_score = sacrebleu.corpus_ter(snr, [audio])\n",
        "print(f'TER score: {ter_score.score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Adzchq6PwRV",
        "outputId": "67656e85-7567-4770-994a-cd11a4e7bc2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TER score: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChrF (Character F-score): Evaluates translation accuracy based on character n-grams. Useful for morphologically rich languages."
      ],
      "metadata": {
        "id": "BVU3YjdtQSrV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Task 1: Audio Transcription\n",
        "\n",
        "**Advantages:**\n",
        "1. **Accessibility**: Transcribing audio to text makes content accessible to those who are deaf or hard of hearing.\n",
        "2. **Searchability**: Text versions of audio content can be easily searched, indexed, and referenced.\n",
        "3. **Archiving**: Text files take up significantly less space than audio files, making archiving and storage more efficient.\n",
        "4. **Multimedia Integration**: Transcripts can be used alongside audio for multimedia presentations, aiding in comprehension and learning.\n",
        "5. **Data Analysis**: Text data can be more easily analyzed and processed for patterns, keywords, and trends compared to audio.\n",
        "\n",
        "**Disadvantages:**\n",
        "1. **Accuracy**: Transcription accuracy can vary based on audio quality, background noise, and the clarity of speech, leading to potential errors.\n",
        "2. **Processing Time**: High-quality transcription, especially for long audio files, can be time-consuming and resource-intensive.\n",
        "3. **Context Loss**: Some nuances, emotions, and context might be lost in transcription, as text lacks the tone and inflection of spoken language.\n",
        "4. **Language Support**: Automatic transcription tools may not support all languages or dialects equally well, limiting their applicability.\n",
        "\n",
        "### Task 2: Text Translation\n",
        "\n",
        "**Advantages:**\n",
        "1. **Global Reach**: Translating text into multiple languages allows content to reach a broader, global audience.\n",
        "2. **Cultural Relevance**: Translation makes content culturally relevant and understandable to different linguistic groups.\n",
        "3. **Education**: Translated texts can be used as educational resources, helping language learners and providing access to information in various languages.\n",
        "4. **Business Expansion**: For businesses, translating content can open up new markets and customer bases.\n",
        "5. **Improved Communication**: Translation aids in breaking down language barriers, facilitating better communication and collaboration across linguistic boundaries.\n",
        "\n",
        "**Disadvantages:**\n",
        "1. **Accuracy and Quality**: Machine translations can sometimes be inaccurate or awkward, potentially leading to misunderstandings or miscommunications.\n",
        "2. **Context Sensitivity**: Translating idioms, slang, and context-specific phrases can be challenging, often requiring human intervention to ensure accuracy.\n",
        "3. **Resource Intensive**: High-quality translation, especially for technical or specialized content, can be resource-intensive and may require professional human translators.\n",
        "4. **Language Support**: Not all languages are supported equally well by translation models, and low-resource languages might have limited translation quality.\n",
        "5. **Maintenance**: Keeping translations up to date with original content can be a continuous effort, requiring ongoing attention and resources.\n",
        "\n",
        "### Combined Workflow: Transcription and Translation\n",
        "\n",
        "**Advantages:**\n",
        "1. **Comprehensive Accessibility**: Combining transcription and translation makes content accessible to both non-native speakers and those with hearing impairments.\n",
        "2. **Enhanced Usability**: Translated transcripts can be used in diverse settings, such as education, media, and customer support, improving overall usability.\n",
        "3. **Broader Reach**: This workflow enables content to be both accessible and understandable to a global audience, maximizing its impact.\n",
        "\n",
        "**Disadvantages:**\n",
        "1. **Complexity**: Combining both tasks increases the complexity of the workflow, potentially introducing more points of failure or error.\n",
        "2. **Cost and Time**: Both tasks can be resource-intensive, requiring significant computational power and time, especially for large datasets.\n",
        "3. **Cumulative Errors**: Errors in transcription can propagate to translation, compounding inaccuracies and reducing overall quality.\n",
        "\n",
        "In summary, while both transcription and translation offer significant benefits in terms of accessibility and reach, they also come with challenges related to accuracy, resource requirements, and complexity. Balancing these factors is key to successfully implementing these tasks in real-world applications."
      ],
      "metadata": {
        "id": "9cGOu5dSRyN6"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f6399a0aaaba4199bd17bdb3f4c4c105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c021321ad1c34121a56e45062db03b12",
              "IPY_MODEL_61cbc9241a0d402ca06cc3f920712fd3",
              "IPY_MODEL_7fac24baddcd4b3590a94530559777cc"
            ],
            "layout": "IPY_MODEL_c9e909b01cca482981a3397e39e9a4b7"
          }
        },
        "c021321ad1c34121a56e45062db03b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_660301ea651442adadce24d8da27a2fa",
            "placeholder": "​",
            "style": "IPY_MODEL_1c875bc1839f4ce198c2aaa92d506b6b",
            "value": "config.json: 100%"
          }
        },
        "61cbc9241a0d402ca06cc3f920712fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee4424304f5540978216f4c79d74479a",
            "max": 1531,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d5863c887474be3919bd72b3e9fbd87",
            "value": 1531
          }
        },
        "7fac24baddcd4b3590a94530559777cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89101a79247542dd9a8095bef7afcee6",
            "placeholder": "​",
            "style": "IPY_MODEL_53e8ccab8da346b89e1532cff5eefb81",
            "value": " 1.53k/1.53k [00:00&lt;00:00, 16.1kB/s]"
          }
        },
        "c9e909b01cca482981a3397e39e9a4b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "660301ea651442adadce24d8da27a2fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c875bc1839f4ce198c2aaa92d506b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee4424304f5540978216f4c79d74479a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d5863c887474be3919bd72b3e9fbd87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89101a79247542dd9a8095bef7afcee6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53e8ccab8da346b89e1532cff5eefb81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bba9fdaa4f334a1b9b3eb244f7749042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7d781a9752b4673b9a0319239e33ffb",
              "IPY_MODEL_61ad0b88193d4777b73916c6ecfaf829",
              "IPY_MODEL_c6f3ea1e36ec4d47964e36c21e3108f7"
            ],
            "layout": "IPY_MODEL_df56bc77113e4b46b551eab776838043"
          }
        },
        "b7d781a9752b4673b9a0319239e33ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc3e10bcf5bc4ea49c21fd4702cca395",
            "placeholder": "​",
            "style": "IPY_MODEL_38e616f59e284052882473201e53bf41",
            "value": "model.safetensors: 100%"
          }
        },
        "61ad0b88193d4777b73916c6ecfaf829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c87d95c93b3049a58547b56fc859f233",
            "max": 1261942732,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0317b9fcee974d4190d680cf4a82637e",
            "value": 1261942732
          }
        },
        "c6f3ea1e36ec4d47964e36c21e3108f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17918264bc964a6a90ae95107075dfb1",
            "placeholder": "​",
            "style": "IPY_MODEL_42ea468df5834d01b130b89e6a9f34bf",
            "value": " 1.26G/1.26G [00:40&lt;00:00, 17.4MB/s]"
          }
        },
        "df56bc77113e4b46b551eab776838043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc3e10bcf5bc4ea49c21fd4702cca395": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38e616f59e284052882473201e53bf41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c87d95c93b3049a58547b56fc859f233": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0317b9fcee974d4190d680cf4a82637e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17918264bc964a6a90ae95107075dfb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42ea468df5834d01b130b89e6a9f34bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d79e7c909fda4fbf972494a16b7e6d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e8bb7a508084c438fa7eb57715c6287",
              "IPY_MODEL_33e15d315d834330bb79c47718c3b2a1",
              "IPY_MODEL_990552a19b6040598369af0c2976ffd3"
            ],
            "layout": "IPY_MODEL_5abf10858c8d4a65856d5ca262f92d95"
          }
        },
        "2e8bb7a508084c438fa7eb57715c6287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ecb54fce93e436399c2ebd965c18cb7",
            "placeholder": "​",
            "style": "IPY_MODEL_76e8e8d229534300ae371a04d5f4fe3d",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "33e15d315d834330bb79c47718c3b2a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50025e04e630441bb85207c42d4e2b4a",
            "max": 262,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d698c9d3b4c442d860a597672f240b2",
            "value": 262
          }
        },
        "990552a19b6040598369af0c2976ffd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf80d4fde51b4342b66b174272b1bdb7",
            "placeholder": "​",
            "style": "IPY_MODEL_330d7c50653c4069a100d51b96619779",
            "value": " 262/262 [00:00&lt;00:00, 17.0kB/s]"
          }
        },
        "5abf10858c8d4a65856d5ca262f92d95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ecb54fce93e436399c2ebd965c18cb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76e8e8d229534300ae371a04d5f4fe3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50025e04e630441bb85207c42d4e2b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d698c9d3b4c442d860a597672f240b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf80d4fde51b4342b66b174272b1bdb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "330d7c50653c4069a100d51b96619779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e42bf5d388064b19b2f1b0ebfbeae4c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80c495c9092a48869cab7ba7df20c381",
              "IPY_MODEL_ca8e8fabc7494f0faf28090572977347",
              "IPY_MODEL_032c8e094eec40c98ac0d9e284d9dd56"
            ],
            "layout": "IPY_MODEL_63abb5c8ed86426fa0f672f9f734ac04"
          }
        },
        "80c495c9092a48869cab7ba7df20c381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_712b181a9138445893edf51b9e32d003",
            "placeholder": "​",
            "style": "IPY_MODEL_bcca7a7c463942ec811358413ff1ec77",
            "value": "vocab.json: 100%"
          }
        },
        "ca8e8fabc7494f0faf28090572977347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d37948d4ad942069064476a99076707",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b513e0a403b74191b4bac698ecdb9c25",
            "value": 300
          }
        },
        "032c8e094eec40c98ac0d9e284d9dd56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56caba84a5fb46fcb210dda0bb474577",
            "placeholder": "​",
            "style": "IPY_MODEL_8e7cf019480747768090c838781d1712",
            "value": " 300/300 [00:00&lt;00:00, 17.1kB/s]"
          }
        },
        "63abb5c8ed86426fa0f672f9f734ac04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "712b181a9138445893edf51b9e32d003": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcca7a7c463942ec811358413ff1ec77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d37948d4ad942069064476a99076707": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b513e0a403b74191b4bac698ecdb9c25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56caba84a5fb46fcb210dda0bb474577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e7cf019480747768090c838781d1712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15dcb7b3a28345b49c2f5dc638196cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a93d84b0d4ff4aa8a9f9fb50edbce2c2",
              "IPY_MODEL_ba541533e6d64ac4b97689f14d9682fc",
              "IPY_MODEL_f2a7303730f1499583e84a0aad789114"
            ],
            "layout": "IPY_MODEL_28e126392b5a4a0fad4bdbc13f30883c"
          }
        },
        "a93d84b0d4ff4aa8a9f9fb50edbce2c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63a1d5ae21cd4be4b5a34177916992bb",
            "placeholder": "​",
            "style": "IPY_MODEL_42e699c717ce4e0bbce5e8a298552faf",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "ba541533e6d64ac4b97689f14d9682fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_112afb0733a7441ca6dd4850e81566b1",
            "max": 85,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a12cd402e654b4a842736e830f9b553",
            "value": 85
          }
        },
        "f2a7303730f1499583e84a0aad789114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be995b49d1d04fd8b1b5cb7f2135f3bf",
            "placeholder": "​",
            "style": "IPY_MODEL_bb418f25644847579af5634cdc1dee6c",
            "value": " 85.0/85.0 [00:00&lt;00:00, 4.39kB/s]"
          }
        },
        "28e126392b5a4a0fad4bdbc13f30883c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63a1d5ae21cd4be4b5a34177916992bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42e699c717ce4e0bbce5e8a298552faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "112afb0733a7441ca6dd4850e81566b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a12cd402e654b4a842736e830f9b553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be995b49d1d04fd8b1b5cb7f2135f3bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb418f25644847579af5634cdc1dee6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}